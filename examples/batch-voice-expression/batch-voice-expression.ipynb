{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch API / Voice Expression\n",
        "\n",
        "This notebook uses the batch API to analyze emotion in the spoken word and in emotional sounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utilities import print_emotions\n",
        "\n",
        "from hume import HumeBatchClient\n",
        "from hume.models.config import BurstConfig, ProsodyConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Submit a batch job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = HumeBatchClient(\"<your-api-key>\")\n",
        "\n",
        "urls = [\"https://storage.googleapis.com/hume-test-data/audio/ninth-century-laugh.mp3\"]\n",
        "burst_config = BurstConfig()\n",
        "prosody_config = ProsodyConfig()\n",
        "\n",
        "# Use a webhook callback to get a POST notification to your API when the batch job has completed\n",
        "callback_url = \"https://mockbin.org/bin/08d1f920-801c-4de1-9622-8c7b39658009\"\n",
        "job = client.submit_job(urls, [burst_config, prosody_config], callback_url=callback_url)\n",
        "\n",
        "print(\"Running...\", job)\n",
        "job.await_complete()\n",
        "print(\"Job completed with status: \", job.get_status())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print out predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_predictions = job.get_predictions()\n",
        "for source in full_predictions:\n",
        "    source_name = source[\"source\"][\"url\"]\n",
        "    predictions = source[\"results\"][\"predictions\"]\n",
        "    for prediction in predictions:\n",
        "        print()\n",
        "        print(\"Speech prosody\")\n",
        "        prosody_predictions = prediction[\"models\"][\"prosody\"][\"grouped_predictions\"]\n",
        "        for prosody_prediction in prosody_predictions:\n",
        "            for segment in prosody_prediction[\"predictions\"][:1]:\n",
        "                print_emotions(segment[\"emotions\"])\n",
        "\n",
        "        print()\n",
        "        print(\"Vocal burst\")\n",
        "        burst_predictions = prediction[\"models\"][\"burst\"][\"grouped_predictions\"]\n",
        "        for burst_prediction in burst_predictions:\n",
        "            for segment in burst_prediction[\"predictions\"][:1]:\n",
        "                print_emotions(segment[\"emotions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "803ebf602b46e67aaba753b211048224996199ded4fc88a644a85d99d245b351"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
