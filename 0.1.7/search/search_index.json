{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Requirements Python versions 3.8 and 3.9 are supported Installation Basic installation: $ pip install hume Websocket and streaming features can be enabled with: $ pip install hume [ stream ] Basic Usage Submit a new batch job Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] job = client . submit_face ( urls ) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" ) Rehydrate a batch job from a job ID from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job ) Stream predictions over a websocket Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient , StreamSocket from hume.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) configs = [ FaceConfig ( identify_faces = True )] async with client . connect ( configs ) as socket : socket : StreamSocket result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Other Resources Hume AI Homepage Platform Documentation API Reference Support The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#requirements","text":"Python versions 3.8 and 3.9 are supported","title":"Requirements"},{"location":"#installation","text":"Basic installation: $ pip install hume Websocket and streaming features can be enabled with: $ pip install hume [ stream ]","title":"Installation"},{"location":"#basic-usage","text":"","title":"Basic Usage"},{"location":"#submit-a-new-batch-job","text":"Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] job = client . submit_face ( urls ) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" )","title":"Submit a new batch job"},{"location":"#rehydrate-a-batch-job-from-a-job-id","text":"from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job )","title":"Rehydrate a batch job from a job ID"},{"location":"#stream-predictions-over-a-websocket","text":"Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient , StreamSocket from hume.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) configs = [ FaceConfig ( identify_faces = True )] async with client . connect ( configs ) as socket : socket : StreamSocket result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ())","title":"Stream predictions over a websocket"},{"location":"#other-resources","text":"Hume AI Homepage Platform Documentation API Reference","title":"Other Resources"},{"location":"#support","text":"The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Support"},{"location":"batch/batch-job-result/","text":"Batch job result. Source code in hume/_batch/batch_job_result.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class BatchJobResult : \"\"\"Batch job result.\"\"\" def __init__ ( self , * , configs : Dict [ ModelType , JobConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, JobConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientError ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath ) def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientError ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath ) def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientError ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath ) def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time ) def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time ) @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . deserialize ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientError ( message ) from exc @classmethod def _get_invalid_response_message ( cls , response : Any ) -> str : response_str = json . dumps ( response ) message = f \"Could not parse response into BatchJobResult: { response_str } \" # Check for invalid API key if \"fault\" in response and \"faultstring\" in response [ \"fault\" ]: fault_string = response [ \"fault\" ][ \"faultstring\" ] if fault_string == \"Invalid ApiKey\" : message = \"Client initialized with invalid API key\" return message __init__ ( * , configs , urls , status , predictions_url = None , artifacts_url = None , errors_url = None , error_message = None , job_start_time = None , job_end_time = None ) Construct a BatchJobResult. Parameters: Name Type Description Default configs Dict [ ModelType , JobConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required status BatchJobStatus Status of BatchJob . required predictions_url Optional [ str ] URL to predictions file. None artifacts_url Optional [ str ] URL to artifacts zip archive. None errors_url Optional [ str ] URL to errors file. None error_message Optional [ str ] Error message for request. None job_start_time Optional [ int ] Time when job started. None job_end_time Optional [ int ] Time when job completed. None Source code in hume/_batch/batch_job_result.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , * , configs : Dict [ ModelType , JobConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, JobConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time download_artifacts ( filepath = None ) Download BatchJob artifacts zip archive. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts zip archive will be downloaded. None Source code in hume/_batch/batch_job_result.py 64 65 66 67 68 69 70 71 72 def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientError ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath ) download_errors ( filepath = None ) Download BatchJob errors file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where errors will be downloaded. None Source code in hume/_batch/batch_job_result.py 74 75 76 77 78 79 80 81 82 def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientError ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath ) download_predictions ( filepath = None ) Download BatchJob predictions file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where predictions will be downloaded. None Source code in hume/_batch/batch_job_result.py 54 55 56 57 58 59 60 61 62 def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientError ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath ) from_response ( response ) classmethod Construct a BatchJobResult from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobResult BatchJobResult A BatchJobResult based on a batch API job response. Source code in hume/_batch/batch_job_result.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . deserialize ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientError ( message ) from exc get_end_time () Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 114 115 116 117 118 119 120 121 122 123 def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time ) get_error_message () Get any available error messages on the job. Returns: Type Description Optional [ str ] Optional[str]: A string with the error message if there was an error, otherwise None . Source code in hume/_batch/batch_job_result.py 84 85 86 87 88 89 90 def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message get_run_time () Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 92 93 94 95 96 97 98 99 100 101 def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None get_start_time () Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_result.py 103 104 105 106 107 108 109 110 111 112 def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time )","title":"BatchJobResult"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.__init__","text":"Construct a BatchJobResult. Parameters: Name Type Description Default configs Dict [ ModelType , JobConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required status BatchJobStatus Status of BatchJob . required predictions_url Optional [ str ] URL to predictions file. None artifacts_url Optional [ str ] URL to artifacts zip archive. None errors_url Optional [ str ] URL to errors file. None error_message Optional [ str ] Error message for request. None job_start_time Optional [ int ] Time when job started. None job_end_time Optional [ int ] Time when job completed. None Source code in hume/_batch/batch_job_result.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , * , configs : Dict [ ModelType , JobConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, JobConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time","title":"__init__()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_artifacts","text":"Download BatchJob artifacts zip archive. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts zip archive will be downloaded. None Source code in hume/_batch/batch_job_result.py 64 65 66 67 68 69 70 71 72 def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientError ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath )","title":"download_artifacts()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_errors","text":"Download BatchJob errors file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where errors will be downloaded. None Source code in hume/_batch/batch_job_result.py 74 75 76 77 78 79 80 81 82 def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientError ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath )","title":"download_errors()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_predictions","text":"Download BatchJob predictions file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where predictions will be downloaded. None Source code in hume/_batch/batch_job_result.py 54 55 56 57 58 59 60 61 62 def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientError ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath )","title":"download_predictions()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.from_response","text":"Construct a BatchJobResult from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobResult BatchJobResult A BatchJobResult based on a batch API job response. Source code in hume/_batch/batch_job_result.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . deserialize ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientError ( message ) from exc","title":"from_response()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_end_time","text":"Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 114 115 116 117 118 119 120 121 122 123 def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time )","title":"get_end_time()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_error_message","text":"Get any available error messages on the job. Returns: Type Description Optional [ str ] Optional[str]: A string with the error message if there was an error, otherwise None . Source code in hume/_batch/batch_job_result.py 84 85 86 87 88 89 90 def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message","title":"get_error_message()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_run_time","text":"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 92 93 94 95 96 97 98 99 100 101 def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None","title":"get_run_time()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_start_time","text":"Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_result.py 103 104 105 106 107 108 109 110 111 112 def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time )","title":"get_start_time()"},{"location":"batch/batch-job-status/","text":"Bases: Enum Batch job status. Source code in hume/_batch/batch_job_status.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class BatchJobStatus ( Enum ): \"\"\"Batch job status.\"\"\" COMPLETED = \"COMPLETED\" FAILED = \"FAILED\" IN_PROGRESS = \"IN_PROGRESS\" QUEUED = \"QUEUED\" @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ] @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) from_str ( status ) classmethod Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) is_terminal ( status ) classmethod Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"BatchJobStatus"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.from_str","text":"Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" )","title":"from_str()"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.is_terminal","text":"Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"is_terminal()"},{"location":"batch/batch-job/","text":"Batch job. Source code in hume/_batch/batch_job.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class BatchJob : \"\"\"Batch job.\"\"\" def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id ) def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientError` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) # pylint: disable=unused-argument @retry () def _await_complete ( self , timeout : int = 300 ) -> BatchJobResult : result = self . _client . get_job_result ( self . id ) if not BatchJobStatus . is_terminal ( result . status ): raise RetryIterError return result def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' __init__ ( client , job_id ) Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 18 19 20 21 22 23 24 25 26 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id __repr__ () Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 75 76 77 78 79 80 81 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' await_complete ( timeout = 300 ) Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientError will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientError` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) get_result () Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning the result. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 36 37 38 39 40 41 42 43 44 45 46 def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id ) get_status () Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 28 29 30 31 32 33 34 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status","title":"BatchJob"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__init__","text":"Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 18 19 20 21 22 23 24 25 26 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id","title":"__init__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__repr__","text":"Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 75 76 77 78 79 80 81 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")'","title":"__repr__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.await_complete","text":"Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientError will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientError` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout )","title":"await_complete()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_result","text":"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning the result. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 36 37 38 39 40 41 42 43 44 45 46 def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id )","title":"get_result()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_status","text":"Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 28 29 30 31 32 33 34 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status","title":"get_status()"},{"location":"batch/hume-batch-client/","text":"Bases: ClientBase Batch API client. Example from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job = client . submit_face ([ \"<your-image-url>\" ]) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" ) Source code in hume/_batch/hume_batch_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 class HumeBatchClient ( ClientBase ): \"\"\"Batch API client. Example: ```python from hume import HumeBatchClient client = HumeBatchClient(\"<your-api-key>\") job = client.submit_face([\"<your-image-url>\"]) print(job) print(\"Running...\") result = job.await_complete() result.download_predictions(\"predictions.json\") print(\"Predictions downloaded!\") ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( * args , ** kwargs ) def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientError: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs/ { job_id } \" f \"?apikey= { self . _api_key } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientError ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body ) def submit_face ( self , urls : List [ str ], fps_pred : Optional [ float ] = None , prob_threshold : Optional [ float ] = None , identify_faces : Optional [ bool ] = None , min_face_size : Optional [ float ] = None , ) -> BatchJob : \"\"\"Submit a new job for facial expression. Args: urls (List[str]): URLs to process. fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted from the response. prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. identify_faces (Optional[bool]): Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = FaceConfig ( fps_pred = fps_pred , prob_threshold = prob_threshold , identify_faces = identify_faces , min_face_size = min_face_size , ) return self . _submit ( urls , [ config ]) def submit_burst ( self , urls : List [ str ], ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = BurstConfig () return self . _submit ( urls , [ config ]) def submit_prosody ( self , urls : List [ str ], identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = ProsodyConfig ( identify_speakers = identify_speakers ) return self . _submit ( urls , [ config ]) def submit_language ( self , urls : List [ str ], granularity : Optional [ str ] = None , identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for language emotion. Args: urls (List[str]): URLs to process. granularity (Optional[str]): The granularity at which to generate predictions. Values are `word`, `sentence`, or `passage`. Default value is `word`. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = LanguageConfig ( granularity = granularity , identify_speakers = identify_speakers , ) return self . _submit ( urls , [ config ]) def _submit ( self , urls : List [ str ], configs : List [ JobConfigBase ]) -> BatchJob : request = self . _get_request ( configs , urls ) return self . start_job ( request ) def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) def start_job ( self , request_body : Any ) -> BatchJob : \"\"\"Start a batch job. Args: request_body (Any): JSON request body to be passed to the batch API. Raises: HumeClientError: If the batch job fails to start. Returns: BatchJob: A `BatchJob` that wraps the batch computation. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs\" f \"?apikey= { self . _api_key } \" ) response = requests . post ( endpoint , json = request_body , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . decoder . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( f \"Failed batch request: { response . text } \" ) if \"job_id\" not in body : if \"fault\" in body and \"faultstring\" in body [ \"fault\" ]: fault_string = body [ \"fault\" ][ \"faultstring\" ] raise HumeClientError ( f \"Could not start batch job: { fault_string } \" ) raise HumeClientError ( \"Unexpected error when starting batch job\" ) return BatchJob ( self , body [ \"job_id\" ]) @classmethod def _get_request ( cls , configs : List [ JobConfigBase ], urls : List [ str ]) -> Dict [ str , Any ]: model_requests = {} for config in configs : model_requests [ config . get_model_type () . value ] = config . serialize () return { \"models\" : model_requests , \"urls\" : urls , } __init__ ( * args , ** kwargs ) Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 40 41 42 43 44 45 46 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( * args , ** kwargs ) get_job ( job_id ) Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 183 184 185 186 187 188 189 190 191 192 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) get_job_result ( job_id ) Get the result of the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientError If the job result cannot be loaded. Returns: Name Type Description BatchJobResult BatchJobResult Batch job result. Source code in hume/_batch/hume_batch_client.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientError: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs/ { job_id } \" f \"?apikey= { self . _api_key } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientError ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body ) start_job ( request_body ) Start a batch job. Parameters: Name Type Description Default request_body Any JSON request body to be passed to the batch API. required Raises: Type Description HumeClientError If the batch job fails to start. Returns: Name Type Description BatchJob BatchJob A BatchJob that wraps the batch computation. Source code in hume/_batch/hume_batch_client.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def start_job ( self , request_body : Any ) -> BatchJob : \"\"\"Start a batch job. Args: request_body (Any): JSON request body to be passed to the batch API. Raises: HumeClientError: If the batch job fails to start. Returns: BatchJob: A `BatchJob` that wraps the batch computation. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs\" f \"?apikey= { self . _api_key } \" ) response = requests . post ( endpoint , json = request_body , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . decoder . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( f \"Failed batch request: { response . text } \" ) if \"job_id\" not in body : if \"fault\" in body and \"faultstring\" in body [ \"fault\" ]: fault_string = body [ \"fault\" ][ \"faultstring\" ] raise HumeClientError ( f \"Could not start batch job: { fault_string } \" ) raise HumeClientError ( \"Unexpected error when starting batch job\" ) return BatchJob ( self , body [ \"job_id\" ]) submit_burst ( urls ) Submit a new job for vocal bursts. Parameters: Name Type Description Default urls List [ str ] URLs to process. required Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def submit_burst ( self , urls : List [ str ], ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = BurstConfig () return self . _submit ( urls , [ config ]) submit_face ( urls , fps_pred = None , prob_threshold = None , identify_faces = None , min_face_size = None ) Submit a new job for facial expression. Parameters: Name Type Description Default urls List [ str ] URLs to process. required fps_pred Optional [ float ] Number of frames per second to process. Other frames will be omitted from the response. None prob_threshold Optional [ float ] Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. None identify_faces Optional [ bool ] Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. None min_face_size Optional [ float ] Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def submit_face ( self , urls : List [ str ], fps_pred : Optional [ float ] = None , prob_threshold : Optional [ float ] = None , identify_faces : Optional [ bool ] = None , min_face_size : Optional [ float ] = None , ) -> BatchJob : \"\"\"Submit a new job for facial expression. Args: urls (List[str]): URLs to process. fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted from the response. prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. identify_faces (Optional[bool]): Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = FaceConfig ( fps_pred = fps_pred , prob_threshold = prob_threshold , identify_faces = identify_faces , min_face_size = min_face_size , ) return self . _submit ( urls , [ config ]) submit_language ( urls , granularity = None , identify_speakers = None ) Submit a new job for language emotion. Parameters: Name Type Description Default urls List [ str ] URLs to process. required granularity Optional [ str ] The granularity at which to generate predictions. Values are word , sentence , or passage . Default value is word . None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def submit_language ( self , urls : List [ str ], granularity : Optional [ str ] = None , identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for language emotion. Args: urls (List[str]): URLs to process. granularity (Optional[str]): The granularity at which to generate predictions. Values are `word`, `sentence`, or `passage`. Default value is `word`. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = LanguageConfig ( granularity = granularity , identify_speakers = identify_speakers , ) return self . _submit ( urls , [ config ]) submit_prosody ( urls , identify_speakers = None ) Submit a new job for vocal bursts. Parameters: Name Type Description Default urls List [ str ] URLs to process. required identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def submit_prosody ( self , urls : List [ str ], identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = ProsodyConfig ( identify_speakers = identify_speakers ) return self . _submit ( urls , [ config ])","title":"HumeBatchClient"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.__init__","text":"Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 40 41 42 43 44 45 46 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( * args , ** kwargs )","title":"__init__()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job","text":"Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 183 184 185 186 187 188 189 190 191 192 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id )","title":"get_job()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_result","text":"Get the result of the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientError If the job result cannot be loaded. Returns: Name Type Description BatchJobResult BatchJobResult Batch job result. Source code in hume/_batch/hume_batch_client.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientError: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs/ { job_id } \" f \"?apikey= { self . _api_key } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientError ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body )","title":"get_job_result()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.start_job","text":"Start a batch job. Parameters: Name Type Description Default request_body Any JSON request body to be passed to the batch API. required Raises: Type Description HumeClientError If the batch job fails to start. Returns: Name Type Description BatchJob BatchJob A BatchJob that wraps the batch computation. Source code in hume/_batch/hume_batch_client.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def start_job ( self , request_body : Any ) -> BatchJob : \"\"\"Start a batch job. Args: request_body (Any): JSON request body to be passed to the batch API. Raises: HumeClientError: If the batch job fails to start. Returns: BatchJob: A `BatchJob` that wraps the batch computation. \"\"\" endpoint = ( f \" { self . _api_http_base_url } / { self . _api_version } / { ApiType . BATCH . value } /jobs\" f \"?apikey= { self . _api_key } \" ) response = requests . post ( endpoint , json = request_body , timeout = self . _DEFAULT_API_TIMEOUT ) try : body = response . json () except json . decoder . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientError ( f \"Failed batch request: { response . text } \" ) if \"job_id\" not in body : if \"fault\" in body and \"faultstring\" in body [ \"fault\" ]: fault_string = body [ \"fault\" ][ \"faultstring\" ] raise HumeClientError ( f \"Could not start batch job: { fault_string } \" ) raise HumeClientError ( \"Unexpected error when starting batch job\" ) return BatchJob ( self , body [ \"job_id\" ])","title":"start_job()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_burst","text":"Submit a new job for vocal bursts. Parameters: Name Type Description Default urls List [ str ] URLs to process. required Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def submit_burst ( self , urls : List [ str ], ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = BurstConfig () return self . _submit ( urls , [ config ])","title":"submit_burst()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_face","text":"Submit a new job for facial expression. Parameters: Name Type Description Default urls List [ str ] URLs to process. required fps_pred Optional [ float ] Number of frames per second to process. Other frames will be omitted from the response. None prob_threshold Optional [ float ] Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. None identify_faces Optional [ bool ] Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. None min_face_size Optional [ float ] Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def submit_face ( self , urls : List [ str ], fps_pred : Optional [ float ] = None , prob_threshold : Optional [ float ] = None , identify_faces : Optional [ bool ] = None , min_face_size : Optional [ float ] = None , ) -> BatchJob : \"\"\"Submit a new job for facial expression. Args: urls (List[str]): URLs to process. fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted from the response. prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. identify_faces (Optional[bool]): Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = FaceConfig ( fps_pred = fps_pred , prob_threshold = prob_threshold , identify_faces = identify_faces , min_face_size = min_face_size , ) return self . _submit ( urls , [ config ])","title":"submit_face()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_language","text":"Submit a new job for language emotion. Parameters: Name Type Description Default urls List [ str ] URLs to process. required granularity Optional [ str ] The granularity at which to generate predictions. Values are word , sentence , or passage . Default value is word . None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def submit_language ( self , urls : List [ str ], granularity : Optional [ str ] = None , identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for language emotion. Args: urls (List[str]): URLs to process. granularity (Optional[str]): The granularity at which to generate predictions. Values are `word`, `sentence`, or `passage`. Default value is `word`. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = LanguageConfig ( granularity = granularity , identify_speakers = identify_speakers , ) return self . _submit ( urls , [ config ])","title":"submit_language()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_prosody","text":"Submit a new job for vocal bursts. Parameters: Name Type Description Default urls List [ str ] URLs to process. required identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. None Raises: Type Description HumeClientError If the job fails. Returns: Name Type Description BatchJob BatchJob Batch job. Source code in hume/_batch/hume_batch_client.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def submit_prosody ( self , urls : List [ str ], identify_speakers : Optional [ bool ] = None , ) -> BatchJob : \"\"\"Submit a new job for vocal bursts. Args: urls (List[str]): URLs to process. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. Raises: HumeClientError: If the job fails. Returns: BatchJob: Batch job. \"\"\" config = ProsodyConfig ( identify_speakers = identify_speakers ) return self . _submit ( urls , [ config ])","title":"submit_prosody()"},{"location":"stream/hume-stream-client/","text":"Bases: ClientBase Streaming API client. Example import asyncio from hume import HumeStreamClient , StreamSocket from hume.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) configs = [ FaceConfig ( identify_faces = True )] async with client . connect ( configs ) as socket : socket : StreamSocket result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Source code in hume/_stream/hume_stream_client.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class HumeStreamClient ( ClientBase ): \"\"\"Streaming API client. Example: ```python import asyncio from hume import HumeStreamClient, StreamSocket from hume.config import FaceConfig async def main(): client = HumeStreamClient(\"<your-api-key>\") configs = [FaceConfig(identify_faces=True)] async with client.connect(configs) as socket: socket: StreamSocket result = await socket.send_file(\"<your-image-filepath>\") print(result) asyncio.run(main()) ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) super () . __init__ ( * args , ** kwargs ) @asynccontextmanager async def connect ( self , configs : List [ JobConfigBase ]) -> AsyncIterator : \"\"\"Connect to the streaming API. Args: configs (List[JobConfigBase]): List of job configs. \"\"\" uri = ( f \" { self . _api_ws_base_uri } / { self . _api_version } / { ApiType . STREAM . value } /multi\" f \"?apikey= { self . _api_key } \" ) try : # pylint: disable=no-member async with websockets . connect ( uri ) as protocol : # type: ignore[attr-defined] yield StreamSocket ( protocol , configs ) except websockets . exceptions . InvalidStatusCode as exc : message = \"Client initialized with invalid API key\" raise HumeClientError ( message ) from exc @asynccontextmanager async def _connect_to_models ( self , configs_dict : Any ) -> AsyncIterator : \"\"\"Connect to the streaming API with a single models configuration dict. Args: configs_dict (Any): Models configurations dict. This should be a dict from model name to model configuration dict. An empty dict uses the default configuration. \"\"\" configs = [] for model_name , config_dict in configs_dict . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . deserialize ( config_dict ) configs . append ( config ) async with self . connect ( configs ) as websocket : yield websocket __init__ ( * args , ** kwargs ) Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) super () . __init__ ( * args , ** kwargs ) connect ( configs ) async Connect to the streaming API. Parameters: Name Type Description Default configs List [ JobConfigBase ] List of job configs. required Source code in hume/_stream/hume_stream_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 @asynccontextmanager async def connect ( self , configs : List [ JobConfigBase ]) -> AsyncIterator : \"\"\"Connect to the streaming API. Args: configs (List[JobConfigBase]): List of job configs. \"\"\" uri = ( f \" { self . _api_ws_base_uri } / { self . _api_version } / { ApiType . STREAM . value } /multi\" f \"?apikey= { self . _api_key } \" ) try : # pylint: disable=no-member async with websockets . connect ( uri ) as protocol : # type: ignore[attr-defined] yield StreamSocket ( protocol , configs ) except websockets . exceptions . InvalidStatusCode as exc : message = \"Client initialized with invalid API key\" raise HumeClientError ( message ) from exc","title":"HumeStreamClient"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.__init__","text":"Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 47 48 49 50 51 52 53 54 55 56 def __init__ ( self , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) super () . __init__ ( * args , ** kwargs )","title":"__init__()"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.connect","text":"Connect to the streaming API. Parameters: Name Type Description Default configs List [ JobConfigBase ] List of job configs. required Source code in hume/_stream/hume_stream_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 @asynccontextmanager async def connect ( self , configs : List [ JobConfigBase ]) -> AsyncIterator : \"\"\"Connect to the streaming API. Args: configs (List[JobConfigBase]): List of job configs. \"\"\" uri = ( f \" { self . _api_ws_base_uri } / { self . _api_version } / { ApiType . STREAM . value } /multi\" f \"?apikey= { self . _api_key } \" ) try : # pylint: disable=no-member async with websockets . connect ( uri ) as protocol : # type: ignore[attr-defined] yield StreamSocket ( protocol , configs ) except websockets . exceptions . InvalidStatusCode as exc : message = \"Client initialized with invalid API key\" raise HumeClientError ( message ) from exc","title":"connect()"},{"location":"stream/stream-socket/","text":"Streaming socket connection. Source code in hume/_stream/stream_socket.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 class StreamSocket : \"\"\"Streaming socket connection.\"\"\" _FACE_LIMIT = 100 _N_LANDMARKS = 478 _N_SPATIAL = 3 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ JobConfigBase ], ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[JobConfigBase]): List of model configurations. Raises: HumeClientError: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) self . _configs = configs self . _protocol = protocol self . _serialized_configs = self . _serialize_configs ( configs ) @classmethod def _serialize_configs ( cls , configs : List [ JobConfigBase ]) -> Any : serialized = {} for config in configs : model_type = config . get_model_type () model_name = model_type . value serialized [ model_name ] = config . serialize () return serialized @classmethod def _file_to_bytes ( cls , filepath : Path ) -> bytes : with filepath . open ( 'rb' ) as f : return base64 . b64encode ( f . read ()) def _get_predictions ( self , response : str ) -> Any : try : json_response = json . loads ( response ) except json . JSONDecodeError as exc : raise HumeClientError ( \"Unexpected error when fetching streaming API predictions\" ) from exc return json_response async def _send_bytes_str ( self , bytes_str : str ) -> Any : \"\"\"Send raw bytes string on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_str (str): Raw bytes of media to send on socket connection converted to a string. Returns: Any: Predictions from the streaming API. \"\"\" payload = { \"data\" : bytes_str , \"models\" : self . _serialized_configs , } json_payload = json . dumps ( payload ) await self . _protocol . send ( json_payload ) response = await self . _protocol . recv () # Cast to str because websockets can send bytes, but we will always accept JSON strings response_str = str ( response ) return self . _get_predictions ( response_str ) async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_data = self . _file_to_bytes ( Path ( filepath )) return await self . send_bytes ( bytes_data ) async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientError: If the socket is configured with a modality other than language. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , LanguageConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_text is only supported when using a LanguageConfig.\" ) bytes_data = base64 . b64encode ( text . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientError: If the socket is configured with a modality other than facemesh. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , FacemeshConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_facemesh is only supported when using a FacemeshConfig.\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientError ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientError ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientError ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientError ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) __init__ ( protocol , configs ) Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ JobConfigBase ] List of model configurations. required Raises: Type Description HumeClientError If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ JobConfigBase ], ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[JobConfigBase]): List of model configurations. Raises: HumeClientError: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) self . _configs = configs self . _protocol = protocol self . _serialized_configs = self . _serialize_configs ( configs ) send_bytes ( bytes_data ) async Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) send_facemesh ( landmarks ) async Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientError If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientError: If the socket is configured with a modality other than facemesh. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , FacemeshConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_facemesh is only supported when using a FacemeshConfig.\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientError ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientError ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientError ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientError ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) send_file ( filepath ) async Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 106 107 108 109 110 111 112 113 114 115 116 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_data = self . _file_to_bytes ( Path ( filepath )) return await self . send_bytes ( bytes_data ) send_text ( text ) async Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientError If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientError: If the socket is configured with a modality other than language. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , LanguageConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_text is only supported when using a LanguageConfig.\" ) bytes_data = base64 . b64encode ( text . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data )","title":"StreamSocket"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.__init__","text":"Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ JobConfigBase ] List of model configurations. required Raises: Type Description HumeClientError If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ JobConfigBase ], ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[JobConfigBase]): List of model configurations. Raises: HumeClientError: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientError ( \"websockets package required to use HumeStreamClient\" ) self . _configs = configs self . _protocol = protocol self . _serialized_configs = self . _serialize_configs ( configs )","title":"__init__()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_bytes","text":"Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str )","title":"send_bytes()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_facemesh","text":"Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientError If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientError: If the socket is configured with a modality other than facemesh. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , FacemeshConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_facemesh is only supported when using a FacemeshConfig.\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientError ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientError ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientError ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientError ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data )","title":"send_facemesh()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_file","text":"Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 106 107 108 109 110 111 112 113 114 115 116 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Predictions from the streaming API. \"\"\" bytes_data = self . _file_to_bytes ( Path ( filepath )) return await self . send_bytes ( bytes_data )","title":"send_file()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_text","text":"Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientError If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Predictions from the streaming API. Source code in hume/_stream/stream_socket.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientError: If the socket is configured with a modality other than language. Returns: Any: Predictions from the streaming API. \"\"\" for config in self . _configs : if not isinstance ( config , LanguageConfig ): config_type = config . __class__ . __name__ raise HumeClientError ( f \"Socket configured with { config_type } . \" \"send_text is only supported when using a LanguageConfig.\" ) bytes_data = base64 . b64encode ( text . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data )","title":"send_text()"}]}