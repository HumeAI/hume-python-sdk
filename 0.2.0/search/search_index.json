{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Requirements Python versions 3.8 and 3.9 are supported Installation Basic installation: pip install hume Websocket and streaming features can be enabled with: pip install hume [ stream ] Basic Usage Submit a new batch job Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ config ]) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" ) Rehydrate a batch job from a job ID from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job ) Stream predictions over a websocket Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ config ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Other Resources Hume AI Homepage Platform Documentation API Reference Support The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#requirements","text":"Python versions 3.8 and 3.9 are supported","title":"Requirements"},{"location":"#installation","text":"Basic installation: pip install hume Websocket and streaming features can be enabled with: pip install hume [ stream ]","title":"Installation"},{"location":"#basic-usage","text":"","title":"Basic Usage"},{"location":"#submit-a-new-batch-job","text":"Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ config ]) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" )","title":"Submit a new batch job"},{"location":"#rehydrate-a-batch-job-from-a-job-id","text":"from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job )","title":"Rehydrate a batch job from a job ID"},{"location":"#stream-predictions-over-a-websocket","text":"Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ config ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ())","title":"Stream predictions over a websocket"},{"location":"#other-resources","text":"Hume AI Homepage Platform Documentation API Reference","title":"Other Resources"},{"location":"#support","text":"The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Support"},{"location":"batch/batch-job-result/","text":"Batch job result. Source code in hume/_batch/batch_job_result.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 class BatchJobResult : \"\"\"Batch job result.\"\"\" def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientException ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath ) def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientException ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath ) def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientException ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath ) def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time ) def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time ) @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc @classmethod def _get_invalid_response_message ( cls , response : Any ) -> str : response_str = json . dumps ( response ) message = f \"Could not parse response into BatchJobResult: { response_str } \" # Check for invalid API key if \"fault\" in response and \"faultstring\" in response [ \"fault\" ]: fault_string = response [ \"fault\" ][ \"faultstring\" ] if fault_string == \"Invalid ApiKey\" : message = \"HumeBatchClient initialized with invalid API key.\" return message __init__ ( * , configs , urls , status , predictions_url = None , artifacts_url = None , errors_url = None , error_message = None , job_start_time = None , job_end_time = None ) Construct a BatchJobResult. Parameters: Name Type Description Default configs Dict [ ModelType , ModelConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required status BatchJobStatus Status of BatchJob . required predictions_url Optional [ str ] URL to predictions file. None artifacts_url Optional [ str ] URL to artifacts zip archive. None errors_url Optional [ str ] URL to errors file. None error_message Optional [ str ] Error message for request. None job_start_time Optional [ int ] Time when job started. None job_end_time Optional [ int ] Time when job completed. None Source code in hume/_batch/batch_job_result.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time download_artifacts ( filepath = None ) Download BatchJob artifacts zip archive. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts zip archive will be downloaded. None Source code in hume/_batch/batch_job_result.py 64 65 66 67 68 69 70 71 72 def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientException ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath ) download_errors ( filepath = None ) Download BatchJob errors file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where errors will be downloaded. None Source code in hume/_batch/batch_job_result.py 74 75 76 77 78 79 80 81 82 def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientException ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath ) download_predictions ( filepath = None ) Download BatchJob predictions file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where predictions will be downloaded. None Source code in hume/_batch/batch_job_result.py 54 55 56 57 58 59 60 61 62 def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientException ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath ) from_response ( response ) classmethod Construct a BatchJobResult from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobResult BatchJobResult A BatchJobResult based on a batch API job response. Source code in hume/_batch/batch_job_result.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc get_end_time () Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 114 115 116 117 118 119 120 121 122 123 def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time ) get_error_message () Get any available error messages on the job. Returns: Type Description Optional [ str ] Optional[str]: A string with the error message if there was an error, otherwise None . Source code in hume/_batch/batch_job_result.py 84 85 86 87 88 89 90 def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message get_run_time () Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 92 93 94 95 96 97 98 99 100 101 def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None get_start_time () Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_result.py 103 104 105 106 107 108 109 110 111 112 def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time )","title":"BatchJobResult"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.__init__","text":"Construct a BatchJobResult. Parameters: Name Type Description Default configs Dict [ ModelType , ModelConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required status BatchJobStatus Status of BatchJob . required predictions_url Optional [ str ] URL to predictions file. None artifacts_url Optional [ str ] URL to artifacts zip archive. None errors_url Optional [ str ] URL to errors file. None error_message Optional [ str ] Error message for request. None job_start_time Optional [ int ] Time when job started. None job_end_time Optional [ int ] Time when job completed. None Source code in hume/_batch/batch_job_result.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], status : BatchJobStatus , predictions_url : Optional [ str ] = None , artifacts_url : Optional [ str ] = None , errors_url : Optional [ str ] = None , error_message : Optional [ str ] = None , job_start_time : Optional [ int ] = None , job_end_time : Optional [ int ] = None , ): \"\"\"Construct a BatchJobResult. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. status (BatchJobStatus): Status of `BatchJob`. predictions_url (Optional[str]): URL to predictions file. artifacts_url (Optional[str]): URL to artifacts zip archive. errors_url (Optional[str]): URL to errors file. error_message (Optional[str]): Error message for request. job_start_time (Optional[int]): Time when job started. job_end_time (Optional[int]): Time when job completed. \"\"\" self . configs = configs self . urls = urls self . status = status self . predictions_url = predictions_url self . artifacts_url = artifacts_url self . errors_url = errors_url self . error_message = error_message self . job_start_time = job_start_time self . job_end_time = job_end_time","title":"__init__()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_artifacts","text":"Download BatchJob artifacts zip archive. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts zip archive will be downloaded. None Source code in hume/_batch/batch_job_result.py 64 65 66 67 68 69 70 71 72 def download_artifacts ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` artifacts zip archive. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts zip archive will be downloaded. \"\"\" if self . artifacts_url is None : raise HumeClientException ( \"Could not download job artifacts. No artifacts found on job result.\" ) urlretrieve ( self . artifacts_url , filepath )","title":"download_artifacts()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_errors","text":"Download BatchJob errors file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where errors will be downloaded. None Source code in hume/_batch/batch_job_result.py 74 75 76 77 78 79 80 81 82 def download_errors ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` errors file. Args: filepath (Optional[Union[str, Path]]): Filepath where errors will be downloaded. \"\"\" if self . errors_url is None : raise HumeClientException ( \"Could not download job errors. No errors found on job result.\" ) urlretrieve ( self . errors_url , filepath )","title":"download_errors()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.download_predictions","text":"Download BatchJob predictions file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where predictions will be downloaded. None Source code in hume/_batch/batch_job_result.py 54 55 56 57 58 59 60 61 62 def download_predictions ( self , filepath : Optional [ Union [ str , Path ]] = None ) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Optional[Union[str, Path]]): Filepath where predictions will be downloaded. \"\"\" if self . predictions_url is None : raise HumeClientException ( \"Could not download job predictions. No predictions found on job result.\" ) urlretrieve ( self . predictions_url , filepath )","title":"download_predictions()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.from_response","text":"Construct a BatchJobResult from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobResult BatchJobResult A BatchJobResult based on a batch API job response. Source code in hume/_batch/batch_job_result.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobResult\" : \"\"\"Construct a `BatchJobResult` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobResult: A `BatchJobResult` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config kwargs = {} if \"completed\" in response : completed_dict = response [ \"completed\" ] kwargs [ \"artifacts_url\" ] = completed_dict [ \"artifacts_url\" ] kwargs [ \"errors_url\" ] = completed_dict [ \"errors_url\" ] kwargs [ \"predictions_url\" ] = completed_dict [ \"predictions_url\" ] if \"failed\" in response : failed_dict = response [ \"failed\" ] if \"message\" in failed_dict : kwargs [ \"error_message\" ] = failed_dict [ \"message\" ] if \"creation_timestamp\" in response : kwargs [ \"job_start_time\" ] = response [ \"creation_timestamp\" ] if \"completion_timestamp\" in response : kwargs [ \"job_end_time\" ] = response [ \"completion_timestamp\" ] return cls ( configs = configs , urls = request [ \"urls\" ], status = BatchJobStatus . from_str ( response [ \"status\" ]), ** kwargs , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc","title":"from_response()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_end_time","text":"Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 114 115 116 117 118 119 120 121 122 123 def get_end_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_end_time is None : return None return datetime . utcfromtimestamp ( self . job_end_time )","title":"get_end_time()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_error_message","text":"Get any available error messages on the job. Returns: Type Description Optional [ str ] Optional[str]: A string with the error message if there was an error, otherwise None . Source code in hume/_batch/batch_job_result.py 84 85 86 87 88 89 90 def get_error_message ( self ) -> Optional [ str ]: \"\"\"Get any available error messages on the job. Returns: Optional[str]: A string with the error message if there was an error, otherwise `None`. \"\"\" return self . error_message","title":"get_error_message()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_run_time","text":"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_result.py 92 93 94 95 96 97 98 99 100 101 def get_run_time ( self ) -> Optional [ int ]: \"\"\"Get the total time in seconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in seconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . job_start_time is not None and self . job_end_time is not None : return self . job_end_time - self . job_start_time return None","title":"get_run_time()"},{"location":"batch/batch-job-result/#hume._batch.batch_job_result.BatchJobResult.get_start_time","text":"Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_result.py 103 104 105 106 107 108 109 110 111 112 def get_start_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . job_start_time is None : return None return datetime . utcfromtimestamp ( self . job_start_time )","title":"get_start_time()"},{"location":"batch/batch-job-status/","text":"Bases: Enum Batch job status. Source code in hume/_batch/batch_job_status.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class BatchJobStatus ( Enum ): \"\"\"Batch job status.\"\"\" COMPLETED = \"COMPLETED\" FAILED = \"FAILED\" IN_PROGRESS = \"IN_PROGRESS\" QUEUED = \"QUEUED\" @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ] @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) from_str ( status ) classmethod Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) is_terminal ( status ) classmethod Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"BatchJobStatus"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.from_str","text":"Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" )","title":"from_str()"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.is_terminal","text":"Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"is_terminal()"},{"location":"batch/batch-job/","text":"Batch job. Source code in hume/_batch/batch_job.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 class BatchJob : \"\"\"Batch job.\"\"\" def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id ) def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) # pylint: disable=unused-argument @retry () def _await_complete ( self , timeout : int = 300 ) -> BatchJobResult : result = self . _client . get_job_result ( self . id ) if not BatchJobStatus . is_terminal ( result . status ): raise RetryIterError return result def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' __init__ ( client , job_id ) Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 15 16 17 18 19 20 21 22 23 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id __repr__ () Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 72 73 74 75 76 77 78 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' await_complete ( timeout = 300 ) Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientException will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) get_result () Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning the result. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 33 34 35 36 37 38 39 40 41 42 43 def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id ) get_status () Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 25 26 27 28 29 30 31 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status","title":"BatchJob"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__init__","text":"Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 15 16 17 18 19 20 21 22 23 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id","title":"__init__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__repr__","text":"Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 72 73 74 75 76 77 78 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")'","title":"__repr__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.await_complete","text":"Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientException will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def await_complete ( self , timeout : int = 300 ) -> BatchJobResult : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout )","title":"await_complete()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_result","text":"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning the result. Returns: Name Type Description BatchJobResult BatchJobResult The result of the BatchJob . Source code in hume/_batch/batch_job.py 33 34 35 36 37 38 39 40 41 42 43 def get_result ( self ) -> BatchJobResult : \"\"\"Get the result of the BatchJob. Note that the result of a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning the result. Returns: BatchJobResult: The result of the `BatchJob`. \"\"\" return self . _client . get_job_result ( self . id )","title":"get_result()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_status","text":"Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 25 26 27 28 29 30 31 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_result () . status","title":"get_status()"},{"location":"batch/hume-batch-client/","text":"Bases: ClientBase Batch API client. Example from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"<your-image-url>\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ configs ]) print ( job ) print ( \"Running...\" ) result = job . await_complete () result . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded!\" ) Source code in hume/_batch/hume_batch_client.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class HumeBatchClient ( ClientBase ): \"\"\"Batch API client. Example: ```python from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient(\"<your-api-key>\") urls = [\"<your-image-url>\"] config = FaceConfig(identify_faces=True) job = client.submit_job(urls, [configs]) print(job) print(\"Running...\") result = job.await_complete() result.download_predictions(\"predictions.json\") print(\"Predictions downloaded!\") ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs ) @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body ) def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ]) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _get_request ( configs , urls ) return self . _submit_job_from_request ( request ) @classmethod def _get_request ( cls , configs : List [ ModelConfigBase ], urls : List [ str ]) -> Dict [ str , Any ]: return { \"urls\" : urls , \"models\" : serialize_configs ( configs ), } def _submit_job_from_request ( self , request_body : Any ) -> BatchJob : \"\"\"Start a job for batch processing by passing a JSON request body. This request body should match the request body used by the batch API, including both the list of URLs and the models configuration. Args: request_body (Any): JSON request body to be passed to the batch API. Raises: HumeClientException: If the batch job fails to start. Returns: BatchJob: A `BatchJob` that wraps the batch computation. \"\"\" endpoint = self . _construct_endpoint ( \"jobs\" ) response = requests . post ( endpoint , json = request_body , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . decoder . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( f \"Failed batch request: { response . text } \" ) if \"job_id\" not in body : if \"fault\" in body and \"faultstring\" in body [ \"fault\" ]: fault = body [ \"fault\" ] fault_string = fault [ \"faultstring\" ] if \"detail\" in fault and \"errorcode\" in fault [ \"detail\" ]: detail = fault [ \"detail\" ] error_code = detail [ \"errorcode\" ] if \"InvalidApiKey\" in error_code : raise HumeClientException ( \"HumeBatchClient initialized with invalid API key.\" ) raise HumeClientException ( f \"Could not start batch job: { error_code } : { fault_string } \" ) raise HumeClientException ( f \"Could not start batch job: { fault_string } \" ) raise HumeClientException ( f \"Unexpected error when starting batch job: { body } \" ) return BatchJob ( self , body [ \"job_id\" ]) __init__ ( api_key , * args , ** kwargs ) Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 41 42 43 44 45 46 47 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs ) get_api_type () classmethod Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_batch/hume_batch_client.py 49 50 51 52 53 54 55 56 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH get_job ( job_id ) Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 88 89 90 91 92 93 94 95 96 97 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) get_job_result ( job_id ) Get the result of the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job result cannot be loaded. Returns: Name Type Description BatchJobResult BatchJobResult Batch job result. Source code in hume/_batch/hume_batch_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body ) submit_job ( urls , configs ) Submit a job for batch processing. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default urls List [ str ] List of URLs to media files to be processed. required configs List [ ModelConfigBase ] List of model config objects to run on each media URL. required Returns: Name Type Description BatchJob BatchJob The BatchJob representing the batch computation. Source code in hume/_batch/hume_batch_client.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ]) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _get_request ( configs , urls ) return self . _submit_job_from_request ( request )","title":"HumeBatchClient"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.__init__","text":"Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 41 42 43 44 45 46 47 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs )","title":"__init__()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_api_type","text":"Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_batch/hume_batch_client.py 49 50 51 52 53 54 55 56 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH","title":"get_api_type()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job","text":"Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 88 89 90 91 92 93 94 95 96 97 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id )","title":"get_job()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_result","text":"Get the result of the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job result cannot be loaded. Returns: Name Type Description BatchJobResult BatchJobResult Batch job result. Source code in hume/_batch/hume_batch_client.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def get_job_result ( self , job_id : str ) -> BatchJobResult : \"\"\"Get the result of the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job result cannot be loaded. Returns: BatchJobResult: Batch job result. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job result\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobResult . from_response ( body )","title":"get_job_result()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_job","text":"Submit a job for batch processing. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default urls List [ str ] List of URLs to media files to be processed. required configs List [ ModelConfigBase ] List of model config objects to run on each media URL. required Returns: Name Type Description BatchJob BatchJob The BatchJob representing the batch computation. Source code in hume/_batch/hume_batch_client.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ]) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _get_request ( configs , urls ) return self . _submit_job_from_request ( request )","title":"submit_job()"},{"location":"config/burst-config/","text":"Bases: ModelConfigBase [ BurstConfig ] Configuration for the vocal burst model. Source code in hume/models/config/burst_config.py 8 9 10 11 12 13 14 15 16 17 18 19 @dataclass class BurstConfig ( ModelConfigBase [ \"BurstConfig\" ]): \"\"\"Configuration for the vocal burst model.\"\"\" @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/burst_config.py 12 13 14 15 16 17 18 19 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST","title":"BurstConfig"},{"location":"config/burst-config/#hume.models.config.burst_config.BurstConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/burst_config.py 12 13 14 15 16 17 18 19 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST","title":"get_model_type()"},{"location":"config/face-config/","text":"Bases: ModelConfigBase [ FaceConfig ] Configuration for the facial expression model. Parameters: Name Type Description Default fps_pred Optional [ float ] Number of frames per second to process. Other frames will be omitted from the response. This configuration is not available for the streaming API. None prob_threshold Optional [ float ] Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. This configuration is not available for the streaming API. None identify_faces Optional [ bool ] Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. None min_face_size Optional [ float ] Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. This configuration is not available for the streaming API. None save_faces Optional [ bool ] Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is not available for the streaming API. None descriptions Optional [ Dict [ str , Any ]] Configuration for Descriptions predictions. If missing or null, no Descriptions predictions will be generated. None facs Optional [ Dict [ str , Any ]] Configuration for FACS predictions. If missing or null, no FACS predictions will be generated. None Source code in hume/models/config/face_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class FaceConfig ( ModelConfigBase [ \"FaceConfig\" ]): \"\"\"Configuration for the facial expression model. Args: fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted from the response. This configuration is not available for the streaming API. prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. This configuration is not available for the streaming API. identify_faces (Optional[bool]): Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. This configuration is not available for the streaming API. save_faces (Optional[bool]): Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is not available for the streaming API. descriptions (Optional[Dict[str, Any]]): Configuration for Descriptions predictions. If missing or null, no Descriptions predictions will be generated. facs (Optional[Dict[str, Any]]): Configuration for FACS predictions. If missing or null, no FACS predictions will be generated. \"\"\" fps_pred : Optional [ float ] = None prob_threshold : Optional [ float ] = None identify_faces : Optional [ bool ] = None min_face_size : Optional [ float ] = None save_faces : Optional [ bool ] = None descriptions : Optional [ Dict [ str , Any ]] = None facs : Optional [ Dict [ str , Any ]] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/face_config.py 44 45 46 47 48 49 50 51 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE","title":"FaceConfig"},{"location":"config/face-config/#hume.models.config.face_config.FaceConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/face_config.py 44 45 46 47 48 49 50 51 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE","title":"get_model_type()"},{"location":"config/facemesh-config/","text":"Bases: ModelConfigBase [ FacemeshConfig ] Configuration for the facemesh model. This model is not available for the batch API. Source code in hume/models/config/facemesh_config.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @dataclass class FacemeshConfig ( ModelConfigBase [ \"FacemeshConfig\" ]): \"\"\"Configuration for the facemesh model. This model is not available for the batch API. \"\"\" @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/facemesh_config.py 15 16 17 18 19 20 21 22 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH","title":"FacemeshConfig"},{"location":"config/facemesh-config/#hume.models.config.facemesh_config.FacemeshConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/facemesh_config.py 15 16 17 18 19 20 21 22 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH","title":"get_model_type()"},{"location":"config/language-config/","text":"Bases: ModelConfigBase [ LanguageConfig ] Configuration for the language emotion model. Parameters: Name Type Description Default language Optional [ str ] The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are zh , da , nl , en , en-AU , en-IN , en-NZ , en-GB , fr , fr-CA , de , hi , hi-Latn , id , it , ja , ko , no , pl , pt , pt-BR , pt-PT , ru , es , es-419 , sv , ta , tr , or uk . This configuration is not available for the streaming API. None granularity Optional [ str ] The granularity at which to generate predictions. Values are word , sentence , or passage . Default value is word . This configuration is not available for the streaming API. None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. None use_existing_partition Optional [ bool ] Whether to generate predictions for speech utterances (rather than the user specified granularity) for text created from audio transcripts. This configuration is not available for the streaming API. None sentiment Optional [ Dict [ str , Any ]] Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated. None toxicity Optional [ Dict [ str , Any ]] Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated. None Source code in hume/models/config/language_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class LanguageConfig ( ModelConfigBase [ \"LanguageConfig\" ]): \"\"\"Configuration for the language emotion model. Args: language (Optional[str]): The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are `zh`, `da`, `nl`, `en`, `en-AU`, `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`, `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`. This configuration is not available for the streaming API. granularity (Optional[str]): The granularity at which to generate predictions. Values are `word`, `sentence`, or `passage`. Default value is `word`. This configuration is not available for the streaming API. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. use_existing_partition: Whether to generate predictions for speech utterances (rather than the user specified granularity) for text created from audio transcripts. This configuration is not available for the streaming API. sentiment (Optional[Dict[str, Any]]): Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated. toxicity (Optional[Dict[str, Any]]): Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated. \"\"\" language : Optional [ str ] = None granularity : Optional [ str ] = None identify_speakers : Optional [ bool ] = None use_existing_partition : Optional [ bool ] = None sentiment : Optional [ Dict [ str , Any ]] = None toxicity : Optional [ Dict [ str , Any ]] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/language_config.py 44 45 46 47 48 49 50 51 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE","title":"LanguageConfig"},{"location":"config/language-config/#hume.models.config.language_config.LanguageConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/language_config.py 44 45 46 47 48 49 50 51 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE","title":"get_model_type()"},{"location":"config/ner-config/","text":"Bases: ModelConfigBase [ NerConfig ] Configuration for the named-entity emotion model. This model is not available for the streaming API. Parameters: Name Type Description Default language Optional [ str ] The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are zh , da , nl , en , en-AU , en-IN , en-NZ , en-GB , fr , fr-CA , de , hi , hi-Latn , id , it , ja , ko , no , pl , pt , pt-BR , pt-PT , ru , es , es-419 , sv , ta , tr , or uk . This configuration is not available for the streaming API. None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. None Source code in hume/models/config/ner_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @dataclass class NerConfig ( ModelConfigBase [ \"NerConfig\" ]): \"\"\"Configuration for the named-entity emotion model. This model is not available for the streaming API. Args: language (Optional[str]): The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are `zh`, `da`, `nl`, `en`, `en-AU`, `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`, `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`. This configuration is not available for the streaming API. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. \"\"\" language : Optional [ str ] = None identify_speakers : Optional [ bool ] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/ner_config.py 30 31 32 33 34 35 36 37 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER","title":"NerConfig"},{"location":"config/ner-config/#hume.models.config.ner_config.NerConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/ner_config.py 30 31 32 33 34 35 36 37 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER","title":"get_model_type()"},{"location":"config/prosody-config/","text":"Bases: ModelConfigBase [ ProsodyConfig ] Configuration for the speech prosody model. Parameters: Name Type Description Default language Optional [ str ] The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are zh , da , nl , en , en-AU , en-IN , en-NZ , en-GB , fr , fr-CA , de , hi , hi-Latn , id , it , ja , ko , no , pl , pt , pt-BR , pt-PT , ru , es , es-419 , sv , ta , tr , or uk . This configuration is not available for the streaming API. None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. None Source code in hume/models/config/prosody_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @dataclass class ProsodyConfig ( ModelConfigBase [ \"ProsodyConfig\" ]): \"\"\"Configuration for the speech prosody model. Args: language (Optional[str]): The BCP-47 tag (see above) of the language spoken in your media samples; If missing or null, it will be automatically detected. Values are `zh`, `da`, `nl`, `en`, `en-AU`, `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`, `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`. This configuration is not available for the streaming API. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is not available for the streaming API. \"\"\" language : Optional [ str ] = None identify_speakers : Optional [ bool ] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/prosody_config.py 28 29 30 31 32 33 34 35 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY","title":"ProsodyConfig"},{"location":"config/prosody-config/#hume.models.config.prosody_config.ProsodyConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/prosody_config.py 28 29 30 31 32 33 34 35 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY","title":"get_model_type()"},{"location":"stream/hume-stream-client/","text":"Bases: ClientBase Streaming API client. Example import asyncio from hume import HumeStreamClient , StreamSocket from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ configs ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Source code in hume/_stream/hume_stream_client.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class HumeStreamClient ( ClientBase ): \"\"\"Streaming API client. Example: ```python import asyncio from hume import HumeStreamClient, StreamSocket from hume.models.config import FaceConfig async def main(): client = HumeStreamClient(\"<your-api-key>\") config = FaceConfig(identify_faces=True) async with client.connect([configs]) as socket: result = await socket.send_file(\"<your-image-filepath>\") print(result) asyncio.run(main()) ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs ) @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc @asynccontextmanager async def _connect_with_configs_dict ( self , configs_dict : Any ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API with a single models configuration dict. Args: configs_dict (Any): Models configurations dict. This should be a dict from model name to model configuration dict. An empty dict uses the default configuration. \"\"\" configs = deserialize_configs ( configs_dict ) async with self . connect ( configs ) as websocket : yield websocket __init__ ( api_key , * args , ** kwargs ) Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs ) connect ( configs , stream_window_ms = None ) async Connect to the streaming API. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default configs List [ ModelConfigBase ] List of job configs. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Source code in hume/_stream/hume_stream_client.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc get_api_type () classmethod Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_stream/hume_stream_client.py 55 56 57 58 59 60 61 62 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM","title":"HumeStreamClient"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.__init__","text":"Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs )","title":"__init__()"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.connect","text":"Connect to the streaming API. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default configs List [ ModelConfigBase ] List of job configs. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Source code in hume/_stream/hume_stream_client.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc","title":"connect()"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.get_api_type","text":"Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_stream/hume_stream_client.py 55 56 57 58 59 60 61 62 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM","title":"get_api_type()"},{"location":"stream/stream-socket/","text":"Streaming socket connection. Source code in hume/_stream/stream_socket.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class StreamSocket : \"\"\"Streaming socket connection.\"\"\" _FACE_LIMIT = 100 _N_LANDMARKS = 478 _N_SPATIAL = 3 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs ) async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data ) async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload ) async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload ) async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload ) async def _send_bytes_str ( self , bytes_str : str ) -> Any : payload : Dict [ str , Any ] = { \"data\" : bytes_str , \"models\" : self . _serialized_configs , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload ) async def _send_payload ( self , payload : Dict [ str , Any ]) -> Any : request_message = json . dumps ( payload ) await self . _protocol . send ( request_message ) response_data = await self . _protocol . recv () # Cast to str because websockets can send bytes, but we will always accept JSON strings response_str = str ( response_data ) try : response = json . loads ( response_str ) except json . JSONDecodeError as exc : raise HumeClientException ( \"Unexpected error when fetching streaming API predictions\" ) from exc if \"error\" in response : error = response [ \"error\" ] code = response [ \"code\" ] raise HumeClientException . from_error ( code , error ) return response def _validate_configs_with_model_type ( self , config_type : Any , method_name : str ) -> None : for config in self . _configs : if not isinstance ( config , config_type ): config_name = config_type . __name__ invalid_config_name = config . __class__ . __name__ raise HumeClientException ( f \"Socket configured with { invalid_config_name } . \" f \" { method_name } is only supported when using a { config_name } .\" ) __init__ ( protocol , configs , stream_window_ms = None ) Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ ModelConfigBase ] List of model configurations. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Raises: Type Description HumeClientException If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs ) get_job_details () async Get details associated with the current streaming connection. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 161 162 163 164 165 166 167 168 169 170 async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload ) reset_stream () async Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload ) send_bytes ( bytes_data ) async Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) send_facemesh ( landmarks ) async Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientException If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) send_file ( filepath ) async Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 54 55 56 57 58 59 60 61 62 63 64 65 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data ) send_text ( text ) async Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientException If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload )","title":"StreamSocket"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.__init__","text":"Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ ModelConfigBase ] List of model configurations. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Raises: Type Description HumeClientException If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs )","title":"__init__()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.get_job_details","text":"Get details associated with the current streaming connection. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 161 162 163 164 165 166 167 168 169 170 async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload )","title":"get_job_details()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.reset_stream","text":"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload )","title":"reset_stream()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_bytes","text":"Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str )","title":"send_bytes()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_facemesh","text":"Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientException If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data )","title":"send_facemesh()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_file","text":"Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 54 55 56 57 58 59 60 61 62 63 64 65 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data )","title":"send_file()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_text","text":"Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientException If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload )","title":"send_text()"}]}