{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#requirements","title":"Requirements","text":"<p>Python versions 3.8 and 3.9 are supported</p>"},{"location":"#installation","title":"Installation","text":"<p>Basic installation:</p> <pre><code>pip install hume\n</code></pre> <p>WebSocket and streaming features can be enabled with:</p> <pre><code>pip install \"hume[stream]\"\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Jupyter example notebooks can be found in the Python SDK GitHub repo.</p>"},{"location":"#submit-a-new-batch-job","title":"Submit a new batch job","text":"<p>Note: Your personal API key can be found in the profile section of beta.hume.ai</p> <pre><code>from hume import HumeBatchClient\nfrom hume.models.config import FaceConfig\nfrom hume.models.config import ProsodyConfig\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\nurls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\nconfigs = [FaceConfig(identify_faces=True), ProsodyConfig()]\njob = client.submit_job(urls, configs)\nprint(job)\nprint(\"Running...\")\njob.await_complete()\njob.download_predictions(\"predictions.json\")\nprint(\"Predictions downloaded to predictions.json\")\njob.download_artifacts(\"artifacts.zip\")\nprint(\"Artifacts downloaded to artifacts.zip\")\n</code></pre> <p>Note: You can also supply a local filepath when submitting a batch job. Check it out in a Jupyter notebook here.</p>"},{"location":"#rehydrate-a-batch-job-from-a-job-id","title":"Rehydrate a batch job from a job ID","text":"<pre><code>from hume import HumeBatchClient\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\njob_id = \"&lt;your-job-id&gt;\"\njob = client.get_job(job_id)\nprint(job)\n</code></pre>"},{"location":"#stream-predictions-over-a-websocket","title":"Stream predictions over a WebSocket","text":"<p>Note: <code>pip install \"hume[stream]\"</code> is required to use WebSocket features</p> <pre><code>import asyncio\nfrom hume import HumeStreamClient\nfrom hume.models.config import BurstConfig\nfrom hume.models.config import ProsodyConfig\nasync def main():\nclient = HumeStreamClient(\"&lt;your-api-key&gt;\")\nconfigs = [BurstConfig(), ProsodyConfig()]\nasync with client.connect(configs) as socket:\nresult = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\nprint(result)\nasyncio.run(main())\n</code></pre>"},{"location":"#other-resources","title":"Other Resources","text":"<ul> <li>Hume AI Homepage</li> <li>Platform Documentation</li> <li>API Reference</li> </ul>"},{"location":"#support","title":"Support","text":"<p>The Python SDK is open source! More details can be found on GitHub.</p> <p>If you've found a bug with this SDK please open an issue!</p>"},{"location":"batch/batch-job-details/","title":"BatchJobDetails","text":"<p>Batch job details.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>class BatchJobDetails:\n\"\"\"Batch job details.\"\"\"\ndef __init__(\nself,\n*,\nconfigs: Dict[ModelType, ModelConfigBase],\nurls: List[str],\nfiles: List[str],\nstate: BatchJobState,\ncallback_url: Optional[str] = None,\nnotify: bool = False,\n):\n\"\"\"Construct a BatchJobDetails.\n        Args:\n            configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`.\n            urls (List[str]): URLs processed in the `BatchJob`.\n            files (List[str]): Files processed in the `BatchJob`.\n            state (BatchJobState): State of `BatchJob`.\n            callback_url (Optional[str]): A URL to which a POST request is sent upon job completion.\n            notify (bool): Whether an email notification should be sent upon job completion.\n        \"\"\"\nself.configs = configs\nself.urls = urls\nself.files = files\nself.state = state\nself.callback_url = callback_url\nself.notify = notify\n@classmethod\ndef from_response(cls, response: Any) -&gt; \"BatchJobDetails\":\n\"\"\"Construct a `BatchJobDetails` from a batch API job response.\n        Args:\n            response (Any): Batch API job response.\n        Returns:\n            BatchJobDetails: A `BatchJobDetails` based on a batch API job response.\n        \"\"\"\ntry:\nrequest = response[\"request\"]\nconfigs = {}\nfor model_name, config_dict in request[\"models\"].items():\nif config_dict is None:\ncontinue\nmodel_type = ModelType.from_str(model_name)\nconfig = config_from_model_type(model_type).from_dict(config_dict)\nconfigs[model_type] = config\nurls = request[\"urls\"]\nfiles = request[\"files\"]\ncallback_url = request[\"callback_url\"]\nnotify = request[\"notify\"]\nstate_dict = response[\"state\"]\nstate = BatchJobState(\nstatus=BatchJobStatus.from_str(state_dict[\"status\"]),\ncreated_timestamp_ms=state_dict.get(\"created_timestamp_ms\"),\nstarted_timestamp_ms=state_dict.get(\"started_timestamp_ms\"),\nended_timestamp_ms=state_dict.get(\"ended_timestamp_ms\"),\n)\nreturn cls(\nconfigs=configs,\nurls=urls,\nfiles=files,\nstate=state,\ncallback_url=callback_url,\nnotify=notify,\n)\n# pylint: disable=broad-except\nexcept Exception as exc:\nmessage = cls._get_invalid_response_message(response)\nraise HumeClientException(message) from exc\n@classmethod\ndef _get_invalid_response_message(cls, response: Any) -&gt; str:\nresponse_str = json.dumps(response)\nmessage = f\"Could not parse response into BatchJobDetails: {response_str}\"\n# Check for invalid API key\nif \"fault\" in response and \"faultstring\" in response[\"fault\"]:\nfault_string = response[\"fault\"][\"faultstring\"]\nif fault_string == \"Invalid ApiKey\":\nmessage = \"HumeBatchClient initialized with invalid API key.\"\nreturn message\ndef get_status(self) -&gt; BatchJobStatus:\n\"\"\"Get the status of the job.\n        Returns:\n            BatchJobStatus: The status of the `BatchJob`.\n        \"\"\"\nreturn self.state.status\ndef get_run_time_ms(self) -&gt; Optional[int]:\n\"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state.\n        Returns:\n            Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal\n                state then `None` is returned.\n        \"\"\"\nif self.state.started_timestamp_ms is not None and self.state.ended_timestamp_ms is not None:\nreturn self.state.ended_timestamp_ms - self.state.started_timestamp_ms\nreturn None\ndef get_created_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job was created.\n        Returns:\n            Optional[datetime]: Datetime when the job was created. If the job has not started\n                then `None` is returned.\n        \"\"\"\nif self.state.created_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.created_timestamp_ms / 1000)\ndef get_started_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job started running.\n        Returns:\n            Optional[datetime]: Datetime when the job started running. If the job has not started\n                then `None` is returned.\n        \"\"\"\nif self.state.started_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.started_timestamp_ms / 1000)\ndef get_ended_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job stopped running if the job is in a terminal state.\n        Returns:\n            Optional[datetime]: Datetime when the job started running. If the job is not in a terminal\n                state then `None` is returned.\n        \"\"\"\nif self.state.ended_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.ended_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.__init__","title":"<code>__init__(*, configs, urls, files, state, callback_url=None, notify=False)</code>","text":"<p>Construct a BatchJobDetails.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>Dict[ModelType, ModelConfigBase]</code> <p>Configurations for the <code>BatchJob</code>.</p> required <code>urls</code> <code>List[str]</code> <p>URLs processed in the <code>BatchJob</code>.</p> required <code>files</code> <code>List[str]</code> <p>Files processed in the <code>BatchJob</code>.</p> required <code>state</code> <code>BatchJobState</code> <p>State of <code>BatchJob</code>.</p> required <code>callback_url</code> <code>Optional[str]</code> <p>A URL to which a POST request is sent upon job completion.</p> <code>None</code> <code>notify</code> <code>bool</code> <p>Whether an email notification should be sent upon job completion.</p> <code>False</code> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def __init__(\nself,\n*,\nconfigs: Dict[ModelType, ModelConfigBase],\nurls: List[str],\nfiles: List[str],\nstate: BatchJobState,\ncallback_url: Optional[str] = None,\nnotify: bool = False,\n):\n\"\"\"Construct a BatchJobDetails.\n    Args:\n        configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`.\n        urls (List[str]): URLs processed in the `BatchJob`.\n        files (List[str]): Files processed in the `BatchJob`.\n        state (BatchJobState): State of `BatchJob`.\n        callback_url (Optional[str]): A URL to which a POST request is sent upon job completion.\n        notify (bool): Whether an email notification should be sent upon job completion.\n    \"\"\"\nself.configs = configs\nself.urls = urls\nself.files = files\nself.state = state\nself.callback_url = callback_url\nself.notify = notify\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.from_response","title":"<code>from_response(response)</code>  <code>classmethod</code>","text":"<p>Construct a <code>BatchJobDetails</code> from a batch API job response.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>Any</code> <p>Batch API job response.</p> required <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>A <code>BatchJobDetails</code> based on a batch API job response.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>@classmethod\ndef from_response(cls, response: Any) -&gt; \"BatchJobDetails\":\n\"\"\"Construct a `BatchJobDetails` from a batch API job response.\n    Args:\n        response (Any): Batch API job response.\n    Returns:\n        BatchJobDetails: A `BatchJobDetails` based on a batch API job response.\n    \"\"\"\ntry:\nrequest = response[\"request\"]\nconfigs = {}\nfor model_name, config_dict in request[\"models\"].items():\nif config_dict is None:\ncontinue\nmodel_type = ModelType.from_str(model_name)\nconfig = config_from_model_type(model_type).from_dict(config_dict)\nconfigs[model_type] = config\nurls = request[\"urls\"]\nfiles = request[\"files\"]\ncallback_url = request[\"callback_url\"]\nnotify = request[\"notify\"]\nstate_dict = response[\"state\"]\nstate = BatchJobState(\nstatus=BatchJobStatus.from_str(state_dict[\"status\"]),\ncreated_timestamp_ms=state_dict.get(\"created_timestamp_ms\"),\nstarted_timestamp_ms=state_dict.get(\"started_timestamp_ms\"),\nended_timestamp_ms=state_dict.get(\"ended_timestamp_ms\"),\n)\nreturn cls(\nconfigs=configs,\nurls=urls,\nfiles=files,\nstate=state,\ncallback_url=callback_url,\nnotify=notify,\n)\n# pylint: disable=broad-except\nexcept Exception as exc:\nmessage = cls._get_invalid_response_message(response)\nraise HumeClientException(message) from exc\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_created_time","title":"<code>get_created_time()</code>","text":"<p>Get the time the job was created.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job was created. If the job has not started then <code>None</code> is returned.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def get_created_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job was created.\n    Returns:\n        Optional[datetime]: Datetime when the job was created. If the job has not started\n            then `None` is returned.\n    \"\"\"\nif self.state.created_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.created_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_ended_time","title":"<code>get_ended_time()</code>","text":"<p>Get the time the job stopped running if the job is in a terminal state.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then <code>None</code> is returned.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def get_ended_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job stopped running if the job is in a terminal state.\n    Returns:\n        Optional[datetime]: Datetime when the job started running. If the job is not in a terminal\n            state then `None` is returned.\n    \"\"\"\nif self.state.ended_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.ended_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_run_time_ms","title":"<code>get_run_time_ms()</code>","text":"<p>Get the total time in milliseconds it took for the job to run if the job is in a terminal state.</p> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then <code>None</code> is returned.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def get_run_time_ms(self) -&gt; Optional[int]:\n\"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state.\n    Returns:\n        Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal\n            state then `None` is returned.\n    \"\"\"\nif self.state.started_timestamp_ms is not None and self.state.ended_timestamp_ms is not None:\nreturn self.state.ended_timestamp_ms - self.state.started_timestamp_ms\nreturn None\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_started_time","title":"<code>get_started_time()</code>","text":"<p>Get the time the job started running.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job started running. If the job has not started then <code>None</code> is returned.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def get_started_time(self) -&gt; Optional[datetime]:\n\"\"\"Get the time the job started running.\n    Returns:\n        Optional[datetime]: Datetime when the job started running. If the job has not started\n            then `None` is returned.\n    \"\"\"\nif self.state.started_timestamp_ms is None:\nreturn None\nreturn datetime.utcfromtimestamp(self.state.started_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the job.</p> <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The status of the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job_details.py</code> <pre><code>def get_status(self) -&gt; BatchJobStatus:\n\"\"\"Get the status of the job.\n    Returns:\n        BatchJobStatus: The status of the `BatchJob`.\n    \"\"\"\nreturn self.state.status\n</code></pre>"},{"location":"batch/batch-job-state/","title":"BatchJobState","text":"<p>Batch job state.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>BatchJobStatus</code> <p>Status of the batch job.</p> required <code>created_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job was created.</p> required <code>started_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job started.</p> required <code>ended_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job ended.</p> required Source code in <code>hume/_batch/batch_job_state.py</code> <pre><code>@dataclass\nclass BatchJobState:\n\"\"\"Batch job state.\n    Args:\n        status (BatchJobStatus): Status of the batch job.\n        created_timestamp_ms (Optional[int]): Time when job was created.\n        started_timestamp_ms (Optional[int]): Time when job started.\n        ended_timestamp_ms (Optional[int]): Time when job ended.\n    \"\"\"\nstatus: BatchJobStatus\ncreated_timestamp_ms: Optional[int]\nstarted_timestamp_ms: Optional[int]\nended_timestamp_ms: Optional[int]\n</code></pre>"},{"location":"batch/batch-job-status/","title":"BatchJobStatus","text":"<p>         Bases: <code>Enum</code></p> <p>Batch job status.</p> Source code in <code>hume/_batch/batch_job_status.py</code> <pre><code>class BatchJobStatus(Enum):\n\"\"\"Batch job status.\"\"\"\nCOMPLETED = \"COMPLETED\"\nFAILED = \"FAILED\"\nIN_PROGRESS = \"IN_PROGRESS\"\nQUEUED = \"QUEUED\"\n@classmethod\ndef is_terminal(cls, status: \"BatchJobStatus\") -&gt; bool:\n\"\"\"Check if a status is \"terminal\".\n        Args:\n            status (BatchJobStatus): Status to check.\n        Returns:\n            bool: Whether the status is \"terminal\".\n        \"\"\"\nreturn status in [cls.COMPLETED, cls.FAILED]\n@classmethod\ndef from_str(cls, status: str) -&gt; \"BatchJobStatus\":\n\"\"\"Convert a status to a string.\n        Args:\n            status (str): Status to convert.\n        Returns:\n            BatchJobStatus: The enum variant for the given string.\n        \"\"\"\nfor _, enum_value in cls.__members__.items():\nif enum_value.value == status:\nreturn enum_value\nraise ValueError(f\"Unknown status '{status}'\")\n</code></pre>"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.from_str","title":"<code>from_str(status)</code>  <code>classmethod</code>","text":"<p>Convert a status to a string.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>str</code> <p>Status to convert.</p> required <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The enum variant for the given string.</p> Source code in <code>hume/_batch/batch_job_status.py</code> <pre><code>@classmethod\ndef from_str(cls, status: str) -&gt; \"BatchJobStatus\":\n\"\"\"Convert a status to a string.\n    Args:\n        status (str): Status to convert.\n    Returns:\n        BatchJobStatus: The enum variant for the given string.\n    \"\"\"\nfor _, enum_value in cls.__members__.items():\nif enum_value.value == status:\nreturn enum_value\nraise ValueError(f\"Unknown status '{status}'\")\n</code></pre>"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.is_terminal","title":"<code>is_terminal(status)</code>  <code>classmethod</code>","text":"<p>Check if a status is \"terminal\".</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>BatchJobStatus</code> <p>Status to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the status is \"terminal\".</p> Source code in <code>hume/_batch/batch_job_status.py</code> <pre><code>@classmethod\ndef is_terminal(cls, status: \"BatchJobStatus\") -&gt; bool:\n\"\"\"Check if a status is \"terminal\".\n    Args:\n        status (BatchJobStatus): Status to check.\n    Returns:\n        bool: Whether the status is \"terminal\".\n    \"\"\"\nreturn status in [cls.COMPLETED, cls.FAILED]\n</code></pre>"},{"location":"batch/batch-job/","title":"BatchJob","text":"<p>Batch job.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>class BatchJob:\n\"\"\"Batch job.\"\"\"\ndef __init__(self, client: \"HumeBatchClient\", job_id: str):\n\"\"\"Construct a BatchJob.\n        Args:\n            client (HumeBatchClient): HumeBatchClient instance.\n            job_id (str): Job ID.\n        \"\"\"\nself._client = client\nself.id = job_id\ndef get_status(self) -&gt; BatchJobStatus:\n\"\"\"Get the status of the job.\n        Returns:\n            BatchJobStatus: The status of the `BatchJob`.\n        \"\"\"\nreturn self.get_details().state.status\ndef get_predictions(self) -&gt; Any:\n\"\"\"Get `BatchJob` predictions.\n        Returns:\n            Any: Predictions for the `BatchJob`.\n        \"\"\"\nreturn self._client.get_job_predictions(self.id)\ndef download_predictions(self, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download `BatchJob` predictions file.\n        Args:\n            filepath (Union[str, Path]): Filepath where predictions will be downloaded.\n        \"\"\"\npredictions = self.get_predictions()\nwith Path(filepath).open(\"w\") as f:\njson.dump(predictions, f)\ndef download_artifacts(self, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download `BatchJob` artifacts zip file.\n        Args:\n            filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n        \"\"\"\nself._client.download_job_artifacts(self.id, filepath)\ndef get_details(self) -&gt; BatchJobDetails:\n\"\"\"Get details for the BatchJob.\n        Note that the details for a job may be fetched before the job has completed.\n        You may want to use `job.await_complete()` which will wait for the job to\n        reach a terminal state before returning.\n        Returns:\n            BatchJobDetails: Details for the `BatchJob`.\n        \"\"\"\nreturn self._client.get_job_details(self.id)\ndef await_complete(self, timeout: int = 300) -&gt; BatchJobDetails:\n\"\"\"Block until the job has reached a terminal status.\n        Args:\n            timeout (int): Maximum time in seconds to await. If the timeout is reached\n                before the job reaches a terminal state the job will continue to be processed,\n                but a `HumeClientException` will be raised to the caller of `await_complete`.\n        Raises:\n            ValueError: If the timeout is not valid.\n        Returns:\n            BatchJobDetails: Details for the `BatchJob`.\n        \"\"\"\nif timeout &lt; 1:\nraise ValueError(\"timeout must be at least 1 second\")\nreturn self._await_complete(timeout=timeout)\n# pylint: disable=unused-argument\n@retry()\ndef _await_complete(self, timeout: int = 300) -&gt; BatchJobDetails:\ndetails = self._client.get_job_details(self.id)\nif not BatchJobStatus.is_terminal(details.state.status):\nraise RetryIterError\nreturn details\ndef __repr__(self) -&gt; str:\n\"\"\"Get the string representation of the `BatchJob`.\n        Returns:\n            The the string representation of the `BatchJob`.\n        \"\"\"\nreturn f'Job(id=\"{self.id}\")'\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__init__","title":"<code>__init__(client, job_id)</code>","text":"<p>Construct a BatchJob.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>HumeBatchClient</code> <p>HumeBatchClient instance.</p> required <code>job_id</code> <code>str</code> <p>Job ID.</p> required Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def __init__(self, client: \"HumeBatchClient\", job_id: str):\n\"\"\"Construct a BatchJob.\n    Args:\n        client (HumeBatchClient): HumeBatchClient instance.\n        job_id (str): Job ID.\n    \"\"\"\nself._client = client\nself.id = job_id\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__repr__","title":"<code>__repr__()</code>","text":"<p>Get the string representation of the <code>BatchJob</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p>The the string representation of the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def __repr__(self) -&gt; str:\n\"\"\"Get the string representation of the `BatchJob`.\n    Returns:\n        The the string representation of the `BatchJob`.\n    \"\"\"\nreturn f'Job(id=\"{self.id}\")'\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.await_complete","title":"<code>await_complete(timeout=300)</code>","text":"<p>Block until the job has reached a terminal status.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a <code>HumeClientException</code> will be raised to the caller of <code>await_complete</code>.</p> <code>300</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the timeout is not valid.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Details for the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def await_complete(self, timeout: int = 300) -&gt; BatchJobDetails:\n\"\"\"Block until the job has reached a terminal status.\n    Args:\n        timeout (int): Maximum time in seconds to await. If the timeout is reached\n            before the job reaches a terminal state the job will continue to be processed,\n            but a `HumeClientException` will be raised to the caller of `await_complete`.\n    Raises:\n        ValueError: If the timeout is not valid.\n    Returns:\n        BatchJobDetails: Details for the `BatchJob`.\n    \"\"\"\nif timeout &lt; 1:\nraise ValueError(\"timeout must be at least 1 second\")\nreturn self._await_complete(timeout=timeout)\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.download_artifacts","title":"<code>download_artifacts(filepath)</code>","text":"<p>Download <code>BatchJob</code> artifacts zip file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[Union[str, Path]]</code> <p>Filepath where artifacts will be downloaded.</p> required Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def download_artifacts(self, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download `BatchJob` artifacts zip file.\n    Args:\n        filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n    \"\"\"\nself._client.download_job_artifacts(self.id, filepath)\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.download_predictions","title":"<code>download_predictions(filepath)</code>","text":"<p>Download <code>BatchJob</code> predictions file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Filepath where predictions will be downloaded.</p> required Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def download_predictions(self, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download `BatchJob` predictions file.\n    Args:\n        filepath (Union[str, Path]): Filepath where predictions will be downloaded.\n    \"\"\"\npredictions = self.get_predictions()\nwith Path(filepath).open(\"w\") as f:\njson.dump(predictions, f)\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_details","title":"<code>get_details()</code>","text":"<p>Get details for the BatchJob.</p> <p>Note that the details for a job may be fetched before the job has completed. You may want to use <code>job.await_complete()</code> which will wait for the job to reach a terminal state before returning.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Details for the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def get_details(self) -&gt; BatchJobDetails:\n\"\"\"Get details for the BatchJob.\n    Note that the details for a job may be fetched before the job has completed.\n    You may want to use `job.await_complete()` which will wait for the job to\n    reach a terminal state before returning.\n    Returns:\n        BatchJobDetails: Details for the `BatchJob`.\n    \"\"\"\nreturn self._client.get_job_details(self.id)\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_predictions","title":"<code>get_predictions()</code>","text":"<p>Get <code>BatchJob</code> predictions.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Predictions for the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def get_predictions(self) -&gt; Any:\n\"\"\"Get `BatchJob` predictions.\n    Returns:\n        Any: Predictions for the `BatchJob`.\n    \"\"\"\nreturn self._client.get_job_predictions(self.id)\n</code></pre>"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the job.</p> <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The status of the <code>BatchJob</code>.</p> Source code in <code>hume/_batch/batch_job.py</code> <pre><code>def get_status(self) -&gt; BatchJobStatus:\n\"\"\"Get the status of the job.\n    Returns:\n        BatchJobStatus: The status of the `BatchJob`.\n    \"\"\"\nreturn self.get_details().state.status\n</code></pre>"},{"location":"batch/hume-batch-client/","title":"HumeBatchClient","text":"<p>         Bases: <code>ClientBase</code></p> <p>Batch API client.</p> Example <pre><code>from hume import HumeBatchClient\nfrom hume.models.config import FaceConfig\nfrom hume.models.config import ProsodyConfig\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\nurls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\nconfigs = [FaceConfig(identify_faces=True), ProsodyConfig()]\njob = client.submit_job(urls, configs)\nprint(job)\nprint(\"Running...\")\njob.await_complete()\njob.download_predictions(\"predictions.json\")\nprint(\"Predictions downloaded to predictions.json\")\njob.download_artifacts(\"artifacts.zip\")\nprint(\"Artifacts downloaded to artifacts.zip\")\n</code></pre> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>class HumeBatchClient(ClientBase):\n\"\"\"Batch API client.\n    Example:\n        ```python\n        from hume import HumeBatchClient\n        from hume.models.config import FaceConfig\n        from hume.models.config import ProsodyConfig\n        client = HumeBatchClient(\"&lt;your-api-key&gt;\")\n        urls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\n        configs = [FaceConfig(identify_faces=True), ProsodyConfig()]\n        job = client.submit_job(urls, configs)\n        print(job)\n        print(\"Running...\")\n        job.await_complete()\n        job.download_predictions(\"predictions.json\")\n        print(\"Predictions downloaded to predictions.json\")\n        job.download_artifacts(\"artifacts.zip\")\n        print(\"Artifacts downloaded to artifacts.zip\")\n        ```\n    \"\"\"\ndef __init__(\nself,\napi_key: str,\n*args: Any,\ntimeout: int = 10,\n**kwargs: Any,\n):\n\"\"\"Construct a HumeBatchClient.\n        Args:\n            api_key (str): Hume API key.\n            timeout (int): Time in seconds before canceling long-running Hume API requests.\n        \"\"\"\nself._timeout = timeout\nself._session = Session()\nsuper().__init__(api_key, *args, **kwargs)\n@classmethod\ndef get_api_type(cls) -&gt; ApiType:\n\"\"\"Get the ApiType of the client.\n        Returns:\n            ApiType: API type of the client.\n        \"\"\"\nreturn ApiType.BATCH\ndef get_job(self, job_id: str) -&gt; BatchJob:\n\"\"\"Rehydrate a job based on a Job ID.\n        Args:\n            job_id (str): ID of the job to rehydrate.\n        Returns:\n            BatchJob: Job associated with the given ID.\n        \"\"\"\nreturn BatchJob(self, job_id)\ndef submit_job(\nself,\nurls: List[str],\nconfigs: List[ModelConfigBase],\ntranscription_config: Optional[TranscriptionConfig] = None,\ncallback_url: Optional[str] = None,\nnotify: Optional[bool] = None,\nfiles: Optional[List[Union[str, Path]]] = None,\n) -&gt; BatchJob:\n\"\"\"Submit a job for batch processing.\n        Note: Only one config per model type should be passed.\n            If more than one config is passed for a given model type, only the last config will be used.\n        Args:\n            urls (List[str]): List of URLs to media files to be processed.\n            configs (List[ModelConfigBase]): List of model config objects to run on each media URL.\n            transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object.\n            callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion.\n            notify (Optional[bool]): Wether an email notification should be sent upon job completion.\n            files (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n        Returns:\n            BatchJob: The `BatchJob` representing the batch computation.\n        \"\"\"\nrequest = self._construct_request(configs, urls, transcription_config, callback_url, notify)\nreturn self._submit_job(request, files)\ndef get_job_details(self, job_id: str) -&gt; BatchJobDetails:\n\"\"\"Get details for the batch job.\n        Args:\n            job_id (str): Job ID.\n        Raises:\n            HumeClientException: If the job details cannot be loaded.\n        Returns:\n            BatchJobDetails: Batch job details.\n        \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\ntry:\nbody = response.json()\nexcept json.JSONDecodeError:\n# pylint: disable=raise-missing-from\nraise HumeClientException(\"Unexpected error when getting job details\")\nif \"message\" in body and body[\"message\"] == \"job not found\":\nraise HumeClientException(f\"Could not find a job with ID {job_id}\")\nreturn BatchJobDetails.from_response(body)\ndef get_job_predictions(self, job_id: str) -&gt; Any:\n\"\"\"Get a batch job's predictions.\n        Args:\n            job_id (str): Job ID.\n        Raises:\n            HumeClientException: If the job predictions cannot be loaded.\n        Returns:\n            Any: Batch job predictions.\n        \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}/predictions\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\ntry:\nbody = response.json()\nexcept json.JSONDecodeError:\n# pylint: disable=raise-missing-from\nraise HumeClientException(\"Unexpected error when getting job predictions\")\nif \"message\" in body and body[\"message\"] == \"job not found\":\nraise HumeClientException(f\"Could not find a job with ID {job_id}\")\nreturn body\ndef download_job_artifacts(self, job_id: str, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download a batch job's artifacts as a zip file.\n        Args:\n            job_id (str): Job ID.\n            filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n        Raises:\n            HumeClientException: If the job artifacts cannot be loaded.\n        Returns:\n            Any: Batch job artifacts.\n        \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}/artifacts\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\nwith Path(filepath).open(\"wb\") as f:\nf.write(response.content)\n@classmethod\ndef _construct_request(\ncls,\nconfigs: List[ModelConfigBase],\nurls: List[str],\ntranscription_config: Optional[TranscriptionConfig],\ncallback_url: Optional[str],\nnotify: Optional[bool],\n) -&gt; Dict[str, Any]:\nrequest: Dict[str, Any] = {\n\"urls\": urls,\n\"models\": serialize_configs(configs),\n}\nif transcription_config is not None:\nrequest[\"transcription\"] = transcription_config.to_dict()\nif callback_url is not None:\nrequest[\"callback_url\"] = callback_url\nif notify is not None:\nrequest[\"notify\"] = notify\nreturn request\ndef _submit_job(\nself,\nrequest_body: Any,\nfilepaths: Optional[List[Union[str, Path]]],\n) -&gt; BatchJob:\n\"\"\"Start a job for batch processing by passing a JSON request body.\n        This request body should match the request body used by the batch API,\n        including both the list of URLs and the models configuration.\n        Args:\n            request_body (Any): JSON request body to be passed to the batch API.\n            filepaths (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n        Raises:\n            HumeClientException: If the batch job fails to start.\n        Returns:\n            BatchJob: A `BatchJob` that wraps the batch computation.\n        \"\"\"\nendpoint = self._construct_endpoint(\"jobs\")\nif filepaths is None:\nresponse = self._session.post(\nendpoint,\njson=request_body,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\nelse:\nform_data = self._get_multipart_form_data(request_body, filepaths)\nresponse = self._session.post(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\nfiles=form_data,\n)\ntry:\nbody = response.json()\nexcept json.decoder.JSONDecodeError:\n# pylint: disable=raise-missing-from\nraise HumeClientException(f\"Failed batch request: {response.text}\")\nif \"job_id\" not in body:\nif \"fault\" in body and \"faultstring\" in body[\"fault\"]:\nfault = body[\"fault\"]\nfault_string = fault[\"faultstring\"]\nif \"detail\" in fault and \"errorcode\" in fault[\"detail\"]:\ndetail = fault[\"detail\"]\nerror_code = detail[\"errorcode\"]\nif \"InvalidApiKey\" in error_code:\nraise HumeClientException(\"HumeBatchClient initialized with invalid API key.\")\nraise HumeClientException(f\"Could not start batch job: {error_code}: {fault_string}\")\nraise HumeClientException(f\"Could not start batch job: {fault_string}\")\nraise HumeClientException(f\"Unexpected error when starting batch job: {body}\")\nreturn BatchJob(self, body[\"job_id\"])\ndef _get_multipart_form_data(\nself,\nrequest_body: Any,\nfilepaths: List[Union[str, Path]],\n) -&gt; List[Tuple[str, Union[bytes, Tuple[str, bytes]]]]:\n\"\"\"Convert a list of filepaths into a list of multipart form data.\n        Multipart form data allows the client to attach files to the POST request,\n        including both the raw file bytes and the filename.\n        Args:\n            request_body (Any): JSON request body to be passed to the batch API.\n            filepaths (List[Union[str, Path]]): List of paths to files on the local disk to be processed.\n        Returns:\n            List[Tuple[str, Union[bytes, Tuple[str, bytes]]]]: A list of tuples representing\n                the multipart form data for the POST request.\n        \"\"\"\nform_data: List[Tuple[str, Union[bytes, Tuple[str, bytes]]]] = []\nfor filepath in filepaths:\npath = Path(filepath)\npost_file = (\"file\", (path.name, path.read_bytes()))\nform_data.append(post_file)\nform_data.append((\"json\", json.dumps(request_body).encode(\"utf-8\")))\nreturn form_data\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.__init__","title":"<code>__init__(api_key, *args, timeout=10, **kwargs)</code>","text":"<p>Construct a HumeBatchClient.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Hume API key.</p> required <code>timeout</code> <code>int</code> <p>Time in seconds before canceling long-running Hume API requests.</p> <code>10</code> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def __init__(\nself,\napi_key: str,\n*args: Any,\ntimeout: int = 10,\n**kwargs: Any,\n):\n\"\"\"Construct a HumeBatchClient.\n    Args:\n        api_key (str): Hume API key.\n        timeout (int): Time in seconds before canceling long-running Hume API requests.\n    \"\"\"\nself._timeout = timeout\nself._session = Session()\nsuper().__init__(api_key, *args, **kwargs)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.download_job_artifacts","title":"<code>download_job_artifacts(job_id, filepath)</code>","text":"<p>Download a batch job's artifacts as a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <code>filepath</code> <code>Optional[Union[str, Path]]</code> <p>Filepath where artifacts will be downloaded.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job artifacts cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>None</code> <p>Batch job artifacts.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def download_job_artifacts(self, job_id: str, filepath: Union[str, Path]) -&gt; None:\n\"\"\"Download a batch job's artifacts as a zip file.\n    Args:\n        job_id (str): Job ID.\n        filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n    Raises:\n        HumeClientException: If the job artifacts cannot be loaded.\n    Returns:\n        Any: Batch job artifacts.\n    \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}/artifacts\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\nwith Path(filepath).open(\"wb\") as f:\nf.write(response.content)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_api_type","title":"<code>get_api_type()</code>  <code>classmethod</code>","text":"<p>Get the ApiType of the client.</p> <p>Returns:</p> Name Type Description <code>ApiType</code> <code>ApiType</code> <p>API type of the client.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>@classmethod\ndef get_api_type(cls) -&gt; ApiType:\n\"\"\"Get the ApiType of the client.\n    Returns:\n        ApiType: API type of the client.\n    \"\"\"\nreturn ApiType.BATCH\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job","title":"<code>get_job(job_id)</code>","text":"<p>Rehydrate a job based on a Job ID.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>ID of the job to rehydrate.</p> required <p>Returns:</p> Name Type Description <code>BatchJob</code> <code>BatchJob</code> <p>Job associated with the given ID.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def get_job(self, job_id: str) -&gt; BatchJob:\n\"\"\"Rehydrate a job based on a Job ID.\n    Args:\n        job_id (str): ID of the job to rehydrate.\n    Returns:\n        BatchJob: Job associated with the given ID.\n    \"\"\"\nreturn BatchJob(self, job_id)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_details","title":"<code>get_job_details(job_id)</code>","text":"<p>Get details for the batch job.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job details cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Batch job details.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def get_job_details(self, job_id: str) -&gt; BatchJobDetails:\n\"\"\"Get details for the batch job.\n    Args:\n        job_id (str): Job ID.\n    Raises:\n        HumeClientException: If the job details cannot be loaded.\n    Returns:\n        BatchJobDetails: Batch job details.\n    \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\ntry:\nbody = response.json()\nexcept json.JSONDecodeError:\n# pylint: disable=raise-missing-from\nraise HumeClientException(\"Unexpected error when getting job details\")\nif \"message\" in body and body[\"message\"] == \"job not found\":\nraise HumeClientException(f\"Could not find a job with ID {job_id}\")\nreturn BatchJobDetails.from_response(body)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_predictions","title":"<code>get_job_predictions(job_id)</code>","text":"<p>Get a batch job's predictions.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job predictions cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Batch job predictions.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def get_job_predictions(self, job_id: str) -&gt; Any:\n\"\"\"Get a batch job's predictions.\n    Args:\n        job_id (str): Job ID.\n    Raises:\n        HumeClientException: If the job predictions cannot be loaded.\n    Returns:\n        Any: Batch job predictions.\n    \"\"\"\nendpoint = self._construct_endpoint(f\"jobs/{job_id}/predictions\")\nresponse = self._session.get(\nendpoint,\ntimeout=self._timeout,\nheaders=self._get_client_headers(),\n)\ntry:\nbody = response.json()\nexcept json.JSONDecodeError:\n# pylint: disable=raise-missing-from\nraise HumeClientException(\"Unexpected error when getting job predictions\")\nif \"message\" in body and body[\"message\"] == \"job not found\":\nraise HumeClientException(f\"Could not find a job with ID {job_id}\")\nreturn body\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_job","title":"<code>submit_job(urls, configs, transcription_config=None, callback_url=None, notify=None, files=None)</code>","text":"<p>Submit a job for batch processing.</p> Only one config per model type should be passed. <p>If more than one config is passed for a given model type, only the last config will be used.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>List[str]</code> <p>List of URLs to media files to be processed.</p> required <code>configs</code> <code>List[ModelConfigBase]</code> <p>List of model config objects to run on each media URL.</p> required <code>transcription_config</code> <code>Optional[TranscriptionConfig]</code> <p>A <code>TranscriptionConfig</code> object.</p> <code>None</code> <code>callback_url</code> <code>Optional[str]</code> <p>A URL to which a POST request will be sent upon job completion.</p> <code>None</code> <code>notify</code> <code>Optional[bool]</code> <p>Wether an email notification should be sent upon job completion.</p> <code>None</code> <code>files</code> <code>Optional[List[Union[str, Path]]]</code> <p>List of paths to files on the local disk to be processed.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchJob</code> <code>BatchJob</code> <p>The <code>BatchJob</code> representing the batch computation.</p> Source code in <code>hume/_batch/hume_batch_client.py</code> <pre><code>def submit_job(\nself,\nurls: List[str],\nconfigs: List[ModelConfigBase],\ntranscription_config: Optional[TranscriptionConfig] = None,\ncallback_url: Optional[str] = None,\nnotify: Optional[bool] = None,\nfiles: Optional[List[Union[str, Path]]] = None,\n) -&gt; BatchJob:\n\"\"\"Submit a job for batch processing.\n    Note: Only one config per model type should be passed.\n        If more than one config is passed for a given model type, only the last config will be used.\n    Args:\n        urls (List[str]): List of URLs to media files to be processed.\n        configs (List[ModelConfigBase]): List of model config objects to run on each media URL.\n        transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object.\n        callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion.\n        notify (Optional[bool]): Wether an email notification should be sent upon job completion.\n        files (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n    Returns:\n        BatchJob: The `BatchJob` representing the batch computation.\n    \"\"\"\nrequest = self._construct_request(configs, urls, transcription_config, callback_url, notify)\nreturn self._submit_job(request, files)\n</code></pre>"},{"location":"batch/transcription-config/","title":"TranscriptionConfig","text":"<p>         Bases: <code>ConfigBase[TranscriptionConfig]</code></p> <p>Configuration for speech transcription.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>Optional[str]</code> <p>By default, we use an automated language detection method for our Speech Prosody, Language, and NER models. However, if you know what language is being spoken in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results. You can specify any of the following: <code>zh</code>, <code>da</code>, <code>nl</code>, <code>en</code>, <code>en-AU</code>, <code>en-IN</code>, <code>en-NZ</code>, <code>en-GB</code>, <code>fr</code>, <code>fr-CA</code>, <code>de</code>, <code>hi</code>, <code>hi-Latn</code>, <code>id</code>, <code>it</code>, <code>ja</code>, <code>ko</code>, <code>no</code>, <code>pl</code>, <code>pt</code>, <code>pt-BR</code>, <code>pt-PT</code>, <code>ru</code>, <code>es</code>, <code>es-419</code>, <code>sv</code>, <code>ta</code>, <code>tr</code>, or <code>uk</code>.</p> <code>None</code> Source code in <code>hume/_batch/transcription_config.py</code> <pre><code>@dataclass\nclass TranscriptionConfig(ConfigBase[\"TranscriptionConfig\"]):\n\"\"\"Configuration for speech transcription.\n    Args:\n        language (Optional[str]): By default, we use an automated language detection method for our\n            Speech Prosody, Language, and NER models. However, if you know what language is being spoken\n            in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results.\n            You can specify any of the following: `zh`, `da`, `nl`, `en`, `en-AU`,\n            `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`,\n            `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`.\n    \"\"\"\nlanguage: Optional[str] = None\n</code></pre>"},{"location":"config/burst-config/","title":"BurstConfig","text":"<p>         Bases: <code>ModelConfigBase[BurstConfig]</code></p> <p>Configuration for the vocal burst model.</p> Source code in <code>hume/models/config/burst_config.py</code> <pre><code>@dataclass\nclass BurstConfig(ModelConfigBase[\"BurstConfig\"]):\n\"\"\"Configuration for the vocal burst model.\"\"\"\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.BURST\n</code></pre>"},{"location":"config/burst-config/#hume.models.config.burst_config.BurstConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/burst_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.BURST\n</code></pre>"},{"location":"config/face-config/","title":"FaceConfig","text":"<p>         Bases: <code>ModelConfigBase[FaceConfig]</code></p> <p>Configuration for the facial expression model.</p> <p>Parameters:</p> Name Type Description Default <code>fps_pred</code> <code>Optional[float]</code> <p>Number of frames per second to process. Other frames will be omitted from the response. This configuration is only available for the batch API.</p> <code>None</code> <code>prob_threshold</code> <code>Optional[float]</code> <p>Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. This configuration is only available for the batch API.</p> <code>None</code> <code>identify_faces</code> <code>Optional[bool]</code> <p>Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID.</p> <code>None</code> <code>min_face_size</code> <code>Optional[float]</code> <p>Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. This configuration is only available for the batch API.</p> <code>None</code> <code>save_faces</code> <code>Optional[bool]</code> <p>Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is only available for the batch API.</p> <code>None</code> <code>descriptions</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Descriptions predictions. Descriptions prediction can be enabled by setting \"descriptions\": {}. Currently, Descriptions prediction cannot be further configured with any parameters. If missing or null, no descriptions predictions will be generated.</p> <code>None</code> <code>facs</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for FACS predictions. FACS prediction can be enabled by setting \"facs\": {}. Currently, FACS prediction cannot be further configured with any parameters. If missing or null, no facs predictions will be generated.</p> <code>None</code> Source code in <code>hume/models/config/face_config.py</code> <pre><code>@dataclass\nclass FaceConfig(ModelConfigBase[\"FaceConfig\"]):\n\"\"\"Configuration for the facial expression model.\n    Args:\n        fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted\n            from the response.\n            This configuration is only available for the batch API.\n        prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a\n            probability less than this threshold will be omitted from the response.\n            This configuration is only available for the batch API.\n        identify_faces (Optional[bool]): Whether to return identifiers for faces across frames.\n            If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces.\n            If false, all faces will be tagged with an \"unknown\" ID.\n        min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face.\n            Faces detected with a bounding box side length in pixels less than this threshold will be\n            omitted from the response.\n            This configuration is only available for the batch API.\n        save_faces (Optional[bool]): Whether to extract and save the detected faces to the artifacts\n            directory included in the response.\n            This configuration is only available for the batch API.\n        descriptions (Optional[Dict[str, Any]]): Configuration for Descriptions predictions.\n            Descriptions prediction can be enabled by setting \"descriptions\": {}.\n            Currently, Descriptions prediction cannot be further configured with any parameters.\n            If missing or null, no descriptions predictions will be generated.\n        facs (Optional[Dict[str, Any]]): Configuration for FACS predictions.\n            FACS prediction can be enabled by setting \"facs\": {}.\n            Currently, FACS prediction cannot be further configured with any parameters.\n            If missing or null, no facs predictions will be generated.\n    \"\"\"\nfps_pred: Optional[float] = None\nprob_threshold: Optional[float] = None\nidentify_faces: Optional[bool] = None\nmin_face_size: Optional[float] = None\nsave_faces: Optional[bool] = None\ndescriptions: Optional[Dict[str, Any]] = None\nfacs: Optional[Dict[str, Any]] = None\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.FACE\n</code></pre>"},{"location":"config/face-config/#hume.models.config.face_config.FaceConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/face_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.FACE\n</code></pre>"},{"location":"config/facemesh-config/","title":"FacemeshConfig","text":"<p>         Bases: <code>ModelConfigBase[FacemeshConfig]</code></p> <p>Configuration for the facemesh model.</p> Source code in <code>hume/models/config/facemesh_config.py</code> <pre><code>@dataclass\nclass FacemeshConfig(ModelConfigBase[\"FacemeshConfig\"]):\n\"\"\"Configuration for the facemesh model.\"\"\"\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.FACEMESH\n</code></pre>"},{"location":"config/facemesh-config/#hume.models.config.facemesh_config.FacemeshConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/facemesh_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.FACEMESH\n</code></pre>"},{"location":"config/language-config/","title":"LanguageConfig","text":"<p>         Bases: <code>ModelConfigBase[LanguageConfig]</code></p> <p>Configuration for the language emotion model.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Optional[str]</code> <p>The granularity at which to generate predictions. Accepted values are <code>word</code>, <code>sentence</code>, <code>utterance</code>, or <code>conversational_turn</code>. The default is <code>utterance</code>. <code>utterance</code> corresponds to a natural pause or break in conversation <code>conversational_turn</code> corresponds to a change in speaker. This configuration is available for the streaming API, but only with values <code>word</code> and <code>sentence</code>.</p> <code>None</code> <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> <code>sentiment</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Sentiment predictions. Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, Sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated.</p> <code>None</code> <code>toxicity</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Toxicity predictions. Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, Toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated.</p> <code>None</code> Source code in <code>hume/models/config/language_config.py</code> <pre><code>@dataclass\nclass LanguageConfig(ModelConfigBase[\"LanguageConfig\"]):\n\"\"\"Configuration for the language emotion model.\n    Args:\n        granularity (Optional[str]): The granularity at which to generate predictions.\n            Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`.\n            The default is `utterance`.\n            `utterance` corresponds to a natural pause or break in conversation\n            `conversational_turn` corresponds to a change in speaker.\n            This configuration is available for the streaming API, but only with values `word` and `sentence`.\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time.\n            If true, unique identifiers will be assigned to spoken words to differentiate different speakers.\n            If false, all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n        sentiment (Optional[Dict[str, Any]]): Configuration for Sentiment predictions.\n            Sentiment prediction can be enabled by setting \"sentiment\": {}.\n            Currently, Sentiment prediction cannot be further configured with any parameters.\n            If missing or null, no sentiment predictions will be generated.\n        toxicity (Optional[Dict[str, Any]]): Configuration for Toxicity predictions.\n            Toxicity prediction can be enabled by setting \"toxicity\": {}.\n            Currently, Toxicity prediction cannot be further configured with any parameters.\n            If missing or null, no toxicity predictions will be generated.\n    \"\"\"\ngranularity: Optional[str] = None\nidentify_speakers: Optional[bool] = None\nsentiment: Optional[Dict[str, Any]] = None\ntoxicity: Optional[Dict[str, Any]] = None\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.LANGUAGE\n</code></pre>"},{"location":"config/language-config/#hume.models.config.language_config.LanguageConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/language_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.LANGUAGE\n</code></pre>"},{"location":"config/ner-config/","title":"NerConfig","text":"<p>         Bases: <code>ModelConfigBase[NerConfig]</code></p> <p>Configuration for the named-entity emotion model.</p> <p>This model is only available for the batch API.</p> <p>Parameters:</p> Name Type Description Default <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> Source code in <code>hume/models/config/ner_config.py</code> <pre><code>@dataclass\nclass NerConfig(ModelConfigBase[\"NerConfig\"]):\n\"\"\"Configuration for the named-entity emotion model.\n    This model is only available for the batch API.\n    Args:\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true,\n            unique identifiers will be assigned to spoken words to differentiate different speakers. If false,\n            all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n    \"\"\"\nidentify_speakers: Optional[bool] = None\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.NER\n</code></pre>"},{"location":"config/ner-config/#hume.models.config.ner_config.NerConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/ner_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.NER\n</code></pre>"},{"location":"config/prosody-config/","title":"ProsodyConfig","text":"<p>         Bases: <code>ModelConfigBase[ProsodyConfig]</code></p> <p>Configuration for the speech prosody model.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Optional[str]</code> <p>The granularity at which to generate predictions. Accepted values are <code>word</code>, <code>sentence</code>, <code>utterance</code>, or <code>conversational_turn</code>. The default is <code>utterance</code>. <code>utterance</code> corresponds to a natural pause or break in conversation <code>conversational_turn</code> corresponds to a change in speaker. This configuration is only available for the batch API.</p> <code>None</code> <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> <code>window</code> <code>Optional[Dict[str, float]]</code> <p>Sliding window used to chunk audio. This dictionary input takes two entries: <code>length</code> and <code>step</code> representing the width of the window in seconds and the step size in seconds. This configuration is only available for the batch API.</p> <code>None</code> Source code in <code>hume/models/config/prosody_config.py</code> <pre><code>@dataclass\nclass ProsodyConfig(ModelConfigBase[\"ProsodyConfig\"]):\n\"\"\"Configuration for the speech prosody model.\n    Args:\n        granularity (Optional[str]): The granularity at which to generate predictions.\n            Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`.\n            The default is `utterance`.\n            `utterance` corresponds to a natural pause or break in conversation\n            `conversational_turn` corresponds to a change in speaker.\n            This configuration is only available for the batch API.\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true,\n            unique identifiers will be assigned to spoken words to differentiate different speakers. If false,\n            all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n        window (Optional[Dict[str, float]]): Sliding window used to chunk audio.\n            This dictionary input takes two entries: `length` and `step` representing\n            the width of the window in seconds and the step size in seconds.\n            This configuration is only available for the batch API.\n    \"\"\"\nidentify_speakers: Optional[bool] = None\ngranularity: Optional[str] = None\nwindow: Optional[Dict[str, float]] = None\n@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n        Returns:\n            ModelType: Model type.\n        \"\"\"\nreturn ModelType.PROSODY\n</code></pre>"},{"location":"config/prosody-config/#hume.models.config.prosody_config.ProsodyConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/prosody_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n\"\"\"Get the configuration model type.\n    Returns:\n        ModelType: Model type.\n    \"\"\"\nreturn ModelType.PROSODY\n</code></pre>"},{"location":"stream/hume-stream-client/","title":"HumeStreamClient","text":"<p>         Bases: <code>ClientBase</code></p> <p>Streaming API client.</p> Example <pre><code>import asyncio\nfrom hume import HumeStreamClient\nfrom hume.models.config import BurstConfig\nfrom hume.models.config import ProsodyConfig\nasync def main():\nclient = HumeStreamClient(\"&lt;your-api-key&gt;\")\nconfigs = [BurstConfig(), ProsodyConfig()]\nasync with client.connect(configs) as socket:\nresult = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\nprint(result)\nasyncio.run(main())\n</code></pre> Source code in <code>hume/_stream/hume_stream_client.py</code> <pre><code>class HumeStreamClient(ClientBase):\n\"\"\"Streaming API client.\n    Example:\n        ```python\n        import asyncio\n        from hume import HumeStreamClient\n        from hume.models.config import BurstConfig\n        from hume.models.config import ProsodyConfig\n        async def main():\n            client = HumeStreamClient(\"&lt;your-api-key&gt;\")\n            configs = [BurstConfig(), ProsodyConfig()]\n            async with client.connect(configs) as socket:\n                result = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\n                print(result)\n        asyncio.run(main())\n        ```\n    \"\"\"\ndef __init__(\nself,\napi_key: str,\n*args: Any,\nopen_timeout: Optional[int] = 10,\nclose_timeout: Optional[int] = 10,\n**kwargs: Any,\n):\n\"\"\"Construct a HumeStreamClient.\n        Args:\n            api_key (str): Hume API key.\n            open_timeout (Optional[int]): Time in seconds before canceling socket open operation.\n            close_timeout (Optional[int]): Time in seconds before canceling socket close operation.\n        \"\"\"\nif not HAS_WEBSOCKETS:\nraise HumeClientException(\"The websockets package is required to use HumeStreamClient. \"\n\"Run `pip install \\\"hume[stream]\\\"` to install a version compatible with the\"\n\"Hume Python SDK.\")\nself._open_timeout = open_timeout\nself._close_timeout = close_timeout\nsuper().__init__(api_key, *args, **kwargs)\n@classmethod\ndef get_api_type(cls) -&gt; ApiType:\n\"\"\"Get the ApiType of the client.\n        Returns:\n            ApiType: API type of the client.\n        \"\"\"\nreturn ApiType.STREAM\n@asynccontextmanager\nasync def connect(\nself,\nconfigs: List[ModelConfigBase],\nstream_window_ms: Optional[int] = None,\n) -&gt; AsyncIterator[StreamSocket]:\n\"\"\"Connect to the streaming API.\n        Note: Only one config per model type should be passed.\n            If more than one config is passed for a given model type, only the last config will be used.\n        Args:\n            configs (List[ModelConfigBase]): List of job configs.\n            stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n                aggregating media across streaming payloads within one WebSocket connection.\n        \"\"\"\nendpoint = self._construct_endpoint(\"models\")\ntry:\n# pylint: disable=no-member\nasync with websockets.connect(  # type: ignore[attr-defined]\nendpoint,\nextra_headers=self._get_client_headers(),\nclose_timeout=self._close_timeout,\nopen_timeout=self._open_timeout) as protocol:\nyield StreamSocket(protocol, configs, stream_window_ms=stream_window_ms)\nexcept websockets.exceptions.InvalidStatusCode as exc:\nstatus_code: int = exc.status_code\nif status_code == 401:  # Unauthorized\nmessage = \"HumeStreamClient initialized with invalid API key.\"\nraise HumeClientException(message) from exc\nraise HumeClientException(\"Unexpected error when creating streaming connection\") from exc\n@asynccontextmanager\nasync def _connect_with_configs_dict(self, configs_dict: Any) -&gt; AsyncIterator[StreamSocket]:\n\"\"\"Connect to the streaming API with a single models configuration dict.\n        Args:\n            configs_dict (Any): Models configurations dict. This should be a dict from model name\n                to model configuration dict. An empty dict uses the default configuration.\n        \"\"\"\nconfigs = deserialize_configs(configs_dict)\nasync with self.connect(configs) as websocket:\nyield websocket\n</code></pre>"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.__init__","title":"<code>__init__(api_key, *args, open_timeout=10, close_timeout=10, **kwargs)</code>","text":"<p>Construct a HumeStreamClient.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Hume API key.</p> required <code>open_timeout</code> <code>Optional[int]</code> <p>Time in seconds before canceling socket open operation.</p> <code>10</code> <code>close_timeout</code> <code>Optional[int]</code> <p>Time in seconds before canceling socket close operation.</p> <code>10</code> Source code in <code>hume/_stream/hume_stream_client.py</code> <pre><code>def __init__(\nself,\napi_key: str,\n*args: Any,\nopen_timeout: Optional[int] = 10,\nclose_timeout: Optional[int] = 10,\n**kwargs: Any,\n):\n\"\"\"Construct a HumeStreamClient.\n    Args:\n        api_key (str): Hume API key.\n        open_timeout (Optional[int]): Time in seconds before canceling socket open operation.\n        close_timeout (Optional[int]): Time in seconds before canceling socket close operation.\n    \"\"\"\nif not HAS_WEBSOCKETS:\nraise HumeClientException(\"The websockets package is required to use HumeStreamClient. \"\n\"Run `pip install \\\"hume[stream]\\\"` to install a version compatible with the\"\n\"Hume Python SDK.\")\nself._open_timeout = open_timeout\nself._close_timeout = close_timeout\nsuper().__init__(api_key, *args, **kwargs)\n</code></pre>"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.connect","title":"<code>connect(configs, stream_window_ms=None)</code>  <code>async</code>","text":"<p>Connect to the streaming API.</p> Only one config per model type should be passed. <p>If more than one config is passed for a given model type, only the last config will be used.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>List[ModelConfigBase]</code> <p>List of job configs.</p> required <code>stream_window_ms</code> <code>Optional[int]</code> <p>Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one WebSocket connection.</p> <code>None</code> Source code in <code>hume/_stream/hume_stream_client.py</code> <pre><code>@asynccontextmanager\nasync def connect(\nself,\nconfigs: List[ModelConfigBase],\nstream_window_ms: Optional[int] = None,\n) -&gt; AsyncIterator[StreamSocket]:\n\"\"\"Connect to the streaming API.\n    Note: Only one config per model type should be passed.\n        If more than one config is passed for a given model type, only the last config will be used.\n    Args:\n        configs (List[ModelConfigBase]): List of job configs.\n        stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n            aggregating media across streaming payloads within one WebSocket connection.\n    \"\"\"\nendpoint = self._construct_endpoint(\"models\")\ntry:\n# pylint: disable=no-member\nasync with websockets.connect(  # type: ignore[attr-defined]\nendpoint,\nextra_headers=self._get_client_headers(),\nclose_timeout=self._close_timeout,\nopen_timeout=self._open_timeout) as protocol:\nyield StreamSocket(protocol, configs, stream_window_ms=stream_window_ms)\nexcept websockets.exceptions.InvalidStatusCode as exc:\nstatus_code: int = exc.status_code\nif status_code == 401:  # Unauthorized\nmessage = \"HumeStreamClient initialized with invalid API key.\"\nraise HumeClientException(message) from exc\nraise HumeClientException(\"Unexpected error when creating streaming connection\") from exc\n</code></pre>"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.get_api_type","title":"<code>get_api_type()</code>  <code>classmethod</code>","text":"<p>Get the ApiType of the client.</p> <p>Returns:</p> Name Type Description <code>ApiType</code> <code>ApiType</code> <p>API type of the client.</p> Source code in <code>hume/_stream/hume_stream_client.py</code> <pre><code>@classmethod\ndef get_api_type(cls) -&gt; ApiType:\n\"\"\"Get the ApiType of the client.\n    Returns:\n        ApiType: API type of the client.\n    \"\"\"\nreturn ApiType.STREAM\n</code></pre>"},{"location":"stream/stream-socket/","title":"StreamSocket","text":"<p>Streaming socket connection.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>class StreamSocket:\n\"\"\"Streaming socket connection.\"\"\"\n_FACE_LIMIT = 100\n_N_LANDMARKS = 478\n_N_SPATIAL = 3\ndef __init__(\nself,\nprotocol: \"WebSocketClientProtocol\",\nconfigs: List[ModelConfigBase],\nstream_window_ms: Optional[int] = None,\n):\n\"\"\"Construct a `StreamSocket`.\n        Args:\n            protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n            configs (List[ModelConfigBase]): List of model configurations.\n            stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n                aggregating media across streaming payloads within one websocket connection.\n        Raises:\n            HumeClientException: If there is an error processing media over the socket connection.\n        \"\"\"\nif not HAS_WEBSOCKETS:\nraise HumeClientException(\"The websockets package is required to use HumeStreamClient. \"\n\"Run `pip install \\\"hume[stream]\\\"` to install a version compatible with the\"\n\"Hume Python SDK.\")\nself._protocol = protocol\nself._configs = configs\nself._stream_window_ms = stream_window_ms\n# Serialize configs once for full lifetime of socket\nself._serialized_configs = serialize_configs(configs)\nasync def send_file(self, filepath: Union[str, Path]) -&gt; Any:\n\"\"\"Send a file on the `StreamSocket`.\n        Args:\n            filepath (Path): Path to media file to send on socket connection.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\nwith Path(filepath).open('rb') as f:\nbytes_data = base64.b64encode(f.read())\nreturn await self.send_bytes(bytes_data)\nasync def send_bytes(self, bytes_data: bytes) -&gt; Any:\n\"\"\"Send raw bytes on the `StreamSocket`.\n        Note: Input should be base64 encoded bytes.\n            You can use base64.b64encode() to encode a raw string.\n        Args:\n            bytes_data (bytes): Raw bytes of media to send on socket connection.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\nbytes_str = bytes_data.decode(\"utf-8\")\nreturn await self._send_bytes_str(bytes_str)\nasync def send_text(self, text: str) -&gt; Any:\n\"\"\"Send text on the `StreamSocket`.\n        Note: This method is intended for use with a `LanguageConfig`.\n            When the socket is configured for other modalities this method will fail.\n        Args:\n            text (str): Text to send to the language model.\n        Raises:\n            HumeClientException: If the socket is configured with a modality other than language.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\nself._validate_configs_with_model_type(LanguageConfig, \"send_text\")\npayload = {\n\"data\": text,\n\"models\": self._serialized_configs,\n\"raw_text\": True,\n}\nif self._stream_window_ms is not None:\npayload[\"stream_window_ms\"] = self._stream_window_ms\nreturn await self._send_payload(payload)\nasync def send_facemesh(self, landmarks: List[List[List[float]]]) -&gt; Any:\n\"\"\"Send facemesh landmarks on the `StreamSocket`.\n        Note: This method is intended for use with a `FacemeshConfig`.\n            When the socket is configured for other modalities this method will fail.\n        Args:\n            landmarks (List[List[List[float]]]): List of landmark points for multiple faces.\n                The shape of this 3-dimensional list should be (n, 478, 3) where n is the number\n                of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3\n                represents the (x, y, z) coordinates of each landmark.\n        Raises:\n            HumeClientException: If the socket is configured with a modality other than facemesh.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\nself._validate_configs_with_model_type(FacemeshConfig, \"send_facemesh\")\nn_faces = len(landmarks)\nif n_faces &gt; self._FACE_LIMIT:\nraise HumeClientException(\"Number of faces sent in facemesh payload was greater \"\nf\"than the limit of {self._FACE_LIMIT}, found {n_faces}.\")\nif n_faces == 0:\nraise HumeClientException(\"No faces sent in facemesh payload.\")\nn_landmarks = len(landmarks[0])\nif n_landmarks != self._N_LANDMARKS:\nraise HumeClientException(f\"Number of MediaPipe landmarks per face must be exactly {self._N_LANDMARKS}, \"\nf\"found {n_landmarks}.\")\nif len(landmarks[0][0]) != self._N_SPATIAL:\nraise HumeClientException(\"Invalid facemesh payload detected. \"\n\"Each facemesh landmark should be an (x, y, z) point.\")\nlandmarks_str = json.dumps(landmarks)\nbytes_data = base64.b64encode(landmarks_str.encode(\"utf-8\"))\nreturn await self.send_bytes(bytes_data)\nasync def reset_stream(self) -&gt; Any:\n\"\"\"Reset the streaming sliding window.\n        A sliding window of context is maintained for the lifetime of your streaming connection.\n        Call this method when some media has been fully processed and you want to continue using the same\n        streaming connection without leaking context across media samples.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\npayload = {\n\"reset_stream\": True,\n}\nreturn await self._send_payload(payload)\nasync def get_job_details(self) -&gt; Any:\n\"\"\"Get details associated with the current streaming connection.\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\npayload = {\n\"job_details\": True,\n}\nreturn await self._send_payload(payload)\nasync def _send_bytes_str(self, bytes_str: str) -&gt; Any:\npayload: Dict[str, Any] = {\n\"data\": bytes_str,\n\"models\": self._serialized_configs,\n}\nif self._stream_window_ms is not None:\npayload[\"stream_window_ms\"] = self._stream_window_ms\nreturn await self._send_payload(payload)\nasync def _send_payload(self, payload: Dict[str, Any]) -&gt; Any:\nrequest_message = json.dumps(payload)\nawait self._protocol.send(request_message)\nresponse_data = await self._protocol.recv()\n# Cast to str because websockets can send bytes, but we will always accept JSON strings\nresponse_str = str(response_data)\ntry:\nresponse = json.loads(response_str)\nexcept json.JSONDecodeError as exc:\nraise HumeClientException(\"Unexpected error when fetching streaming API predictions\") from exc\nif \"error\" in response:\nerror = response[\"error\"]\ncode = response[\"code\"]\nraise HumeClientException.from_error(code, error)\nreturn response\ndef _validate_configs_with_model_type(self, config_type: Any, method_name: str) -&gt; None:\nfor config in self._configs:\nif not isinstance(config, config_type):\nconfig_name = config_type.__name__\ninvalid_config_name = config.__class__.__name__\nraise HumeClientException(f\"Socket configured with {invalid_config_name}. \"\nf\"{method_name} is only supported when using a {config_name}.\")\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.__init__","title":"<code>__init__(protocol, configs, stream_window_ms=None)</code>","text":"<p>Construct a <code>StreamSocket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>protocol</code> <code>WebSocketClientProtocol</code> <p>Protocol instance from websockets library.</p> required <code>configs</code> <code>List[ModelConfigBase]</code> <p>List of model configurations.</p> required <code>stream_window_ms</code> <code>Optional[int]</code> <p>Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection.</p> <code>None</code> <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If there is an error processing media over the socket connection.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>def __init__(\nself,\nprotocol: \"WebSocketClientProtocol\",\nconfigs: List[ModelConfigBase],\nstream_window_ms: Optional[int] = None,\n):\n\"\"\"Construct a `StreamSocket`.\n    Args:\n        protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n        configs (List[ModelConfigBase]): List of model configurations.\n        stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n            aggregating media across streaming payloads within one websocket connection.\n    Raises:\n        HumeClientException: If there is an error processing media over the socket connection.\n    \"\"\"\nif not HAS_WEBSOCKETS:\nraise HumeClientException(\"The websockets package is required to use HumeStreamClient. \"\n\"Run `pip install \\\"hume[stream]\\\"` to install a version compatible with the\"\n\"Hume Python SDK.\")\nself._protocol = protocol\nself._configs = configs\nself._stream_window_ms = stream_window_ms\n# Serialize configs once for full lifetime of socket\nself._serialized_configs = serialize_configs(configs)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.get_job_details","title":"<code>get_job_details()</code>  <code>async</code>","text":"<p>Get details associated with the current streaming connection.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def get_job_details(self) -&gt; Any:\n\"\"\"Get details associated with the current streaming connection.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\npayload = {\n\"job_details\": True,\n}\nreturn await self._send_payload(payload)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.reset_stream","title":"<code>reset_stream()</code>  <code>async</code>","text":"<p>Reset the streaming sliding window.</p> <p>A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def reset_stream(self) -&gt; Any:\n\"\"\"Reset the streaming sliding window.\n    A sliding window of context is maintained for the lifetime of your streaming connection.\n    Call this method when some media has been fully processed and you want to continue using the same\n    streaming connection without leaking context across media samples.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\npayload = {\n\"reset_stream\": True,\n}\nreturn await self._send_payload(payload)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_bytes","title":"<code>send_bytes(bytes_data)</code>  <code>async</code>","text":"<p>Send raw bytes on the <code>StreamSocket</code>.</p> Input should be base64 encoded bytes. <p>You can use base64.b64encode() to encode a raw string.</p> <p>Parameters:</p> Name Type Description Default <code>bytes_data</code> <code>bytes</code> <p>Raw bytes of media to send on socket connection.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def send_bytes(self, bytes_data: bytes) -&gt; Any:\n\"\"\"Send raw bytes on the `StreamSocket`.\n    Note: Input should be base64 encoded bytes.\n        You can use base64.b64encode() to encode a raw string.\n    Args:\n        bytes_data (bytes): Raw bytes of media to send on socket connection.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\nbytes_str = bytes_data.decode(\"utf-8\")\nreturn await self._send_bytes_str(bytes_str)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_facemesh","title":"<code>send_facemesh(landmarks)</code>  <code>async</code>","text":"<p>Send facemesh landmarks on the <code>StreamSocket</code>.</p> This method is intended for use with a <code>FacemeshConfig</code>. <p>When the socket is configured for other modalities this method will fail.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[List[List[float]]]</code> <p>List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the socket is configured with a modality other than facemesh.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def send_facemesh(self, landmarks: List[List[List[float]]]) -&gt; Any:\n\"\"\"Send facemesh landmarks on the `StreamSocket`.\n    Note: This method is intended for use with a `FacemeshConfig`.\n        When the socket is configured for other modalities this method will fail.\n    Args:\n        landmarks (List[List[List[float]]]): List of landmark points for multiple faces.\n            The shape of this 3-dimensional list should be (n, 478, 3) where n is the number\n            of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3\n            represents the (x, y, z) coordinates of each landmark.\n    Raises:\n        HumeClientException: If the socket is configured with a modality other than facemesh.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\nself._validate_configs_with_model_type(FacemeshConfig, \"send_facemesh\")\nn_faces = len(landmarks)\nif n_faces &gt; self._FACE_LIMIT:\nraise HumeClientException(\"Number of faces sent in facemesh payload was greater \"\nf\"than the limit of {self._FACE_LIMIT}, found {n_faces}.\")\nif n_faces == 0:\nraise HumeClientException(\"No faces sent in facemesh payload.\")\nn_landmarks = len(landmarks[0])\nif n_landmarks != self._N_LANDMARKS:\nraise HumeClientException(f\"Number of MediaPipe landmarks per face must be exactly {self._N_LANDMARKS}, \"\nf\"found {n_landmarks}.\")\nif len(landmarks[0][0]) != self._N_SPATIAL:\nraise HumeClientException(\"Invalid facemesh payload detected. \"\n\"Each facemesh landmark should be an (x, y, z) point.\")\nlandmarks_str = json.dumps(landmarks)\nbytes_data = base64.b64encode(landmarks_str.encode(\"utf-8\"))\nreturn await self.send_bytes(bytes_data)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_file","title":"<code>send_file(filepath)</code>  <code>async</code>","text":"<p>Send a file on the <code>StreamSocket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to media file to send on socket connection.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def send_file(self, filepath: Union[str, Path]) -&gt; Any:\n\"\"\"Send a file on the `StreamSocket`.\n    Args:\n        filepath (Path): Path to media file to send on socket connection.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\nwith Path(filepath).open('rb') as f:\nbytes_data = base64.b64encode(f.read())\nreturn await self.send_bytes(bytes_data)\n</code></pre>"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_text","title":"<code>send_text(text)</code>  <code>async</code>","text":"<p>Send text on the <code>StreamSocket</code>.</p> This method is intended for use with a <code>LanguageConfig</code>. <p>When the socket is configured for other modalities this method will fail.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to send to the language model.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the socket is configured with a modality other than language.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_stream/stream_socket.py</code> <pre><code>async def send_text(self, text: str) -&gt; Any:\n\"\"\"Send text on the `StreamSocket`.\n    Note: This method is intended for use with a `LanguageConfig`.\n        When the socket is configured for other modalities this method will fail.\n    Args:\n        text (str): Text to send to the language model.\n    Raises:\n        HumeClientException: If the socket is configured with a modality other than language.\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\nself._validate_configs_with_model_type(LanguageConfig, \"send_text\")\npayload = {\n\"data\": text,\n\"models\": self._serialized_configs,\n\"raw_text\": True,\n}\nif self._stream_window_ms is not None:\npayload[\"stream_window_ms\"] = self._stream_window_ms\nreturn await self._send_payload(payload)\n</code></pre>"}]}