# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
from ...core.pydantic_utilities import IS_PYDANTIC_V2, UniversalBaseModel
from .format import Format
from .octave_version import OctaveVersion
from .posted_context import PostedContext
from .posted_utterance import PostedUtterance
from .timestamp_type import TimestampType


class PostedTts(UniversalBaseModel):
    context: typing.Optional[PostedContext] = pydantic.Field(default=None)
    """
    Utterances to use as context for generating consistent speech style and prosody across multiple requests. These will not be converted to speech output.
    """

    format: typing.Optional[Format] = pydantic.Field(default=None)
    """
    Specifies the output audio file format.
    """

    include_timestamp_types: typing.Optional[typing.List[TimestampType]] = pydantic.Field(default=None)
    """
    The set of timestamp types to include in the response. Only supported for Octave 2 requests.
    """

    num_generations: typing.Optional[int] = pydantic.Field(default=None)
    """
    Number of audio generations to produce from the input utterances.
    
    Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
    """

    split_utterances: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Controls how audio output is segmented in the response.
    
    - When **enabled** (`true`), input utterances are automatically split into natural-sounding speech segments.
    
    - When **disabled** (`false`), the response maintains a strict one-to-one mapping between input utterances and output snippets. 
    
    This setting affects how the `snippets` array is structured in the response, which may be important for applications that need to track the relationship between input text and generated audio segments. When setting to `false`, avoid including utterances with long `text`, as this can result in distorted output.
    """

    strip_headers: typing.Optional[bool] = pydantic.Field(default=None)
    """
    If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable).
    """

    utterances: typing.List[PostedUtterance] = pydantic.Field()
    """
    A list of **Utterances** to be converted to speech output.
    
    An **Utterance** is a unit of input for [Octave](/docs/text-to-speech-tts/overview), and includes input `text`, an optional `description` to serve as the prompt for how the speech should be delivered, an optional `voice` specification, and additional controls to guide delivery for `speed` and `trailing_silence`.
    """

    version: typing.Optional[OctaveVersion] = pydantic.Field(default=None)
    """
    Selects the Octave model version used to synthesize speech for this request. If you omit this field, Hume automatically routes the request to the most appropriate model. Setting a specific version ensures stable and repeatable behavior across requests.
    
    Use `2` to opt into the latest Octave capabilities. When you specify version `2`, you must also provide a `voice`. Requests that set `version: 2` without a voice will be rejected.
    
    For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
    """

    instant_mode: typing.Optional[bool] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
