diff --git a/src/hume/tts/client.py b/src/hume/tts/client.py
index a427e2b..fdff3be 100644
--- a/src/hume/tts/client.py
+++ b/src/hume/tts/client.py
@@ -4,8 +4,7 @@ from __future__ import annotations
 
 import typing
 
-from hume.tts.stream_input.client import StreamInputClient
-
+from .. import core
 from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
 from ..core.request_options import RequestOptions
 from .raw_client import AsyncRawTtsClient, RawTtsClient
@@ -13,13 +12,13 @@ from .types.format import Format
 from .types.octave_version import OctaveVersion
 from .types.posted_context import PostedContext
 from .types.posted_utterance import PostedUtterance
+from .types.posted_utterance_voice import PostedUtteranceVoice
 from .types.return_tts import ReturnTts
 from .types.timestamp_type import TimestampType
 from .types.tts_output import TtsOutput
 
 if typing.TYPE_CHECKING:
     from .voices.client import AsyncVoicesClient, VoicesClient
-    from .stream_input.client import AsyncStreamInputClient, StreamInputClient
 # this is used as the default value for optional parameters
 OMIT = typing.cast(typing.Any, ...)
 
@@ -29,7 +28,6 @@ class TtsClient:
         self._raw_client = RawTtsClient(client_wrapper=client_wrapper)
         self._client_wrapper = client_wrapper
         self._voices: typing.Optional[VoicesClient] = None
-        self._stream_input: typing.Optional[StreamInputClient] = None
 
     @property
     def with_raw_response(self) -> RawTtsClient:
@@ -75,10 +73,12 @@ class TtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -100,10 +100,6 @@ class TtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration.
@@ -187,10 +183,12 @@ class TtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -212,10 +210,6 @@ class TtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
@@ -292,10 +286,12 @@ class TtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -317,10 +313,6 @@ class TtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
@@ -397,10 +389,12 @@ class TtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -422,10 +416,6 @@ class TtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration.
@@ -471,6 +461,117 @@ class TtsClient:
         ) as r:
             yield from r.data
 
+    def convert_voice_file(
+        self,
+        *,
+        audio: core.File,
+        strip_headers: typing.Optional[bool] = OMIT,
+        context: typing.Optional[PostedContext] = OMIT,
+        voice: typing.Optional[PostedUtteranceVoice] = OMIT,
+        format: typing.Optional[Format] = OMIT,
+        include_timestamp_types: typing.Optional[typing.List[TimestampType]] = OMIT,
+        request_options: typing.Optional[RequestOptions] = None,
+    ) -> typing.Iterator[bytes]:
+        """
+        Parameters
+        ----------
+        audio : core.File
+            See core.File for more documentation
+
+        strip_headers : typing.Optional[bool]
+            If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable).
+
+        context : typing.Optional[PostedContext]
+            Utterances to use as context for generating consistent speech style and prosody across multiple requests. These will not be converted to speech output.
+
+        voice : typing.Optional[PostedUtteranceVoice]
+
+        format : typing.Optional[Format]
+            Specifies the output audio file format.
+
+        include_timestamp_types : typing.Optional[typing.List[TimestampType]]
+            The set of timestamp types to include in the response. When used in multipart/form-data, specify each value using bracket notation: `include_timestamp_types[0]=word&include_timestamp_types[1]=phoneme`. Only supported for Octave 2 requests.
+
+        request_options : typing.Optional[RequestOptions]
+            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
+
+        Returns
+        -------
+        typing.Iterator[bytes]
+            Successful Response
+        """
+        with self._raw_client.convert_voice_file(
+            audio=audio,
+            strip_headers=strip_headers,
+            context=context,
+            voice=voice,
+            format=format,
+            include_timestamp_types=include_timestamp_types,
+            request_options=request_options,
+        ) as r:
+            yield from r.data
+
+    def convert_voice_json(
+        self,
+        *,
+        strip_headers: typing.Optional[bool] = OMIT,
+        audio: typing.Optional[core.File] = OMIT,
+        context: typing.Optional[PostedContext] = OMIT,
+        voice: typing.Optional[PostedUtteranceVoice] = OMIT,
+        format: typing.Optional[Format] = OMIT,
+        include_timestamp_types: typing.Optional[typing.List[TimestampType]] = OMIT,
+        request_options: typing.Optional[RequestOptions] = None,
+    ) -> typing.Iterator[TtsOutput]:
+        """
+        Parameters
+        ----------
+        strip_headers : typing.Optional[bool]
+            If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable).
+
+        audio : typing.Optional[core.File]
+            See core.File for more documentation
+
+        context : typing.Optional[PostedContext]
+            Utterances to use as context for generating consistent speech style and prosody across multiple requests. These will not be converted to speech output.
+
+        voice : typing.Optional[PostedUtteranceVoice]
+
+        format : typing.Optional[Format]
+            Specifies the output audio file format.
+
+        include_timestamp_types : typing.Optional[typing.List[TimestampType]]
+            The set of timestamp types to include in the response. When used in multipart/form-data, specify each value using bracket notation: `include_timestamp_types[0]=word&include_timestamp_types[1]=phoneme`. Only supported for Octave 2 requests.
+
+        request_options : typing.Optional[RequestOptions]
+            Request-specific configuration.
+
+        Yields
+        ------
+        typing.Iterator[TtsOutput]
+            Successful Response
+
+        Examples
+        --------
+        from hume import HumeClient
+
+        client = HumeClient(
+            api_key="YOUR_API_KEY",
+        )
+        response = client.tts.convert_voice_json()
+        for chunk in response:
+            yield chunk
+        """
+        with self._raw_client.convert_voice_json(
+            strip_headers=strip_headers,
+            audio=audio,
+            context=context,
+            voice=voice,
+            format=format,
+            include_timestamp_types=include_timestamp_types,
+            request_options=request_options,
+        ) as r:
+            yield from r.data
+
     @property
     def voices(self):
         if self._voices is None:
@@ -479,21 +580,12 @@ class TtsClient:
             self._voices = VoicesClient(client_wrapper=self._client_wrapper)
         return self._voices
 
-    @property
-    def stream_input(self):
-        if self._stream_input is None:
-            from .stream_input.client import StreamInputClient  # noqa: E402
-
-            self._stream_input = StreamInputClient(client_wrapper=self._client_wrapper)
-        return self._stream_input
-
 
 class AsyncTtsClient:
     def __init__(self, *, client_wrapper: AsyncClientWrapper):
         self._raw_client = AsyncRawTtsClient(client_wrapper=client_wrapper)
         self._client_wrapper = client_wrapper
         self._voices: typing.Optional[AsyncVoicesClient] = None
-        self._stream_input: typing.Optional[AsyncStreamInputClient] = None
 
     @property
     def with_raw_response(self) -> AsyncRawTtsClient:
@@ -539,10 +631,12 @@ class AsyncTtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -564,10 +658,6 @@ class AsyncTtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration.
@@ -659,10 +749,12 @@ class AsyncTtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -684,10 +776,6 @@ class AsyncTtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
@@ -773,10 +861,12 @@ class AsyncTtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -798,10 +888,6 @@ class AsyncTtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
@@ -887,10 +973,12 @@ class AsyncTtsClient:
             Specifies the output audio file format.
 
         include_timestamp_types : typing.Optional[typing.Sequence[TimestampType]]
-            The set of timestamp types to include in the response.
+            The set of timestamp types to include in the response. Only supported for Octave 2 requests.
 
         num_generations : typing.Optional[int]
-            Number of generations of the audio to produce.
+            Number of audio generations to produce from the input utterances.
+
+            Using `num_generations` enables faster processing than issuing multiple sequential requests. Additionally, specifying `num_generations` allows prosody continuation across all generations without repeating context, ensuring each generation sounds slightly different while maintaining contextual consistency.
 
         split_utterances : typing.Optional[bool]
             Controls how audio output is segmented in the response.
@@ -912,10 +1000,6 @@ class AsyncTtsClient:
             For a comparison of Octave versions, see the [Octave versions](/docs/text-to-speech-tts/overview#octave-versions) section in the TTS overview.
 
         instant_mode : typing.Optional[bool]
-            Enables ultra-low latency streaming, significantly reducing the time until the first audio chunk is received. Recommended for real-time applications requiring immediate audio playback. For further details, see our documentation on [instant mode](/docs/text-to-speech-tts/overview#ultra-low-latency-streaming-instant-mode).
-            - A [voice](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.utterances.voice) must be specified when instant mode is enabled. Dynamic voice generation is not supported with this mode.
-            - Instant mode is only supported for streaming endpoints (e.g., [/v0/tts/stream/json](/reference/text-to-speech-tts/synthesize-json-streaming), [/v0/tts/stream/file](/reference/text-to-speech-tts/synthesize-file-streaming)).
-            - Ensure only a single generation is requested ([num_generations](/reference/text-to-speech-tts/synthesize-json-streaming#request.body.num_generations) must be `1` or omitted).
 
         request_options : typing.Optional[RequestOptions]
             Request-specific configuration.
@@ -970,6 +1054,127 @@ class AsyncTtsClient:
             async for _chunk in r.data:
                 yield _chunk
 
+    async def convert_voice_file(
+        self,
+        *,
+        audio: core.File,
+        strip_headers: typing.Optional[bool] = OMIT,
+        context: typing.Optional[PostedContext] = OMIT,
+        voice: typing.Optional[PostedUtteranceVoice] = OMIT,
+        format: typing.Optional[Format] = OMIT,
+        include_timestamp_types: typing.Optional[typing.List[TimestampType]] = OMIT,
+        request_options: typing.Optional[RequestOptions] = None,
+    ) -> typing.AsyncIterator[bytes]:
+        """
+        Parameters
+        ----------
+        audio : core.File
+            See core.File for more documentation
+
+        strip_headers : typing.Optional[bool]
+            If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable).
+
+        context : typing.Optional[PostedContext]
+            Utterances to use as context for generating consistent speech style and prosody across multiple requests. These will not be converted to speech output.
+
+        voice : typing.Optional[PostedUtteranceVoice]
+
+        format : typing.Optional[Format]
+            Specifies the output audio file format.
+
+        include_timestamp_types : typing.Optional[typing.List[TimestampType]]
+            The set of timestamp types to include in the response. When used in multipart/form-data, specify each value using bracket notation: `include_timestamp_types[0]=word&include_timestamp_types[1]=phoneme`. Only supported for Octave 2 requests.
+
+        request_options : typing.Optional[RequestOptions]
+            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.
+
+        Returns
+        -------
+        typing.AsyncIterator[bytes]
+            Successful Response
+        """
+        async with self._raw_client.convert_voice_file(
+            audio=audio,
+            strip_headers=strip_headers,
+            context=context,
+            voice=voice,
+            format=format,
+            include_timestamp_types=include_timestamp_types,
+            request_options=request_options,
+        ) as r:
+            async for _chunk in r.data:
+                yield _chunk
+
+    async def convert_voice_json(
+        self,
+        *,
+        strip_headers: typing.Optional[bool] = OMIT,
+        audio: typing.Optional[core.File] = OMIT,
+        context: typing.Optional[PostedContext] = OMIT,
+        voice: typing.Optional[PostedUtteranceVoice] = OMIT,
+        format: typing.Optional[Format] = OMIT,
+        include_timestamp_types: typing.Optional[typing.List[TimestampType]] = OMIT,
+        request_options: typing.Optional[RequestOptions] = None,
+    ) -> typing.AsyncIterator[TtsOutput]:
+        """
+        Parameters
+        ----------
+        strip_headers : typing.Optional[bool]
+            If enabled, the audio for all the chunks of a generation, once concatenated together, will constitute a single audio file. Otherwise, if disabled, each chunk's audio will be its own audio file, each with its own headers (if applicable).
+
+        audio : typing.Optional[core.File]
+            See core.File for more documentation
+
+        context : typing.Optional[PostedContext]
+            Utterances to use as context for generating consistent speech style and prosody across multiple requests. These will not be converted to speech output.
+
+        voice : typing.Optional[PostedUtteranceVoice]
+
+        format : typing.Optional[Format]
+            Specifies the output audio file format.
+
+        include_timestamp_types : typing.Optional[typing.List[TimestampType]]
+            The set of timestamp types to include in the response. When used in multipart/form-data, specify each value using bracket notation: `include_timestamp_types[0]=word&include_timestamp_types[1]=phoneme`. Only supported for Octave 2 requests.
+
+        request_options : typing.Optional[RequestOptions]
+            Request-specific configuration.
+
+        Yields
+        ------
+        typing.AsyncIterator[TtsOutput]
+            Successful Response
+
+        Examples
+        --------
+        import asyncio
+
+        from hume import AsyncHumeClient
+
+        client = AsyncHumeClient(
+            api_key="YOUR_API_KEY",
+        )
+
+
+        async def main() -> None:
+            response = await client.tts.convert_voice_json()
+            async for chunk in response:
+                yield chunk
+
+
+        asyncio.run(main())
+        """
+        async with self._raw_client.convert_voice_json(
+            strip_headers=strip_headers,
+            audio=audio,
+            context=context,
+            voice=voice,
+            format=format,
+            include_timestamp_types=include_timestamp_types,
+            request_options=request_options,
+        ) as r:
+            async for _chunk in r.data:
+                yield _chunk
+
     @property
     def voices(self):
         if self._voices is None:
@@ -977,13 +1182,3 @@ class AsyncTtsClient:
 
             self._voices = AsyncVoicesClient(client_wrapper=self._client_wrapper)
         return self._voices
-
-    @property
-    def stream_input(self):
-        if self._stream_input is None:
-            from .stream_input.client import AsyncStreamInputClient
-
-            self._stream_input = AsyncStreamInputClient(
-                client_wrapper=self._client_wrapper,
-            )
-        return self._stream_input
