# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ...core.datetime_utils import serialize_datetime
from ...core.pydantic_utilities import deep_union_pydantic_dicts, pydantic_v1
from .emotion_score import EmotionScore
from .position_interval import PositionInterval
from .sentiment_score import SentimentScore
from .time_interval import TimeInterval
from .toxicity_score import ToxicityScore


class LanguagePrediction(pydantic_v1.BaseModel):
    text: str = pydantic_v1.Field()
    """
    A segment of text (like a word or a sentence).
    """

    position: PositionInterval
    time: typing.Optional[TimeInterval] = None
    confidence: typing.Optional[float] = pydantic_v1.Field(default=None)
    """
    Value between `0.0` and `1.0` that indicates our transcription model's relative confidence in this text.
    """

    speaker_confidence: typing.Optional[float] = pydantic_v1.Field(default=None)
    """
    Value between `0.0` and `1.0` that indicates our transcription model's relative confidence that this text was spoken by this speaker.
    """

    emotions: typing.List[EmotionScore] = pydantic_v1.Field()
    """
    A high-dimensional embedding in emotion space.
    """

    sentiment: typing.Optional[typing.List[SentimentScore]] = pydantic_v1.Field(default=None)
    """
    Sentiment predictions returned as a distribution. This model predicts the probability that a given text could be interpreted as having each sentiment level from `1` (negative) to `9` (positive).
    
    Compared to returning one estimate of sentiment, this enables a more nuanced analysis of a text's meaning. For example, a text with very neutral sentiment would have an average rating of `5`. But also a text that could be interpreted as having very positive sentiment or very negative sentiment would also have an average rating of `5`. The average sentiment is less informative than the distribution over sentiment, so this API returns a value for each sentiment level.
    """

    toxicity: typing.Optional[typing.List[ToxicityScore]] = pydantic_v1.Field(default=None)
    """
    Toxicity predictions returned as probabilities that the text can be classified into the following categories: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`.
    """

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults_exclude_unset: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        kwargs_with_defaults_exclude_none: typing.Any = {"by_alias": True, "exclude_none": True, **kwargs}

        return deep_union_pydantic_dicts(
            super().dict(**kwargs_with_defaults_exclude_unset), super().dict(**kwargs_with_defaults_exclude_none)
        )

    class Config:
        frozen = True
        smart_union = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
