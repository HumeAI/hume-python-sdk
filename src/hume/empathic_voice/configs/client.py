# This file was auto-generated by Fern from our API Definition.

import typing
from ...core.client_wrapper import SyncClientWrapper
from ...core.request_options import RequestOptions
from ..types.return_paged_configs import ReturnPagedConfigs
from ...core.pydantic_utilities import parse_obj_as
from json.decoder import JSONDecodeError
from ...core.api_error import ApiError
from ..types.posted_prompt_spec import PostedPromptSpec
from ..types.posted_voice import PostedVoice
from ..types.posted_language_model import PostedLanguageModel
from ..types.posted_ellm_model import PostedEllmModel
from ..types.posted_user_defined_tool_spec import PostedUserDefinedToolSpec
from ..types.posted_builtin_tool import PostedBuiltinTool
from ..types.posted_event_message_specs import PostedEventMessageSpecs
from ..types.posted_timeout_specs import PostedTimeoutSpecs
from ..types.return_config import ReturnConfig
from ...core.serialization import convert_and_respect_annotation_metadata
from ...core.jsonable_encoder import jsonable_encoder
from ...core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ConfigsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list_configs(
        self,
        *,
        page_number: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        restrict_to_most_recent: typing.Optional[bool] = None,
        name: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnPagedConfigs:
        """
        Parameters
        ----------
        page_number : typing.Optional[int]
            Specifies the page number to retrieve, enabling pagination.

            This parameter uses zero-based indexing. For example, setting `page_number` to 0 retrieves the first page of results (items 0-9 if `page_size` is 10), setting `page_number` to 1 retrieves the second page (items 10-19), and so on. Defaults to 0, which retrieves the first page.

        page_size : typing.Optional[int]
            Specifies the maximum number of results to include per page, enabling pagination. The value must be between 1 and 100, inclusive.

            For example, if `page_size` is set to 10, each page will include up to 10 items. Defaults to 10.

        restrict_to_most_recent : typing.Optional[bool]
            By default, `restrict_to_most_recent` is set to true, returning only the latest version of each config. To include all versions of each config in the list, set `restrict_to_most_recent` to false.

        name : typing.Optional[str]
            Filter to only include configs with this name.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnPagedConfigs
            Success

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.list_configs(
            page_number=0,
            page_size=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v0/evi/configs",
            method="GET",
            params={
                "page_number": page_number,
                "page_size": page_size,
                "restrict_to_most_recent": restrict_to_most_recent,
                "name": name,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnPagedConfigs,
                    parse_obj_as(
                        type_=ReturnPagedConfigs,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_config(
        self,
        *,
        name: str,
        version_description: typing.Optional[str] = OMIT,
        prompt: typing.Optional[PostedPromptSpec] = OMIT,
        voice: typing.Optional[PostedVoice] = OMIT,
        language_model: typing.Optional[PostedLanguageModel] = OMIT,
        ellm_model: typing.Optional[PostedEllmModel] = OMIT,
        tools: typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]] = OMIT,
        builtin_tools: typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]] = OMIT,
        event_messages: typing.Optional[PostedEventMessageSpecs] = OMIT,
        timeouts: typing.Optional[PostedTimeoutSpecs] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        name : str
            Name applied to all versions of a particular Config.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        prompt : typing.Optional[PostedPromptSpec]

        voice : typing.Optional[PostedVoice]
            A voice specification associated with this Config.

        language_model : typing.Optional[PostedLanguageModel]
            The supplemental language model associated with this Config.

            This model is used to generate longer, more detailed responses from EVI. Choosing an appropriate supplemental language model for your use case is crucial for generating fast, high-quality responses from EVI.

        ellm_model : typing.Optional[PostedEllmModel]
            The eLLM setup associated with this Config.

            Hume's eLLM (empathic Large Language Model) is a multimodal language model that takes into account both expression measures and language. The eLLM generates short, empathic language responses and guides text-to-speech (TTS) prosody.

        tools : typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]]
            List of user-defined tools associated with this Config.

        builtin_tools : typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]]
            List of built-in tools associated with this Config.

        event_messages : typing.Optional[PostedEventMessageSpecs]

        timeouts : typing.Optional[PostedTimeoutSpecs]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Created

        Examples
        --------
        from hume import HumeClient
        from hume.empathic_voice import (
            PostedEventMessageSpec,
            PostedEventMessageSpecs,
            PostedLanguageModel,
            PostedPromptSpec,
            PostedVoice,
        )

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.create_config(
            name="Weather Assistant Config",
            prompt=PostedPromptSpec(
                id="af699d45-2985-42cc-91b9-af9e5da3bac5",
                version=0,
            ),
            voice=PostedVoice(
                name="KORA",
            ),
            language_model=PostedLanguageModel(
                model_provider="ANTHROPIC",
                model_resource="claude-3-5-sonnet-20240620",
                temperature=1.0,
            ),
            event_messages=PostedEventMessageSpecs(
                on_new_chat=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
                on_inactivity_timeout=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
                on_max_duration_timeout=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v0/evi/configs",
            method="POST",
            json={
                "name": name,
                "version_description": version_description,
                "prompt": convert_and_respect_annotation_metadata(
                    object_=prompt, annotation=PostedPromptSpec, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=PostedVoice, direction="write"
                ),
                "language_model": convert_and_respect_annotation_metadata(
                    object_=language_model, annotation=PostedLanguageModel, direction="write"
                ),
                "ellm_model": convert_and_respect_annotation_metadata(
                    object_=ellm_model, annotation=PostedEllmModel, direction="write"
                ),
                "tools": convert_and_respect_annotation_metadata(
                    object_=tools,
                    annotation=typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]],
                    direction="write",
                ),
                "builtin_tools": convert_and_respect_annotation_metadata(
                    object_=builtin_tools,
                    annotation=typing.Sequence[typing.Optional[PostedBuiltinTool]],
                    direction="write",
                ),
                "event_messages": convert_and_respect_annotation_metadata(
                    object_=event_messages, annotation=PostedEventMessageSpecs, direction="write"
                ),
                "timeouts": convert_and_respect_annotation_metadata(
                    object_=timeouts, annotation=PostedTimeoutSpecs, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_config_versions(
        self,
        id: str,
        *,
        page_number: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        restrict_to_most_recent: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnPagedConfigs:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        page_number : typing.Optional[int]
            Specifies the page number to retrieve, enabling pagination.

            This parameter uses zero-based indexing. For example, setting `page_number` to 0 retrieves the first page of results (items 0-9 if `page_size` is 10), setting `page_number` to 1 retrieves the second page (items 10-19), and so on. Defaults to 0, which retrieves the first page.

        page_size : typing.Optional[int]
            Specifies the maximum number of results to include per page, enabling pagination. The value must be between 1 and 100, inclusive.

            For example, if `page_size` is set to 10, each page will include up to 10 items. Defaults to 10.

        restrict_to_most_recent : typing.Optional[bool]
            By default, `restrict_to_most_recent` is set to true, returning only the latest version of each config. To include all versions of each config in the list, set `restrict_to_most_recent` to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnPagedConfigs
            Success

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.list_config_versions(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="GET",
            params={
                "page_number": page_number,
                "page_size": page_size,
                "restrict_to_most_recent": restrict_to_most_recent,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnPagedConfigs,
                    parse_obj_as(
                        type_=ReturnPagedConfigs,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_config_version(
        self,
        id: str,
        *,
        version_description: typing.Optional[str] = OMIT,
        prompt: typing.Optional[PostedPromptSpec] = OMIT,
        voice: typing.Optional[PostedVoice] = OMIT,
        language_model: typing.Optional[PostedLanguageModel] = OMIT,
        ellm_model: typing.Optional[PostedEllmModel] = OMIT,
        tools: typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]] = OMIT,
        builtin_tools: typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]] = OMIT,
        event_messages: typing.Optional[PostedEventMessageSpecs] = OMIT,
        timeouts: typing.Optional[PostedTimeoutSpecs] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        prompt : typing.Optional[PostedPromptSpec]

        voice : typing.Optional[PostedVoice]
            A voice specification associated with this Config version.

        language_model : typing.Optional[PostedLanguageModel]
            The supplemental language model associated with this Config version.

            This model is used to generate longer, more detailed responses from EVI. Choosing an appropriate supplemental language model for your use case is crucial for generating fast, high-quality responses from EVI.

        ellm_model : typing.Optional[PostedEllmModel]
            The eLLM setup associated with this Config version.

            Hume's eLLM (empathic Large Language Model) is a multimodal language model that takes into account both expression measures and language. The eLLM generates short, empathic language responses and guides text-to-speech (TTS) prosody.

        tools : typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]]
            List of user-defined tools associated with this Config version.

        builtin_tools : typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]]
            List of built-in tools associated with this Config version.

        event_messages : typing.Optional[PostedEventMessageSpecs]

        timeouts : typing.Optional[PostedTimeoutSpecs]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Created

        Examples
        --------
        from hume import HumeClient
        from hume.empathic_voice import (
            PostedEllmModel,
            PostedEventMessageSpec,
            PostedEventMessageSpecs,
            PostedLanguageModel,
            PostedPromptSpec,
            PostedVoice,
        )

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.create_config_version(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            version_description="This is an updated version of the Weather Assistant Config.",
            prompt=PostedPromptSpec(
                id="af699d45-2985-42cc-91b9-af9e5da3bac5",
                version=0,
            ),
            voice=PostedVoice(
                name="ITO",
            ),
            language_model=PostedLanguageModel(
                model_provider="ANTHROPIC",
                model_resource="claude-3-5-sonnet-20240620",
                temperature=1.0,
            ),
            ellm_model=PostedEllmModel(
                allow_short_responses=True,
            ),
            event_messages=PostedEventMessageSpecs(
                on_new_chat=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
                on_inactivity_timeout=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
                on_max_duration_timeout=PostedEventMessageSpec(
                    enabled=False,
                    text="",
                ),
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="POST",
            json={
                "version_description": version_description,
                "prompt": convert_and_respect_annotation_metadata(
                    object_=prompt, annotation=PostedPromptSpec, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=PostedVoice, direction="write"
                ),
                "language_model": convert_and_respect_annotation_metadata(
                    object_=language_model, annotation=PostedLanguageModel, direction="write"
                ),
                "ellm_model": convert_and_respect_annotation_metadata(
                    object_=ellm_model, annotation=PostedEllmModel, direction="write"
                ),
                "tools": convert_and_respect_annotation_metadata(
                    object_=tools,
                    annotation=typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]],
                    direction="write",
                ),
                "builtin_tools": convert_and_respect_annotation_metadata(
                    object_=builtin_tools,
                    annotation=typing.Sequence[typing.Optional[PostedBuiltinTool]],
                    direction="write",
                ),
                "event_messages": convert_and_respect_annotation_metadata(
                    object_=event_messages, annotation=PostedEventMessageSpecs, direction="write"
                ),
                "timeouts": convert_and_respect_annotation_metadata(
                    object_=timeouts, annotation=PostedTimeoutSpecs, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_config(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.delete_config(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_config_name(self, id: str, *, name: str, request_options: typing.Optional[RequestOptions] = None) -> str:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        name : str
            Name applied to all versions of a particular Config.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        str
            Success

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.update_config_name(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            name="Updated Weather Assistant Config Name",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "name": name,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return _response.text  # type: ignore
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_config_version(
        self, id: str, version: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Success

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.get_config_version(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            version=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_config_version(
        self, id: str, version: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.delete_config_version(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            version=1,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_config_description(
        self,
        id: str,
        version: int,
        *,
        version_description: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Success

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.configs.update_config_description(
            id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            version=1,
            version_description="This is an updated version_description.",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="PATCH",
            json={
                "version_description": version_description,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncConfigsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list_configs(
        self,
        *,
        page_number: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        restrict_to_most_recent: typing.Optional[bool] = None,
        name: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnPagedConfigs:
        """
        Parameters
        ----------
        page_number : typing.Optional[int]
            Specifies the page number to retrieve, enabling pagination.

            This parameter uses zero-based indexing. For example, setting `page_number` to 0 retrieves the first page of results (items 0-9 if `page_size` is 10), setting `page_number` to 1 retrieves the second page (items 10-19), and so on. Defaults to 0, which retrieves the first page.

        page_size : typing.Optional[int]
            Specifies the maximum number of results to include per page, enabling pagination. The value must be between 1 and 100, inclusive.

            For example, if `page_size` is set to 10, each page will include up to 10 items. Defaults to 10.

        restrict_to_most_recent : typing.Optional[bool]
            By default, `restrict_to_most_recent` is set to true, returning only the latest version of each config. To include all versions of each config in the list, set `restrict_to_most_recent` to false.

        name : typing.Optional[str]
            Filter to only include configs with this name.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnPagedConfigs
            Success

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.list_configs(
                page_number=0,
                page_size=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v0/evi/configs",
            method="GET",
            params={
                "page_number": page_number,
                "page_size": page_size,
                "restrict_to_most_recent": restrict_to_most_recent,
                "name": name,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnPagedConfigs,
                    parse_obj_as(
                        type_=ReturnPagedConfigs,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_config(
        self,
        *,
        name: str,
        version_description: typing.Optional[str] = OMIT,
        prompt: typing.Optional[PostedPromptSpec] = OMIT,
        voice: typing.Optional[PostedVoice] = OMIT,
        language_model: typing.Optional[PostedLanguageModel] = OMIT,
        ellm_model: typing.Optional[PostedEllmModel] = OMIT,
        tools: typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]] = OMIT,
        builtin_tools: typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]] = OMIT,
        event_messages: typing.Optional[PostedEventMessageSpecs] = OMIT,
        timeouts: typing.Optional[PostedTimeoutSpecs] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        name : str
            Name applied to all versions of a particular Config.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        prompt : typing.Optional[PostedPromptSpec]

        voice : typing.Optional[PostedVoice]
            A voice specification associated with this Config.

        language_model : typing.Optional[PostedLanguageModel]
            The supplemental language model associated with this Config.

            This model is used to generate longer, more detailed responses from EVI. Choosing an appropriate supplemental language model for your use case is crucial for generating fast, high-quality responses from EVI.

        ellm_model : typing.Optional[PostedEllmModel]
            The eLLM setup associated with this Config.

            Hume's eLLM (empathic Large Language Model) is a multimodal language model that takes into account both expression measures and language. The eLLM generates short, empathic language responses and guides text-to-speech (TTS) prosody.

        tools : typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]]
            List of user-defined tools associated with this Config.

        builtin_tools : typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]]
            List of built-in tools associated with this Config.

        event_messages : typing.Optional[PostedEventMessageSpecs]

        timeouts : typing.Optional[PostedTimeoutSpecs]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Created

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient
        from hume.empathic_voice import (
            PostedEventMessageSpec,
            PostedEventMessageSpecs,
            PostedLanguageModel,
            PostedPromptSpec,
            PostedVoice,
        )

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.create_config(
                name="Weather Assistant Config",
                prompt=PostedPromptSpec(
                    id="af699d45-2985-42cc-91b9-af9e5da3bac5",
                    version=0,
                ),
                voice=PostedVoice(
                    name="KORA",
                ),
                language_model=PostedLanguageModel(
                    model_provider="ANTHROPIC",
                    model_resource="claude-3-5-sonnet-20240620",
                    temperature=1.0,
                ),
                event_messages=PostedEventMessageSpecs(
                    on_new_chat=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                    on_inactivity_timeout=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                    on_max_duration_timeout=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v0/evi/configs",
            method="POST",
            json={
                "name": name,
                "version_description": version_description,
                "prompt": convert_and_respect_annotation_metadata(
                    object_=prompt, annotation=PostedPromptSpec, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=PostedVoice, direction="write"
                ),
                "language_model": convert_and_respect_annotation_metadata(
                    object_=language_model, annotation=PostedLanguageModel, direction="write"
                ),
                "ellm_model": convert_and_respect_annotation_metadata(
                    object_=ellm_model, annotation=PostedEllmModel, direction="write"
                ),
                "tools": convert_and_respect_annotation_metadata(
                    object_=tools,
                    annotation=typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]],
                    direction="write",
                ),
                "builtin_tools": convert_and_respect_annotation_metadata(
                    object_=builtin_tools,
                    annotation=typing.Sequence[typing.Optional[PostedBuiltinTool]],
                    direction="write",
                ),
                "event_messages": convert_and_respect_annotation_metadata(
                    object_=event_messages, annotation=PostedEventMessageSpecs, direction="write"
                ),
                "timeouts": convert_and_respect_annotation_metadata(
                    object_=timeouts, annotation=PostedTimeoutSpecs, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_config_versions(
        self,
        id: str,
        *,
        page_number: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        restrict_to_most_recent: typing.Optional[bool] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnPagedConfigs:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        page_number : typing.Optional[int]
            Specifies the page number to retrieve, enabling pagination.

            This parameter uses zero-based indexing. For example, setting `page_number` to 0 retrieves the first page of results (items 0-9 if `page_size` is 10), setting `page_number` to 1 retrieves the second page (items 10-19), and so on. Defaults to 0, which retrieves the first page.

        page_size : typing.Optional[int]
            Specifies the maximum number of results to include per page, enabling pagination. The value must be between 1 and 100, inclusive.

            For example, if `page_size` is set to 10, each page will include up to 10 items. Defaults to 10.

        restrict_to_most_recent : typing.Optional[bool]
            By default, `restrict_to_most_recent` is set to true, returning only the latest version of each config. To include all versions of each config in the list, set `restrict_to_most_recent` to false.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnPagedConfigs
            Success

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.list_config_versions(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="GET",
            params={
                "page_number": page_number,
                "page_size": page_size,
                "restrict_to_most_recent": restrict_to_most_recent,
            },
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnPagedConfigs,
                    parse_obj_as(
                        type_=ReturnPagedConfigs,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_config_version(
        self,
        id: str,
        *,
        version_description: typing.Optional[str] = OMIT,
        prompt: typing.Optional[PostedPromptSpec] = OMIT,
        voice: typing.Optional[PostedVoice] = OMIT,
        language_model: typing.Optional[PostedLanguageModel] = OMIT,
        ellm_model: typing.Optional[PostedEllmModel] = OMIT,
        tools: typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]] = OMIT,
        builtin_tools: typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]] = OMIT,
        event_messages: typing.Optional[PostedEventMessageSpecs] = OMIT,
        timeouts: typing.Optional[PostedTimeoutSpecs] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        prompt : typing.Optional[PostedPromptSpec]

        voice : typing.Optional[PostedVoice]
            A voice specification associated with this Config version.

        language_model : typing.Optional[PostedLanguageModel]
            The supplemental language model associated with this Config version.

            This model is used to generate longer, more detailed responses from EVI. Choosing an appropriate supplemental language model for your use case is crucial for generating fast, high-quality responses from EVI.

        ellm_model : typing.Optional[PostedEllmModel]
            The eLLM setup associated with this Config version.

            Hume's eLLM (empathic Large Language Model) is a multimodal language model that takes into account both expression measures and language. The eLLM generates short, empathic language responses and guides text-to-speech (TTS) prosody.

        tools : typing.Optional[typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]]]
            List of user-defined tools associated with this Config version.

        builtin_tools : typing.Optional[typing.Sequence[typing.Optional[PostedBuiltinTool]]]
            List of built-in tools associated with this Config version.

        event_messages : typing.Optional[PostedEventMessageSpecs]

        timeouts : typing.Optional[PostedTimeoutSpecs]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Created

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient
        from hume.empathic_voice import (
            PostedEllmModel,
            PostedEventMessageSpec,
            PostedEventMessageSpecs,
            PostedLanguageModel,
            PostedPromptSpec,
            PostedVoice,
        )

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.create_config_version(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
                version_description="This is an updated version of the Weather Assistant Config.",
                prompt=PostedPromptSpec(
                    id="af699d45-2985-42cc-91b9-af9e5da3bac5",
                    version=0,
                ),
                voice=PostedVoice(
                    name="ITO",
                ),
                language_model=PostedLanguageModel(
                    model_provider="ANTHROPIC",
                    model_resource="claude-3-5-sonnet-20240620",
                    temperature=1.0,
                ),
                ellm_model=PostedEllmModel(
                    allow_short_responses=True,
                ),
                event_messages=PostedEventMessageSpecs(
                    on_new_chat=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                    on_inactivity_timeout=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                    on_max_duration_timeout=PostedEventMessageSpec(
                        enabled=False,
                        text="",
                    ),
                ),
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="POST",
            json={
                "version_description": version_description,
                "prompt": convert_and_respect_annotation_metadata(
                    object_=prompt, annotation=PostedPromptSpec, direction="write"
                ),
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=PostedVoice, direction="write"
                ),
                "language_model": convert_and_respect_annotation_metadata(
                    object_=language_model, annotation=PostedLanguageModel, direction="write"
                ),
                "ellm_model": convert_and_respect_annotation_metadata(
                    object_=ellm_model, annotation=PostedEllmModel, direction="write"
                ),
                "tools": convert_and_respect_annotation_metadata(
                    object_=tools,
                    annotation=typing.Sequence[typing.Optional[PostedUserDefinedToolSpec]],
                    direction="write",
                ),
                "builtin_tools": convert_and_respect_annotation_metadata(
                    object_=builtin_tools,
                    annotation=typing.Sequence[typing.Optional[PostedBuiltinTool]],
                    direction="write",
                ),
                "event_messages": convert_and_respect_annotation_metadata(
                    object_=event_messages, annotation=PostedEventMessageSpecs, direction="write"
                ),
                "timeouts": convert_and_respect_annotation_metadata(
                    object_=timeouts, annotation=PostedTimeoutSpecs, direction="write"
                ),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_config(self, id: str, *, request_options: typing.Optional[RequestOptions] = None) -> None:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.delete_config(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_config_name(
        self, id: str, *, name: str, request_options: typing.Optional[RequestOptions] = None
    ) -> str:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        name : str
            Name applied to all versions of a particular Config.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        str
            Success

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.update_config_name(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
                name="Updated Weather Assistant Config Name",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}",
            method="PATCH",
            json={
                "name": name,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return _response.text  # type: ignore
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_config_version(
        self, id: str, version: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Success

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.get_config_version(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
                version=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_config_version(
        self, id: str, version: int, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.delete_config_version(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
                version=1,
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                return
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_config_description(
        self,
        id: str,
        version: int,
        *,
        version_description: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ReturnConfig:
        """
        Parameters
        ----------
        id : str
            Identifier for a Config. Formatted as a UUID.

        version : int
            Version number for a Config.

            Configs, as well as Prompts and Tools, are versioned. This versioning system supports iterative development, allowing you to progressively refine configurations and revert to previous versions if needed.

            Version numbers are integer values representing different iterations of the Config. Each update to the Config increments its version number.

        version_description : typing.Optional[str]
            An optional description of the Config version.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ReturnConfig
            Success

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.configs.update_config_description(
                id="1b60e1a0-cc59-424a-8d2c-189d354db3f3",
                version=1,
                version_description="This is an updated version_description.",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v0/evi/configs/{jsonable_encoder(id)}/version/{jsonable_encoder(version)}",
            method="PATCH",
            json={
                "version_description": version_description,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    ReturnConfig,
                    parse_obj_as(
                        type_=ReturnConfig,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
