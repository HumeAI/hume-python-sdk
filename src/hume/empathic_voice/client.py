# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from .chat_groups.client import AsyncChatGroupsClient, ChatGroupsClient
from .chats.client import AsyncChatsClient, ChatsClient
from .configs.client import AsyncConfigsClient, ConfigsClient
from .prompts.client import AsyncPromptsClient, PromptsClient
from .raw_client import AsyncRawEmpathicVoiceClient, RawEmpathicVoiceClient
from .tools.client import AsyncToolsClient, ToolsClient
from .types.supports_tool_use import SupportsToolUse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class EmpathicVoiceClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawEmpathicVoiceClient(client_wrapper=client_wrapper)
        self.tools = ToolsClient(client_wrapper=client_wrapper)

        self.prompts = PromptsClient(client_wrapper=client_wrapper)

        self.configs = ConfigsClient(client_wrapper=client_wrapper)

        self.chats = ChatsClient(client_wrapper=client_wrapper)

        self.chat_groups = ChatGroupsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawEmpathicVoiceClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawEmpathicVoiceClient
        """
        return self._raw_client

    def custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
        self, *, model_resource: str, request_options: typing.Optional[RequestOptions] = None
    ) -> SupportsToolUse:
        """
        Parameters
        ----------
        model_resource : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SupportsToolUse
            Successful Response

        Examples
        --------
        from hume import HumeClient

        client = HumeClient(
            api_key="YOUR_API_KEY",
        )
        client.empathic_voice.custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
            model_resource="model_resource",
        )
        """
        _response = self._raw_client.custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
            model_resource=model_resource, request_options=request_options
        )
        return _response.data


class AsyncEmpathicVoiceClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawEmpathicVoiceClient(client_wrapper=client_wrapper)
        self.tools = AsyncToolsClient(client_wrapper=client_wrapper)

        self.prompts = AsyncPromptsClient(client_wrapper=client_wrapper)

        self.configs = AsyncConfigsClient(client_wrapper=client_wrapper)

        self.chats = AsyncChatsClient(client_wrapper=client_wrapper)

        self.chat_groups = AsyncChatGroupsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawEmpathicVoiceClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawEmpathicVoiceClient
        """
        return self._raw_client

    async def custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
        self, *, model_resource: str, request_options: typing.Optional[RequestOptions] = None
    ) -> SupportsToolUse:
        """
        Parameters
        ----------
        model_resource : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SupportsToolUse
            Successful Response

        Examples
        --------
        import asyncio

        from hume import AsyncHumeClient

        client = AsyncHumeClient(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.empathic_voice.custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
                model_resource="model_resource",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.custom_language_model_supports_tool_use_v_0_evi_custom_language_model_supports_tool_use_post(
            model_resource=model_resource, request_options=request_options
        )
        return _response.data
