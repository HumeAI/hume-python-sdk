{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#requirements","title":"Requirements","text":"<p>Python versions 3.9, 3.10, and 3.11 are supported</p>"},{"location":"#installation","title":"Installation","text":"<p>Basic installation:</p> <pre><code>pip install hume\n</code></pre>"},{"location":"#requirements_1","title":"Requirements","text":"<p>To use the basic functionality of <code>HumeVoiceClient</code>, <code>HumeBatchClient</code> or <code>HumeStreamClient</code> there are no additional system dependencies, however using the audio playback functionality of the EVI <code>MicrophoneInterface</code> may require a few extra dependencies depending on your operating system.</p>"},{"location":"#linux","title":"Linux","text":"<ul> <li><code>libasound2-dev</code></li> <li><code>libportaudio2</code></li> </ul> <p>You can install these dependencies with:</p> <pre><code>sudo apt-get --yes update\nsudo apt-get --yes install libasound2-dev libportaudio2\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Jupyter example notebooks can be found in the Python SDK GitHub repo.</p>"},{"location":"#stream-an-evi-chat-session","title":"Stream an EVI chat session","text":"<p>Start a new session using your device's microphone:</p> <p>Note: to use audio playback functionality in the MicrophoneInterface run <code>pip install hume[microphone]</code></p> <pre><code>import asyncio\n\nfrom hume import HumeVoiceClient, MicrophoneInterface\n\nasync def main() -&gt; None:\n    client = HumeVoiceClient(\"&lt;your-api-key&gt;\")\n\n    async with client.connect() as socket:\n        await MicrophoneInterface.start(socket)\n\nasyncio.run(main())\n</code></pre> <p>Using a custom voice config:</p> <pre><code>import asyncio\n\nfrom hume import HumeVoiceClient, MicrophoneInterface\n\nasync def main() -&gt; None:\n    client = HumeVoiceClient(\"&lt;your-api-key&gt;\")\n\n    async with client.connect(config_id=\"&lt;your-config-id&gt;\") as socket:\n        await MicrophoneInterface.start(socket)\n\nasyncio.run(main())\n</code></pre>"},{"location":"#managing-voice-configs","title":"Managing voice configs","text":"<p>Create a new config:</p> <pre><code>from hume import HumeVoiceClient, VoiceConfig\n\nclient = HumeVoiceClient(\"&lt;your-api-key\"&gt;)\nconfig: VoiceConfig = client.create_config(\n    name=f\"silly-poet\",\n    prompt=\"you are a silly poet\",\n)\nprint(\"Created config: \", config.id)\n</code></pre> <p>Get an existing config:</p> <pre><code>from hume import HumeVoiceClient\n\nclient = HumeVoiceClient(\"&lt;your-api-key\"&gt;)\nconfig = client.get_config(\"&lt;YOUR CONFIG ID&gt;\")\nprint(\"Fetched config: \", config.name)\n</code></pre> <p>List all your configs:</p> <pre><code>from hume import HumeVoiceClient\n\nclient = HumeVoiceClient(\"&lt;your-api-key\"&gt;)\nfor config in client.iter_configs():\n    print(f\"- {config.name} ({config.id})\")\n</code></pre> <p>Delete a config:</p> <pre><code>from hume import HumeVoiceClient\n\nclient = HumeVoiceClient(\"&lt;your-api-key\"&gt;)\nclient.delete_config(\"&lt;YOUR CONFIG ID&gt;\")\n</code></pre>"},{"location":"#submit-a-new-batch-job","title":"Submit a new batch job","text":"<p>Note: Your personal API key can be found in the profile section of beta.hume.ai</p> <pre><code>from hume import HumeBatchClient\nfrom hume.models.config import FaceConfig\nfrom hume.models.config import ProsodyConfig\n\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\nurls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\nconfigs = [FaceConfig(identify_faces=True), ProsodyConfig()]\njob = client.submit_job(urls, configs)\n\nprint(job)\nprint(\"Running...\")\n\njob.await_complete()\njob.download_predictions(\"predictions.json\")\nprint(\"Predictions downloaded to predictions.json\")\n\njob.download_artifacts(\"artifacts.zip\")\nprint(\"Artifacts downloaded to artifacts.zip\")\n</code></pre> <p>Note: You can also supply a local filepath when submitting a batch job. Check it out in a Jupyter notebook here.</p>"},{"location":"#rehydrate-a-batch-job-from-a-job-id","title":"Rehydrate a batch job from a job ID","text":"<pre><code>from hume import HumeBatchClient\n\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\n\njob_id = \"&lt;your-job-id&gt;\"\njob = client.get_job(job_id)\n\nprint(job)\n</code></pre>"},{"location":"#stream-predictions-over-a-websocket","title":"Stream predictions over a WebSocket","text":"<pre><code>import asyncio\n\nfrom hume import HumeStreamClient\nfrom hume.models.config import BurstConfig\nfrom hume.models.config import ProsodyConfig\n\nasync def main():\n    client = HumeStreamClient(\"&lt;your-api-key&gt;\")\n    configs = [BurstConfig(), ProsodyConfig()]\n    async with client.connect(configs) as socket:\n        result = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\n        print(result)\n\nasyncio.run(main())\n</code></pre>"},{"location":"#other-resources","title":"Other Resources","text":"<ul> <li>Hume AI Homepage</li> <li>Platform Documentation</li> <li>API Reference</li> </ul>"},{"location":"#support","title":"Support","text":"<p>The Python SDK is open source! More details can be found on GitHub.</p> <p>If you've found a bug with this SDK please open an issue!</p>"},{"location":"batch/batch-job-details/","title":"BatchJobDetails","text":"<p>Batch job details.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>class BatchJobDetails:\n    \"\"\"Batch job details.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        configs: Dict[ModelType, ModelConfigBase],\n        urls: List[str],\n        files: List[str],\n        text: Optional[List[str]] = None,\n        state: BatchJobState,\n        callback_url: Optional[str] = None,\n        notify: bool = False,\n    ):\n        \"\"\"Construct a BatchJobDetails.\n\n        Args:\n            configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`.\n            urls (List[str]): URLs processed in the `BatchJob`.\n            files (List[str]): Files processed in the `BatchJob`.\n            text (Optional[List[str]]): Raw text processed in the `BatchJob`.\n            state (BatchJobState): State of `BatchJob`.\n            callback_url (Optional[str]): A URL to which a POST request is sent upon job completion.\n            notify (bool): Whether an email notification should be sent upon job completion.\n        \"\"\"\n        self.configs = configs\n        self.urls = urls\n        self.files = files\n        self.text = text\n        self.state = state\n        self.callback_url = callback_url\n        self.notify = notify\n\n    @classmethod\n    def from_response(cls, response: Any) -&gt; \"BatchJobDetails\":\n        \"\"\"Construct a `BatchJobDetails` from a batch API job response.\n\n        Args:\n            response (Any): Batch API job response.\n\n        Returns:\n            BatchJobDetails: A `BatchJobDetails` based on a batch API job response.\n        \"\"\"\n        try:\n            request = response[\"request\"]\n\n            configs = {}\n            for model_name, config_dict in request[\"models\"].items():\n                if config_dict is None:\n                    continue\n                model_type = ModelType.from_str(model_name)\n                config = config_from_model_type(model_type).from_dict(config_dict)\n                configs[model_type] = config\n\n            urls = request[\"urls\"]\n            files = request[\"files\"]\n            text = request[\"text\"]\n            callback_url = request[\"callback_url\"]\n            notify = request[\"notify\"]\n\n            state_dict = response[\"state\"]\n            state = BatchJobState(\n                status=BatchJobStatus.from_str(state_dict[\"status\"]),\n                created_timestamp_ms=state_dict.get(\"created_timestamp_ms\"),\n                started_timestamp_ms=state_dict.get(\"started_timestamp_ms\"),\n                ended_timestamp_ms=state_dict.get(\"ended_timestamp_ms\"),\n            )\n\n            return cls(\n                configs=configs,\n                urls=urls,\n                files=files,\n                text=text,\n                state=state,\n                callback_url=callback_url,\n                notify=notify,\n            )\n        # pylint: disable=broad-except\n        except Exception as exc:\n            message = cls._get_invalid_response_message(response)\n            raise HumeClientException(message) from exc\n\n    @classmethod\n    def _get_invalid_response_message(cls, response: Any) -&gt; str:\n        response_str = json.dumps(response)\n        message = f\"Could not parse response into BatchJobDetails: {response_str}\"\n\n        # Check for invalid API key\n        if \"fault\" in response and \"faultstring\" in response[\"fault\"]:\n            fault_string = response[\"fault\"][\"faultstring\"]\n            if fault_string == \"Invalid ApiKey\":\n                message = \"HumeBatchClient initialized with invalid API key.\"\n\n        return message\n\n    def get_status(self) -&gt; BatchJobStatus:\n        \"\"\"Get the status of the job.\n\n        Returns:\n            BatchJobStatus: The status of the `BatchJob`.\n        \"\"\"\n        return self.state.status\n\n    def get_run_time_ms(self) -&gt; Optional[int]:\n        \"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state.\n\n        Returns:\n            Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal\n                state then `None` is returned.\n        \"\"\"\n        if self.state.started_timestamp_ms is not None and self.state.ended_timestamp_ms is not None:\n            return self.state.ended_timestamp_ms - self.state.started_timestamp_ms\n        return None\n\n    def get_created_time(self) -&gt; Optional[datetime]:\n        \"\"\"Get the time the job was created.\n\n        Returns:\n            Optional[datetime]: Datetime when the job was created. If the job has not started\n                then `None` is returned.\n        \"\"\"\n        if self.state.created_timestamp_ms is None:\n            return None\n        return datetime.utcfromtimestamp(self.state.created_timestamp_ms / 1000)\n\n    def get_started_time(self) -&gt; Optional[datetime]:\n        \"\"\"Get the time the job started running.\n\n        Returns:\n            Optional[datetime]: Datetime when the job started running. If the job has not started\n                then `None` is returned.\n        \"\"\"\n        if self.state.started_timestamp_ms is None:\n            return None\n        return datetime.utcfromtimestamp(self.state.started_timestamp_ms / 1000)\n\n    def get_ended_time(self) -&gt; Optional[datetime]:\n        \"\"\"Get the time the job stopped running if the job is in a terminal state.\n\n        Returns:\n            Optional[datetime]: Datetime when the job started running. If the job is not in a terminal\n                state then `None` is returned.\n        \"\"\"\n        if self.state.ended_timestamp_ms is None:\n            return None\n        return datetime.utcfromtimestamp(self.state.ended_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.__init__","title":"<code>__init__(*, configs, urls, files, text=None, state, callback_url=None, notify=False)</code>","text":"<p>Construct a BatchJobDetails.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>Dict[ModelType, ModelConfigBase]</code> <p>Configurations for the <code>BatchJob</code>.</p> required <code>urls</code> <code>List[str]</code> <p>URLs processed in the <code>BatchJob</code>.</p> required <code>files</code> <code>List[str]</code> <p>Files processed in the <code>BatchJob</code>.</p> required <code>text</code> <code>Optional[List[str]]</code> <p>Raw text processed in the <code>BatchJob</code>.</p> <code>None</code> <code>state</code> <code>BatchJobState</code> <p>State of <code>BatchJob</code>.</p> required <code>callback_url</code> <code>Optional[str]</code> <p>A URL to which a POST request is sent upon job completion.</p> <code>None</code> <code>notify</code> <code>bool</code> <p>Whether an email notification should be sent upon job completion.</p> <code>False</code> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def __init__(\n    self,\n    *,\n    configs: Dict[ModelType, ModelConfigBase],\n    urls: List[str],\n    files: List[str],\n    text: Optional[List[str]] = None,\n    state: BatchJobState,\n    callback_url: Optional[str] = None,\n    notify: bool = False,\n):\n    \"\"\"Construct a BatchJobDetails.\n\n    Args:\n        configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`.\n        urls (List[str]): URLs processed in the `BatchJob`.\n        files (List[str]): Files processed in the `BatchJob`.\n        text (Optional[List[str]]): Raw text processed in the `BatchJob`.\n        state (BatchJobState): State of `BatchJob`.\n        callback_url (Optional[str]): A URL to which a POST request is sent upon job completion.\n        notify (bool): Whether an email notification should be sent upon job completion.\n    \"\"\"\n    self.configs = configs\n    self.urls = urls\n    self.files = files\n    self.text = text\n    self.state = state\n    self.callback_url = callback_url\n    self.notify = notify\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.from_response","title":"<code>from_response(response)</code>  <code>classmethod</code>","text":"<p>Construct a <code>BatchJobDetails</code> from a batch API job response.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>Any</code> <p>Batch API job response.</p> required <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>A <code>BatchJobDetails</code> based on a batch API job response.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>@classmethod\ndef from_response(cls, response: Any) -&gt; \"BatchJobDetails\":\n    \"\"\"Construct a `BatchJobDetails` from a batch API job response.\n\n    Args:\n        response (Any): Batch API job response.\n\n    Returns:\n        BatchJobDetails: A `BatchJobDetails` based on a batch API job response.\n    \"\"\"\n    try:\n        request = response[\"request\"]\n\n        configs = {}\n        for model_name, config_dict in request[\"models\"].items():\n            if config_dict is None:\n                continue\n            model_type = ModelType.from_str(model_name)\n            config = config_from_model_type(model_type).from_dict(config_dict)\n            configs[model_type] = config\n\n        urls = request[\"urls\"]\n        files = request[\"files\"]\n        text = request[\"text\"]\n        callback_url = request[\"callback_url\"]\n        notify = request[\"notify\"]\n\n        state_dict = response[\"state\"]\n        state = BatchJobState(\n            status=BatchJobStatus.from_str(state_dict[\"status\"]),\n            created_timestamp_ms=state_dict.get(\"created_timestamp_ms\"),\n            started_timestamp_ms=state_dict.get(\"started_timestamp_ms\"),\n            ended_timestamp_ms=state_dict.get(\"ended_timestamp_ms\"),\n        )\n\n        return cls(\n            configs=configs,\n            urls=urls,\n            files=files,\n            text=text,\n            state=state,\n            callback_url=callback_url,\n            notify=notify,\n        )\n    # pylint: disable=broad-except\n    except Exception as exc:\n        message = cls._get_invalid_response_message(response)\n        raise HumeClientException(message) from exc\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.get_created_time","title":"<code>get_created_time()</code>","text":"<p>Get the time the job was created.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job was created. If the job has not started then <code>None</code> is returned.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def get_created_time(self) -&gt; Optional[datetime]:\n    \"\"\"Get the time the job was created.\n\n    Returns:\n        Optional[datetime]: Datetime when the job was created. If the job has not started\n            then `None` is returned.\n    \"\"\"\n    if self.state.created_timestamp_ms is None:\n        return None\n    return datetime.utcfromtimestamp(self.state.created_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.get_ended_time","title":"<code>get_ended_time()</code>","text":"<p>Get the time the job stopped running if the job is in a terminal state.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then <code>None</code> is returned.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def get_ended_time(self) -&gt; Optional[datetime]:\n    \"\"\"Get the time the job stopped running if the job is in a terminal state.\n\n    Returns:\n        Optional[datetime]: Datetime when the job started running. If the job is not in a terminal\n            state then `None` is returned.\n    \"\"\"\n    if self.state.ended_timestamp_ms is None:\n        return None\n    return datetime.utcfromtimestamp(self.state.ended_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.get_run_time_ms","title":"<code>get_run_time_ms()</code>","text":"<p>Get the total time in milliseconds it took for the job to run if the job is in a terminal state.</p> <p>Returns:</p> Type Description <code>Optional[int]</code> <p>Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then <code>None</code> is returned.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def get_run_time_ms(self) -&gt; Optional[int]:\n    \"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state.\n\n    Returns:\n        Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal\n            state then `None` is returned.\n    \"\"\"\n    if self.state.started_timestamp_ms is not None and self.state.ended_timestamp_ms is not None:\n        return self.state.ended_timestamp_ms - self.state.started_timestamp_ms\n    return None\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.get_started_time","title":"<code>get_started_time()</code>","text":"<p>Get the time the job started running.</p> <p>Returns:</p> Type Description <code>Optional[datetime]</code> <p>Optional[datetime]: Datetime when the job started running. If the job has not started then <code>None</code> is returned.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def get_started_time(self) -&gt; Optional[datetime]:\n    \"\"\"Get the time the job started running.\n\n    Returns:\n        Optional[datetime]: Datetime when the job started running. If the job has not started\n            then `None` is returned.\n    \"\"\"\n    if self.state.started_timestamp_ms is None:\n        return None\n    return datetime.utcfromtimestamp(self.state.started_timestamp_ms / 1000)\n</code></pre>"},{"location":"batch/batch-job-details/#hume._measurement.batch.batch_job_details.BatchJobDetails.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the job.</p> <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The status of the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job_details.py</code> <pre><code>def get_status(self) -&gt; BatchJobStatus:\n    \"\"\"Get the status of the job.\n\n    Returns:\n        BatchJobStatus: The status of the `BatchJob`.\n    \"\"\"\n    return self.state.status\n</code></pre>"},{"location":"batch/batch-job-state/","title":"BatchJobState","text":"<p>Batch job state.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>BatchJobStatus</code> <p>Status of the batch job.</p> required <code>created_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job was created.</p> required <code>started_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job started.</p> required <code>ended_timestamp_ms</code> <code>Optional[int]</code> <p>Time when job ended.</p> required Source code in <code>hume/_measurement/batch/batch_job_state.py</code> <pre><code>@dataclass\nclass BatchJobState:\n    \"\"\"Batch job state.\n\n    Args:\n        status (BatchJobStatus): Status of the batch job.\n        created_timestamp_ms (Optional[int]): Time when job was created.\n        started_timestamp_ms (Optional[int]): Time when job started.\n        ended_timestamp_ms (Optional[int]): Time when job ended.\n    \"\"\"\n\n    status: BatchJobStatus\n    created_timestamp_ms: Optional[int]\n    started_timestamp_ms: Optional[int]\n    ended_timestamp_ms: Optional[int]\n</code></pre>"},{"location":"batch/batch-job-status/","title":"BatchJobStatus","text":"<p>             Bases: <code>Enum</code></p> <p>Batch job status.</p> Source code in <code>hume/_measurement/batch/batch_job_status.py</code> <pre><code>class BatchJobStatus(Enum):\n    \"\"\"Batch job status.\"\"\"\n\n    COMPLETED = \"COMPLETED\"\n    FAILED = \"FAILED\"\n    IN_PROGRESS = \"IN_PROGRESS\"\n    QUEUED = \"QUEUED\"\n\n    @classmethod\n    def is_terminal(cls, status: \"BatchJobStatus\") -&gt; bool:\n        \"\"\"Check if a status is \"terminal\".\n\n        Args:\n            status (BatchJobStatus): Status to check.\n\n        Returns:\n            bool: Whether the status is \"terminal\".\n        \"\"\"\n        return status in [cls.COMPLETED, cls.FAILED]\n\n    @classmethod\n    def from_str(cls, status: str) -&gt; \"BatchJobStatus\":\n        \"\"\"Convert a status to a string.\n\n        Args:\n            status (str): Status to convert.\n\n        Returns:\n            BatchJobStatus: The enum variant for the given string.\n        \"\"\"\n        for _, enum_value in cls.__members__.items():\n            if enum_value.value == status:\n                return enum_value\n        raise ValueError(f\"Unknown status '{status}'\")\n</code></pre>"},{"location":"batch/batch-job-status/#hume._measurement.batch.batch_job_status.BatchJobStatus.from_str","title":"<code>from_str(status)</code>  <code>classmethod</code>","text":"<p>Convert a status to a string.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>str</code> <p>Status to convert.</p> required <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The enum variant for the given string.</p> Source code in <code>hume/_measurement/batch/batch_job_status.py</code> <pre><code>@classmethod\ndef from_str(cls, status: str) -&gt; \"BatchJobStatus\":\n    \"\"\"Convert a status to a string.\n\n    Args:\n        status (str): Status to convert.\n\n    Returns:\n        BatchJobStatus: The enum variant for the given string.\n    \"\"\"\n    for _, enum_value in cls.__members__.items():\n        if enum_value.value == status:\n            return enum_value\n    raise ValueError(f\"Unknown status '{status}'\")\n</code></pre>"},{"location":"batch/batch-job-status/#hume._measurement.batch.batch_job_status.BatchJobStatus.is_terminal","title":"<code>is_terminal(status)</code>  <code>classmethod</code>","text":"<p>Check if a status is \"terminal\".</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>BatchJobStatus</code> <p>Status to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the status is \"terminal\".</p> Source code in <code>hume/_measurement/batch/batch_job_status.py</code> <pre><code>@classmethod\ndef is_terminal(cls, status: \"BatchJobStatus\") -&gt; bool:\n    \"\"\"Check if a status is \"terminal\".\n\n    Args:\n        status (BatchJobStatus): Status to check.\n\n    Returns:\n        bool: Whether the status is \"terminal\".\n    \"\"\"\n    return status in [cls.COMPLETED, cls.FAILED]\n</code></pre>"},{"location":"batch/batch-job/","title":"BatchJob","text":"<p>Batch job.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>class BatchJob:\n    \"\"\"Batch job.\"\"\"\n\n    TIMEOUT_MESSAGE = (\n        \"Connection to API has been terminated after {}s, but your job will continue to run. \"\n        \"Get a reference to your job with `client.get_job('{}')` at any time.\"\n    )\n\n    def __init__(self, client: \"HumeBatchClient\", job_id: str):\n        \"\"\"Construct a BatchJob.\n\n        Args:\n            client (HumeBatchClient): HumeBatchClient instance.\n            job_id (str): Job ID.\n        \"\"\"\n        self._client = client\n        self.id = job_id\n\n    def get_status(self) -&gt; BatchJobStatus:\n        \"\"\"Get the status of the job.\n\n        Returns:\n            BatchJobStatus: The status of the `BatchJob`.\n        \"\"\"\n        return self.get_details().state.status\n\n    def get_predictions(self) -&gt; Any:\n        \"\"\"Get `BatchJob` predictions.\n\n        Returns:\n            Any: Predictions for the `BatchJob`.\n        \"\"\"\n        return self._client.get_job_predictions(self.id)\n\n    def download_predictions(self, filepath: Union[str, Path]) -&gt; None:\n        \"\"\"Download `BatchJob` predictions file.\n\n        Args:\n            filepath (Union[str, Path]): Filepath where predictions will be downloaded.\n        \"\"\"\n        predictions = self.get_predictions()\n        with Path(filepath).open(\"w\") as f:\n            json.dump(predictions, f)\n\n    def download_artifacts(self, filepath: Union[str, Path]) -&gt; None:\n        \"\"\"Download `BatchJob` artifacts zip file.\n\n        Args:\n            filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n        \"\"\"\n        self._client.download_job_artifacts(self.id, filepath)\n\n    def get_details(self) -&gt; BatchJobDetails:\n        \"\"\"Get details for the BatchJob.\n\n        Note that the details for a job may be fetched before the job has completed.\n        You may want to use `job.await_complete()` which will wait for the job to\n        reach a terminal state before returning.\n\n        Returns:\n            BatchJobDetails: Details for the `BatchJob`.\n        \"\"\"\n        return self._client.get_job_details(self.id)\n\n    def await_complete(self, timeout: int = 300, raise_on_failed: bool = False) -&gt; BatchJobDetails:\n        \"\"\"Block until the job has reached a terminal status.\n\n        Args:\n            timeout (int): Maximum time in seconds to await. If the timeout is reached\n                before the job reaches a terminal state the job will continue to be processed,\n                but a `HumeClientException` will be raised to the caller of `await_complete`.\n            raise_on_failed (bool): If set to True and job fails an exception will be raised.\n\n        Raises:\n            ValueError: If the timeout is not valid.\n            HumeClientException: If the `BatchJob` has not reached a terminal state within\n                the specified timeout. Also can be raised if `raise_on_failed` is set and\n                the job reaches a `FAILED` terminal state.\n\n        Returns:\n            BatchJobDetails: Details for the `BatchJob`.\n        \"\"\"\n        if timeout &lt; 1:\n            raise ValueError(\"timeout must be at least 1 second\")\n\n        # pylint: disable=unused-argument\n        @retry(timeout_message=self.TIMEOUT_MESSAGE.format(timeout, self.id))\n        def _await_complete(timeout: int = timeout) -&gt; BatchJobDetails:\n            details = self._client.get_job_details(self.id)\n            if not BatchJobStatus.is_terminal(details.state.status):\n                raise RetryIterError\n            if raise_on_failed and details.state.status == BatchJobStatus.FAILED:\n                raise HumeClientException(f\"BatchJob {self.id} failed.\")\n            return details\n\n        return _await_complete(timeout=timeout)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Get the string representation of the `BatchJob`.\n\n        Returns:\n            The the string representation of the `BatchJob`.\n        \"\"\"\n        return f'Job(id=\"{self.id}\")'\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.__init__","title":"<code>__init__(client, job_id)</code>","text":"<p>Construct a BatchJob.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>HumeBatchClient</code> <p>HumeBatchClient instance.</p> required <code>job_id</code> <code>str</code> <p>Job ID.</p> required Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def __init__(self, client: \"HumeBatchClient\", job_id: str):\n    \"\"\"Construct a BatchJob.\n\n    Args:\n        client (HumeBatchClient): HumeBatchClient instance.\n        job_id (str): Job ID.\n    \"\"\"\n    self._client = client\n    self.id = job_id\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.__repr__","title":"<code>__repr__()</code>","text":"<p>Get the string representation of the <code>BatchJob</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p>The the string representation of the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Get the string representation of the `BatchJob`.\n\n    Returns:\n        The the string representation of the `BatchJob`.\n    \"\"\"\n    return f'Job(id=\"{self.id}\")'\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.await_complete","title":"<code>await_complete(timeout=300, raise_on_failed=False)</code>","text":"<p>Block until the job has reached a terminal status.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a <code>HumeClientException</code> will be raised to the caller of <code>await_complete</code>.</p> <code>300</code> <code>raise_on_failed</code> <code>bool</code> <p>If set to True and job fails an exception will be raised.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the timeout is not valid.</p> <code>HumeClientException</code> <p>If the <code>BatchJob</code> has not reached a terminal state within the specified timeout. Also can be raised if <code>raise_on_failed</code> is set and the job reaches a <code>FAILED</code> terminal state.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Details for the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def await_complete(self, timeout: int = 300, raise_on_failed: bool = False) -&gt; BatchJobDetails:\n    \"\"\"Block until the job has reached a terminal status.\n\n    Args:\n        timeout (int): Maximum time in seconds to await. If the timeout is reached\n            before the job reaches a terminal state the job will continue to be processed,\n            but a `HumeClientException` will be raised to the caller of `await_complete`.\n        raise_on_failed (bool): If set to True and job fails an exception will be raised.\n\n    Raises:\n        ValueError: If the timeout is not valid.\n        HumeClientException: If the `BatchJob` has not reached a terminal state within\n            the specified timeout. Also can be raised if `raise_on_failed` is set and\n            the job reaches a `FAILED` terminal state.\n\n    Returns:\n        BatchJobDetails: Details for the `BatchJob`.\n    \"\"\"\n    if timeout &lt; 1:\n        raise ValueError(\"timeout must be at least 1 second\")\n\n    # pylint: disable=unused-argument\n    @retry(timeout_message=self.TIMEOUT_MESSAGE.format(timeout, self.id))\n    def _await_complete(timeout: int = timeout) -&gt; BatchJobDetails:\n        details = self._client.get_job_details(self.id)\n        if not BatchJobStatus.is_terminal(details.state.status):\n            raise RetryIterError\n        if raise_on_failed and details.state.status == BatchJobStatus.FAILED:\n            raise HumeClientException(f\"BatchJob {self.id} failed.\")\n        return details\n\n    return _await_complete(timeout=timeout)\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.download_artifacts","title":"<code>download_artifacts(filepath)</code>","text":"<p>Download <code>BatchJob</code> artifacts zip file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[Union[str, Path]]</code> <p>Filepath where artifacts will be downloaded.</p> required Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def download_artifacts(self, filepath: Union[str, Path]) -&gt; None:\n    \"\"\"Download `BatchJob` artifacts zip file.\n\n    Args:\n        filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n    \"\"\"\n    self._client.download_job_artifacts(self.id, filepath)\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.download_predictions","title":"<code>download_predictions(filepath)</code>","text":"<p>Download <code>BatchJob</code> predictions file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, Path]</code> <p>Filepath where predictions will be downloaded.</p> required Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def download_predictions(self, filepath: Union[str, Path]) -&gt; None:\n    \"\"\"Download `BatchJob` predictions file.\n\n    Args:\n        filepath (Union[str, Path]): Filepath where predictions will be downloaded.\n    \"\"\"\n    predictions = self.get_predictions()\n    with Path(filepath).open(\"w\") as f:\n        json.dump(predictions, f)\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.get_details","title":"<code>get_details()</code>","text":"<p>Get details for the BatchJob.</p> <p>Note that the details for a job may be fetched before the job has completed. You may want to use <code>job.await_complete()</code> which will wait for the job to reach a terminal state before returning.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Details for the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def get_details(self) -&gt; BatchJobDetails:\n    \"\"\"Get details for the BatchJob.\n\n    Note that the details for a job may be fetched before the job has completed.\n    You may want to use `job.await_complete()` which will wait for the job to\n    reach a terminal state before returning.\n\n    Returns:\n        BatchJobDetails: Details for the `BatchJob`.\n    \"\"\"\n    return self._client.get_job_details(self.id)\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.get_predictions","title":"<code>get_predictions()</code>","text":"<p>Get <code>BatchJob</code> predictions.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Predictions for the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def get_predictions(self) -&gt; Any:\n    \"\"\"Get `BatchJob` predictions.\n\n    Returns:\n        Any: Predictions for the `BatchJob`.\n    \"\"\"\n    return self._client.get_job_predictions(self.id)\n</code></pre>"},{"location":"batch/batch-job/#hume._measurement.batch.batch_job.BatchJob.get_status","title":"<code>get_status()</code>","text":"<p>Get the status of the job.</p> <p>Returns:</p> Name Type Description <code>BatchJobStatus</code> <code>BatchJobStatus</code> <p>The status of the <code>BatchJob</code>.</p> Source code in <code>hume/_measurement/batch/batch_job.py</code> <pre><code>def get_status(self) -&gt; BatchJobStatus:\n    \"\"\"Get the status of the job.\n\n    Returns:\n        BatchJobStatus: The status of the `BatchJob`.\n    \"\"\"\n    return self.get_details().state.status\n</code></pre>"},{"location":"batch/hume-batch-client/","title":"HumeBatchClient","text":"<p>             Bases: <code>ClientBase</code></p> <p>Batch API client.</p> Example <pre><code>from hume import HumeBatchClient\nfrom hume.models.config import FaceConfig\nfrom hume.models.config import ProsodyConfig\n\nclient = HumeBatchClient(\"&lt;your-api-key&gt;\")\nurls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\nconfigs = [FaceConfig(identify_faces=True), ProsodyConfig()]\njob = client.submit_job(urls, configs)\n\nprint(job)\nprint(\"Running...\")\n\njob.await_complete()\njob.download_predictions(\"predictions.json\")\nprint(\"Predictions downloaded to predictions.json\")\n\njob.download_artifacts(\"artifacts.zip\")\nprint(\"Artifacts downloaded to artifacts.zip\")\n</code></pre> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>class HumeBatchClient(ClientBase):\n    \"\"\"Batch API client.\n\n    Example:\n        ```python\n        from hume import HumeBatchClient\n        from hume.models.config import FaceConfig\n        from hume.models.config import ProsodyConfig\n\n        client = HumeBatchClient(\"&lt;your-api-key&gt;\")\n        urls = [\"https://storage.googleapis.com/hume-test-data/video/armisen-clip.mp4\"]\n        configs = [FaceConfig(identify_faces=True), ProsodyConfig()]\n        job = client.submit_job(urls, configs)\n\n        print(job)\n        print(\"Running...\")\n\n        job.await_complete()\n        job.download_predictions(\"predictions.json\")\n        print(\"Predictions downloaded to predictions.json\")\n\n        job.download_artifacts(\"artifacts.zip\")\n        print(\"Artifacts downloaded to artifacts.zip\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        *args: Any,\n        timeout: int = 10,\n        **kwargs: Any,\n    ):\n        \"\"\"Construct a HumeBatchClient.\n\n        Args:\n            api_key (str): Hume API key.\n            timeout (int): Time in seconds before canceling long-running Hume API requests.\n        \"\"\"\n        super().__init__(api_key, http_timeout=timeout, *args, **kwargs)\n\n    def get_job(self, job_id: str) -&gt; BatchJob:\n        \"\"\"Rehydrate a job based on a Job ID.\n\n        Args:\n            job_id (str): ID of the job to rehydrate.\n\n        Returns:\n            BatchJob: Job associated with the given ID.\n        \"\"\"\n        return BatchJob(self, job_id)\n\n    def submit_job(\n        self,\n        urls: List[str],\n        configs: List[ModelConfigBase],\n        transcription_config: Optional[TranscriptionConfig] = None,\n        callback_url: Optional[str] = None,\n        notify: Optional[bool] = None,\n        files: Optional[List[Union[str, Path]]] = None,\n        text: Optional[List[str]] = None,\n    ) -&gt; BatchJob:\n        \"\"\"Submit a job for batch processing.\n\n        Note: Only one config per model type should be passed.\n            If more than one config is passed for a given model type, only the last config will be used.\n\n        Args:\n            urls (List[str]): List of URLs to media files to be processed.\n            configs (List[ModelConfigBase]): List of model config objects to run on each media URL.\n            transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object.\n            callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion.\n            notify (Optional[bool]): Wether an email notification should be sent upon job completion.\n            files (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n            text (Optional[List[str]]): List of strings (raw text) to be processed.\n\n        Returns:\n            BatchJob: The `BatchJob` representing the batch computation.\n        \"\"\"\n        request = self._construct_request(configs, urls, text, transcription_config, callback_url, notify)\n        return self._submit_job(request, files)\n\n    def get_job_details(self, job_id: str) -&gt; BatchJobDetails:\n        \"\"\"Get details for the batch job.\n\n        Args:\n            job_id (str): Job ID.\n\n        Raises:\n            HumeClientException: If the job details cannot be loaded.\n\n        Returns:\n            BatchJobDetails: Batch job details.\n        \"\"\"\n        endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}\")\n        response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n        try:\n            body = response.json()\n        except json.JSONDecodeError:\n            # pylint: disable=raise-missing-from\n            raise HumeClientException(\"Unexpected error when getting job details\")\n\n        if \"message\" in body and body[\"message\"] == \"job not found\":\n            raise HumeClientException(f\"Could not find a job with ID {job_id}\")\n\n        return BatchJobDetails.from_response(body)\n\n    def get_job_predictions(self, job_id: str) -&gt; Any:\n        \"\"\"Get a batch job's predictions.\n\n        Args:\n            job_id (str): Job ID.\n\n        Raises:\n            HumeClientException: If the job predictions cannot be loaded.\n\n        Returns:\n            Any: Batch job predictions.\n        \"\"\"\n        endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}/predictions\")\n        response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n        try:\n            body = response.json()\n        except json.JSONDecodeError:\n            # pylint: disable=raise-missing-from\n            raise HumeClientException(\"Unexpected error when getting job predictions\")\n\n        if \"message\" in body and body[\"message\"] == \"job not found\":\n            raise HumeClientException(f\"Could not find a job with ID {job_id}\")\n\n        return body\n\n    def download_job_artifacts(self, job_id: str, filepath: Union[str, Path]) -&gt; None:\n        \"\"\"Download a batch job's artifacts as a zip file.\n\n        Args:\n            job_id (str): Job ID.\n            filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n\n        Raises:\n            HumeClientException: If the job artifacts cannot be loaded.\n\n        Returns:\n            Any: Batch job artifacts.\n        \"\"\"\n        endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}/artifacts\")\n        response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n        with Path(filepath).open(\"wb\") as f:\n            f.write(response.content)\n\n    @classmethod\n    def _construct_request(\n        cls,\n        configs: List[ModelConfigBase],\n        urls: List[str],\n        text: Optional[List[str]],\n        transcription_config: Optional[TranscriptionConfig],\n        callback_url: Optional[str],\n        notify: Optional[bool],\n    ) -&gt; Dict[str, Any]:\n        request: Dict[str, Any] = {\n            \"urls\": urls,\n            \"models\": serialize_configs(configs),\n        }\n        if text is not None:\n            request[\"text\"] = text\n        if transcription_config is not None:\n            request[\"transcription\"] = transcription_config.to_dict()\n        if callback_url is not None:\n            request[\"callback_url\"] = callback_url\n        if notify is not None:\n            request[\"notify\"] = notify\n        return request\n\n    def _submit_job(\n        self,\n        request_body: Any,\n        filepaths: Optional[List[Union[str, Path]]],\n    ) -&gt; BatchJob:\n        \"\"\"Start a job for batch processing by passing a JSON request body.\n\n        This request body should match the request body used by the batch API,\n        including both the list of URLs and the models configuration.\n\n        Args:\n            request_body (Any): JSON request body to be passed to the batch API.\n            filepaths (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n\n        Raises:\n            HumeClientException: If the batch job fails to start.\n\n        Returns:\n            BatchJob: A `BatchJob` that wraps the batch computation.\n        \"\"\"\n        endpoint = self._build_endpoint(\"batch\", \"jobs\")\n\n        if filepaths is None:\n            response = self._http_client.post(\n                endpoint,\n                json=request_body,\n                headers=self._get_client_headers(),\n            )\n        else:\n            form_data = self._get_multipart_form_data(request_body, filepaths)\n            response = self._http_client.post(\n                endpoint,\n                headers=self._get_client_headers(),\n                files=form_data,\n            )\n\n        try:\n            body = response.json()\n        except json.decoder.JSONDecodeError:\n            # pylint: disable=raise-missing-from\n            raise HumeClientException(f\"Failed batch request: {response.text}\")\n\n        if \"job_id\" not in body:\n            if \"fault\" in body and \"faultstring\" in body[\"fault\"]:\n                fault = body[\"fault\"]\n                fault_string = fault[\"faultstring\"]\n                if \"detail\" in fault and \"errorcode\" in fault[\"detail\"]:\n                    detail = fault[\"detail\"]\n                    error_code = detail[\"errorcode\"]\n                    if \"InvalidApiKey\" in error_code:\n                        raise HumeClientException(\"HumeBatchClient initialized with invalid API key.\")\n                    raise HumeClientException(f\"Could not start batch job: {error_code}: {fault_string}\")\n                raise HumeClientException(f\"Could not start batch job: {fault_string}\")\n            raise HumeClientException(f\"Unexpected error when starting batch job: {body}\")\n\n        return BatchJob(self, body[\"job_id\"])\n\n    def _get_multipart_form_data(\n        self,\n        request_body: Any,\n        filepaths: List[Union[str, Path]],\n    ) -&gt; List[Tuple[str, Union[bytes, Tuple[str, bytes]]]]:\n        \"\"\"Convert a list of filepaths into a list of multipart form data.\n\n        Multipart form data allows the client to attach files to the POST request,\n        including both the raw file bytes and the filename.\n\n        Args:\n            request_body (Any): JSON request body to be passed to the batch API.\n            filepaths (List[Union[str, Path]]): List of paths to files on the local disk to be processed.\n\n        Returns:\n            List[Tuple[str, Union[bytes, Tuple[str, bytes]]]]: A list of tuples representing\n                the multipart form data for the POST request.\n        \"\"\"\n        form_data: List[Tuple[str, Union[bytes, Tuple[str, bytes]]]] = []\n        for filepath in filepaths:\n            path = Path(filepath)\n            post_file = (\"file\", (path.name, path.read_bytes()))\n            form_data.append(post_file)\n\n        form_data.append((\"json\", json.dumps(request_body).encode(\"utf-8\")))\n        return form_data\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.__init__","title":"<code>__init__(api_key, *args, timeout=10, **kwargs)</code>","text":"<p>Construct a HumeBatchClient.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Hume API key.</p> required <code>timeout</code> <code>int</code> <p>Time in seconds before canceling long-running Hume API requests.</p> <code>10</code> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def __init__(\n    self,\n    api_key: str,\n    *args: Any,\n    timeout: int = 10,\n    **kwargs: Any,\n):\n    \"\"\"Construct a HumeBatchClient.\n\n    Args:\n        api_key (str): Hume API key.\n        timeout (int): Time in seconds before canceling long-running Hume API requests.\n    \"\"\"\n    super().__init__(api_key, http_timeout=timeout, *args, **kwargs)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.download_job_artifacts","title":"<code>download_job_artifacts(job_id, filepath)</code>","text":"<p>Download a batch job's artifacts as a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <code>filepath</code> <code>Optional[Union[str, Path]]</code> <p>Filepath where artifacts will be downloaded.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job artifacts cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>None</code> <p>Batch job artifacts.</p> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def download_job_artifacts(self, job_id: str, filepath: Union[str, Path]) -&gt; None:\n    \"\"\"Download a batch job's artifacts as a zip file.\n\n    Args:\n        job_id (str): Job ID.\n        filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded.\n\n    Raises:\n        HumeClientException: If the job artifacts cannot be loaded.\n\n    Returns:\n        Any: Batch job artifacts.\n    \"\"\"\n    endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}/artifacts\")\n    response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n    with Path(filepath).open(\"wb\") as f:\n        f.write(response.content)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.get_job","title":"<code>get_job(job_id)</code>","text":"<p>Rehydrate a job based on a Job ID.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>ID of the job to rehydrate.</p> required <p>Returns:</p> Name Type Description <code>BatchJob</code> <code>BatchJob</code> <p>Job associated with the given ID.</p> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def get_job(self, job_id: str) -&gt; BatchJob:\n    \"\"\"Rehydrate a job based on a Job ID.\n\n    Args:\n        job_id (str): ID of the job to rehydrate.\n\n    Returns:\n        BatchJob: Job associated with the given ID.\n    \"\"\"\n    return BatchJob(self, job_id)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.get_job_details","title":"<code>get_job_details(job_id)</code>","text":"<p>Get details for the batch job.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job details cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>BatchJobDetails</code> <code>BatchJobDetails</code> <p>Batch job details.</p> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def get_job_details(self, job_id: str) -&gt; BatchJobDetails:\n    \"\"\"Get details for the batch job.\n\n    Args:\n        job_id (str): Job ID.\n\n    Raises:\n        HumeClientException: If the job details cannot be loaded.\n\n    Returns:\n        BatchJobDetails: Batch job details.\n    \"\"\"\n    endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}\")\n    response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n    try:\n        body = response.json()\n    except json.JSONDecodeError:\n        # pylint: disable=raise-missing-from\n        raise HumeClientException(\"Unexpected error when getting job details\")\n\n    if \"message\" in body and body[\"message\"] == \"job not found\":\n        raise HumeClientException(f\"Could not find a job with ID {job_id}\")\n\n    return BatchJobDetails.from_response(body)\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.get_job_predictions","title":"<code>get_job_predictions(job_id)</code>","text":"<p>Get a batch job's predictions.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>Job ID.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the job predictions cannot be loaded.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Batch job predictions.</p> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def get_job_predictions(self, job_id: str) -&gt; Any:\n    \"\"\"Get a batch job's predictions.\n\n    Args:\n        job_id (str): Job ID.\n\n    Raises:\n        HumeClientException: If the job predictions cannot be loaded.\n\n    Returns:\n        Any: Batch job predictions.\n    \"\"\"\n    endpoint = self._build_endpoint(\"batch\", f\"jobs/{job_id}/predictions\")\n    response = self._http_client.get(endpoint, headers=self._get_client_headers())\n\n    try:\n        body = response.json()\n    except json.JSONDecodeError:\n        # pylint: disable=raise-missing-from\n        raise HumeClientException(\"Unexpected error when getting job predictions\")\n\n    if \"message\" in body and body[\"message\"] == \"job not found\":\n        raise HumeClientException(f\"Could not find a job with ID {job_id}\")\n\n    return body\n</code></pre>"},{"location":"batch/hume-batch-client/#hume._measurement.batch.hume_batch_client.HumeBatchClient.submit_job","title":"<code>submit_job(urls, configs, transcription_config=None, callback_url=None, notify=None, files=None, text=None)</code>","text":"<p>Submit a job for batch processing.</p> Only one config per model type should be passed. <p>If more than one config is passed for a given model type, only the last config will be used.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>List[str]</code> <p>List of URLs to media files to be processed.</p> required <code>configs</code> <code>List[ModelConfigBase]</code> <p>List of model config objects to run on each media URL.</p> required <code>transcription_config</code> <code>Optional[TranscriptionConfig]</code> <p>A <code>TranscriptionConfig</code> object.</p> <code>None</code> <code>callback_url</code> <code>Optional[str]</code> <p>A URL to which a POST request will be sent upon job completion.</p> <code>None</code> <code>notify</code> <code>Optional[bool]</code> <p>Wether an email notification should be sent upon job completion.</p> <code>None</code> <code>files</code> <code>Optional[List[Union[str, Path]]]</code> <p>List of paths to files on the local disk to be processed.</p> <code>None</code> <code>text</code> <code>Optional[List[str]]</code> <p>List of strings (raw text) to be processed.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchJob</code> <code>BatchJob</code> <p>The <code>BatchJob</code> representing the batch computation.</p> Source code in <code>hume/_measurement/batch/hume_batch_client.py</code> <pre><code>def submit_job(\n    self,\n    urls: List[str],\n    configs: List[ModelConfigBase],\n    transcription_config: Optional[TranscriptionConfig] = None,\n    callback_url: Optional[str] = None,\n    notify: Optional[bool] = None,\n    files: Optional[List[Union[str, Path]]] = None,\n    text: Optional[List[str]] = None,\n) -&gt; BatchJob:\n    \"\"\"Submit a job for batch processing.\n\n    Note: Only one config per model type should be passed.\n        If more than one config is passed for a given model type, only the last config will be used.\n\n    Args:\n        urls (List[str]): List of URLs to media files to be processed.\n        configs (List[ModelConfigBase]): List of model config objects to run on each media URL.\n        transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object.\n        callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion.\n        notify (Optional[bool]): Wether an email notification should be sent upon job completion.\n        files (Optional[List[Union[str, Path]]]): List of paths to files on the local disk to be processed.\n        text (Optional[List[str]]): List of strings (raw text) to be processed.\n\n    Returns:\n        BatchJob: The `BatchJob` representing the batch computation.\n    \"\"\"\n    request = self._construct_request(configs, urls, text, transcription_config, callback_url, notify)\n    return self._submit_job(request, files)\n</code></pre>"},{"location":"batch/transcription-config/","title":"TranscriptionConfig","text":"<p>             Bases: <code>ConfigBase['TranscriptionConfig']</code></p> <p>Configuration for speech transcription.</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>Optional[str]</code> <p>By default, we use an automated language detection method for our Speech Prosody, Language, and NER models. However, if you know what language is being spoken in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results. You can specify any of the following: <code>zh</code>, <code>da</code>, <code>nl</code>, <code>en</code>, <code>en-AU</code>, <code>en-IN</code>, <code>en-NZ</code>, <code>en-GB</code>, <code>fr</code>, <code>fr-CA</code>, <code>de</code>, <code>hi</code>, <code>hi-Latn</code>, <code>id</code>, <code>it</code>, <code>ja</code>, <code>ko</code>, <code>no</code>, <code>pl</code>, <code>pt</code>, <code>pt-BR</code>, <code>pt-PT</code>, <code>ru</code>, <code>es</code>, <code>es-419</code>, <code>sv</code>, <code>ta</code>, <code>tr</code>, or <code>uk</code>.</p> <code>None</code> Source code in <code>hume/_measurement/batch/transcription_config.py</code> <pre><code>@dataclass\nclass TranscriptionConfig(ConfigBase[\"TranscriptionConfig\"]):\n    \"\"\"Configuration for speech transcription.\n\n    Args:\n        language (Optional[str]): By default, we use an automated language detection method for our\n            Speech Prosody, Language, and NER models. However, if you know what language is being spoken\n            in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results.\n            You can specify any of the following: `zh`, `da`, `nl`, `en`, `en-AU`,\n            `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`,\n            `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`.\n    \"\"\"\n\n    language: Optional[str] = None\n</code></pre>"},{"location":"config/burst-config/","title":"BurstConfig","text":"<p>             Bases: <code>ModelConfigBase['BurstConfig']</code></p> <p>Configuration for the vocal burst model.</p> Source code in <code>hume/models/config/burst_config.py</code> <pre><code>@dataclass\nclass BurstConfig(ModelConfigBase[\"BurstConfig\"]):\n    \"\"\"Configuration for the vocal burst model.\"\"\"\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.BURST\n</code></pre>"},{"location":"config/burst-config/#hume.models.config.burst_config.BurstConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/burst_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.BURST\n</code></pre>"},{"location":"config/face-config/","title":"FaceConfig","text":"<p>             Bases: <code>ModelConfigBase['FaceConfig']</code></p> <p>Configuration for the facial expression model.</p> <p>Parameters:</p> Name Type Description Default <code>fps_pred</code> <code>Optional[float]</code> <p>Number of frames per second to process. Other frames will be omitted from the response.</p> <code>None</code> <code>prob_threshold</code> <code>Optional[float]</code> <p>Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response.</p> <code>None</code> <code>identify_faces</code> <code>Optional[bool]</code> <p>Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID.</p> <code>None</code> <code>min_face_size</code> <code>Optional[float]</code> <p>Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response.</p> <code>None</code> <code>save_faces</code> <code>Optional[bool]</code> <p>Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is only available for the batch API.</p> <code>None</code> <code>descriptions</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Descriptions predictions. Descriptions prediction can be enabled by setting \"descriptions\": {}. Currently, Descriptions prediction cannot be further configured with any parameters. If missing or null, no descriptions predictions will be generated.</p> <code>None</code> <code>facs</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for FACS predictions. FACS prediction can be enabled by setting \"facs\": {}. Currently, FACS prediction cannot be further configured with any parameters. If missing or null, no facs predictions will be generated.</p> <code>None</code> Source code in <code>hume/models/config/face_config.py</code> <pre><code>@dataclass\nclass FaceConfig(ModelConfigBase[\"FaceConfig\"]):\n    \"\"\"Configuration for the facial expression model.\n\n    Args:\n        fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted\n            from the response.\n        prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a\n            probability less than this threshold will be omitted from the response.\n        identify_faces (Optional[bool]): Whether to return identifiers for faces across frames.\n            If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces.\n            If false, all faces will be tagged with an \"unknown\" ID.\n        min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face.\n            Faces detected with a bounding box side length in pixels less than this threshold will be\n            omitted from the response.\n        save_faces (Optional[bool]): Whether to extract and save the detected faces to the artifacts\n            directory included in the response.\n            This configuration is only available for the batch API.\n        descriptions (Optional[Dict[str, Any]]): Configuration for Descriptions predictions.\n            Descriptions prediction can be enabled by setting \"descriptions\": {}.\n            Currently, Descriptions prediction cannot be further configured with any parameters.\n            If missing or null, no descriptions predictions will be generated.\n        facs (Optional[Dict[str, Any]]): Configuration for FACS predictions.\n            FACS prediction can be enabled by setting \"facs\": {}.\n            Currently, FACS prediction cannot be further configured with any parameters.\n            If missing or null, no facs predictions will be generated.\n    \"\"\"\n\n    fps_pred: Optional[float] = None\n    prob_threshold: Optional[float] = None\n    identify_faces: Optional[bool] = None\n    min_face_size: Optional[float] = None\n    save_faces: Optional[bool] = None\n    descriptions: Optional[Dict[str, Any]] = None\n    facs: Optional[Dict[str, Any]] = None\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.FACE\n</code></pre>"},{"location":"config/face-config/#hume.models.config.face_config.FaceConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/face_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.FACE\n</code></pre>"},{"location":"config/facemesh-config/","title":"FacemeshConfig","text":"<p>             Bases: <code>ModelConfigBase['FacemeshConfig']</code></p> <p>Configuration for the facemesh model.</p> Source code in <code>hume/models/config/facemesh_config.py</code> <pre><code>@dataclass\nclass FacemeshConfig(ModelConfigBase[\"FacemeshConfig\"]):\n    \"\"\"Configuration for the facemesh model.\"\"\"\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.FACEMESH\n</code></pre>"},{"location":"config/facemesh-config/#hume.models.config.facemesh_config.FacemeshConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/facemesh_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.FACEMESH\n</code></pre>"},{"location":"config/language-config/","title":"LanguageConfig","text":"<p>             Bases: <code>ModelConfigBase['LanguageConfig']</code></p> <p>Configuration for the language emotion model.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Optional[str]</code> <p>The granularity at which to generate predictions. Accepted values are <code>word</code>, <code>sentence</code>, <code>utterance</code>, or <code>conversational_turn</code>. The default is <code>utterance</code>. <code>utterance</code> corresponds to a natural pause or break in conversation <code>conversational_turn</code> corresponds to a change in speaker. This configuration is available for the streaming API, but only with values <code>word</code> and <code>sentence</code>.</p> <code>None</code> <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> <code>sentiment</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Sentiment predictions. Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, Sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated.</p> <code>None</code> <code>toxicity</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration for Toxicity predictions. Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, Toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated.</p> <code>None</code> Source code in <code>hume/models/config/language_config.py</code> <pre><code>@dataclass\nclass LanguageConfig(ModelConfigBase[\"LanguageConfig\"]):\n    \"\"\"Configuration for the language emotion model.\n\n    Args:\n        granularity (Optional[str]): The granularity at which to generate predictions.\n            Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`.\n            The default is `utterance`.\n            `utterance` corresponds to a natural pause or break in conversation\n            `conversational_turn` corresponds to a change in speaker.\n            This configuration is available for the streaming API, but only with values `word` and `sentence`.\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time.\n            If true, unique identifiers will be assigned to spoken words to differentiate different speakers.\n            If false, all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n        sentiment (Optional[Dict[str, Any]]): Configuration for Sentiment predictions.\n            Sentiment prediction can be enabled by setting \"sentiment\": {}.\n            Currently, Sentiment prediction cannot be further configured with any parameters.\n            If missing or null, no sentiment predictions will be generated.\n        toxicity (Optional[Dict[str, Any]]): Configuration for Toxicity predictions.\n            Toxicity prediction can be enabled by setting \"toxicity\": {}.\n            Currently, Toxicity prediction cannot be further configured with any parameters.\n            If missing or null, no toxicity predictions will be generated.\n    \"\"\"\n\n    granularity: Optional[str] = None\n    identify_speakers: Optional[bool] = None\n    sentiment: Optional[Dict[str, Any]] = None\n    toxicity: Optional[Dict[str, Any]] = None\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.LANGUAGE\n</code></pre>"},{"location":"config/language-config/#hume.models.config.language_config.LanguageConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/language_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.LANGUAGE\n</code></pre>"},{"location":"config/ner-config/","title":"NerConfig","text":"<p>             Bases: <code>ModelConfigBase['NerConfig']</code></p> <p>Configuration for the named-entity emotion model.</p> <p>This model is only available for the batch API.</p> <p>Parameters:</p> Name Type Description Default <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> Source code in <code>hume/models/config/ner_config.py</code> <pre><code>@dataclass\nclass NerConfig(ModelConfigBase[\"NerConfig\"]):\n    \"\"\"Configuration for the named-entity emotion model.\n\n    This model is only available for the batch API.\n\n    Args:\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true,\n            unique identifiers will be assigned to spoken words to differentiate different speakers. If false,\n            all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n    \"\"\"\n\n    identify_speakers: Optional[bool] = None\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.NER\n</code></pre>"},{"location":"config/ner-config/#hume.models.config.ner_config.NerConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/ner_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.NER\n</code></pre>"},{"location":"config/prosody-config/","title":"ProsodyConfig","text":"<p>             Bases: <code>ModelConfigBase['ProsodyConfig']</code></p> <p>Configuration for the speech prosody model.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Optional[str]</code> <p>The granularity at which to generate predictions. Accepted values are <code>word</code>, <code>sentence</code>, <code>utterance</code>, or <code>conversational_turn</code>. The default is <code>utterance</code>. <code>utterance</code> corresponds to a natural pause or break in conversation <code>conversational_turn</code> corresponds to a change in speaker. This configuration is only available for the batch API.</p> <code>None</code> <code>identify_speakers</code> <code>Optional[bool]</code> <p>Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API.</p> <code>None</code> <code>window</code> <code>Optional[Dict[str, float]]</code> <p>Sliding window used to chunk audio. This dictionary input takes two entries: <code>length</code> and <code>step</code> representing the width of the window in seconds and the step size in seconds. This configuration is only available for the batch API.</p> <code>None</code> Source code in <code>hume/models/config/prosody_config.py</code> <pre><code>@dataclass\nclass ProsodyConfig(ModelConfigBase[\"ProsodyConfig\"]):\n    \"\"\"Configuration for the speech prosody model.\n\n    Args:\n        granularity (Optional[str]): The granularity at which to generate predictions.\n            Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`.\n            The default is `utterance`.\n            `utterance` corresponds to a natural pause or break in conversation\n            `conversational_turn` corresponds to a change in speaker.\n            This configuration is only available for the batch API.\n        identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true,\n            unique identifiers will be assigned to spoken words to differentiate different speakers. If false,\n            all speakers will be tagged with an \"unknown\" ID.\n            This configuration is only available for the batch API.\n        window (Optional[Dict[str, float]]): Sliding window used to chunk audio.\n            This dictionary input takes two entries: `length` and `step` representing\n            the width of the window in seconds and the step size in seconds.\n            This configuration is only available for the batch API.\n    \"\"\"\n\n    identify_speakers: Optional[bool] = None\n    granularity: Optional[str] = None\n    window: Optional[Dict[str, float]] = None\n\n    @classmethod\n    def get_model_type(cls) -&gt; ModelType:\n        \"\"\"Get the configuration model type.\n\n        Returns:\n            ModelType: Model type.\n        \"\"\"\n        return ModelType.PROSODY\n</code></pre>"},{"location":"config/prosody-config/#hume.models.config.prosody_config.ProsodyConfig.get_model_type","title":"<code>get_model_type()</code>  <code>classmethod</code>","text":"<p>Get the configuration model type.</p> <p>Returns:</p> Name Type Description <code>ModelType</code> <code>ModelType</code> <p>Model type.</p> Source code in <code>hume/models/config/prosody_config.py</code> <pre><code>@classmethod\ndef get_model_type(cls) -&gt; ModelType:\n    \"\"\"Get the configuration model type.\n\n    Returns:\n        ModelType: Model type.\n    \"\"\"\n    return ModelType.PROSODY\n</code></pre>"},{"location":"stream/hume-stream-client/","title":"HumeStreamClient","text":"<p>             Bases: <code>ClientBase</code></p> <p>Streaming API client.</p> Example <pre><code>import asyncio\n\nfrom hume import HumeStreamClient\nfrom hume.models.config import BurstConfig\nfrom hume.models.config import ProsodyConfig\n\nasync def main():\n    client = HumeStreamClient(\"&lt;your-api-key&gt;\")\n    configs = [BurstConfig(), ProsodyConfig()]\n    async with client.connect(configs) as socket:\n        result = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\n        print(result)\n\nasyncio.run(main())\n</code></pre> Source code in <code>hume/_measurement/stream/hume_stream_client.py</code> <pre><code>class HumeStreamClient(ClientBase):\n    \"\"\"Streaming API client.\n\n    Example:\n        ```python\n        import asyncio\n\n        from hume import HumeStreamClient\n        from hume.models.config import BurstConfig\n        from hume.models.config import ProsodyConfig\n\n        async def main():\n            client = HumeStreamClient(\"&lt;your-api-key&gt;\")\n            configs = [BurstConfig(), ProsodyConfig()]\n            async with client.connect(configs) as socket:\n                result = await socket.send_file(\"&lt;your-audio-filepath&gt;\")\n                print(result)\n\n        asyncio.run(main())\n        ```\n    \"\"\"\n\n    @asynccontextmanager\n    async def connect(\n        self,\n        configs: Sequence[ModelConfigBase],\n        stream_window_ms: Optional[int] = None,\n    ) -&gt; AsyncIterator[StreamSocket]:\n        \"\"\"Connect to the streaming API.\n\n        Note: Only one config per model type should be passed.\n            If more than one config is passed for a given model type, only the last config will be used.\n\n        Args:\n            configs (List[ModelConfigBase]): List of job configs.\n            stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n                aggregating media across streaming payloads within one WebSocket connection.\n        \"\"\"\n        endpoint = self._build_endpoint(\"stream\", \"models\", protocol=Protocol.WS)\n        try:\n            # pylint: disable=no-member\n            async with websockets.connect(  # type: ignore[attr-defined]\n                endpoint,\n                extra_headers=self._get_client_headers(),\n                close_timeout=self._close_timeout,\n                open_timeout=self._open_timeout,\n            ) as protocol:\n                yield StreamSocket(protocol, list(configs), stream_window_ms=stream_window_ms)\n        except websockets.exceptions.InvalidStatusCode as exc:\n            status_code: int = exc.status_code\n            if status_code == 401:  # Unauthorized\n                message = \"HumeStreamClient initialized with invalid API key.\"\n                raise HumeClientException(message) from exc\n            raise HumeClientException(\"Unexpected error when creating streaming connection\") from exc\n\n    @asynccontextmanager\n    async def _connect_with_configs_dict(self, configs_dict: Any) -&gt; AsyncIterator[StreamSocket]:\n        \"\"\"Connect to the streaming API with a single models configuration dict.\n\n        Args:\n            configs_dict (Any): Models configurations dict. This should be a dict from model name\n                to model configuration dict. An empty dict uses the default configuration.\n        \"\"\"\n        configs = deserialize_configs(configs_dict)\n        async with self.connect(configs) as websocket:\n            yield websocket\n</code></pre>"},{"location":"stream/hume-stream-client/#hume._measurement.stream.hume_stream_client.HumeStreamClient.connect","title":"<code>connect(configs, stream_window_ms=None)</code>  <code>async</code>","text":"<p>Connect to the streaming API.</p> Only one config per model type should be passed. <p>If more than one config is passed for a given model type, only the last config will be used.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>List[ModelConfigBase]</code> <p>List of job configs.</p> required <code>stream_window_ms</code> <code>Optional[int]</code> <p>Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one WebSocket connection.</p> <code>None</code> Source code in <code>hume/_measurement/stream/hume_stream_client.py</code> <pre><code>@asynccontextmanager\nasync def connect(\n    self,\n    configs: Sequence[ModelConfigBase],\n    stream_window_ms: Optional[int] = None,\n) -&gt; AsyncIterator[StreamSocket]:\n    \"\"\"Connect to the streaming API.\n\n    Note: Only one config per model type should be passed.\n        If more than one config is passed for a given model type, only the last config will be used.\n\n    Args:\n        configs (List[ModelConfigBase]): List of job configs.\n        stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n            aggregating media across streaming payloads within one WebSocket connection.\n    \"\"\"\n    endpoint = self._build_endpoint(\"stream\", \"models\", protocol=Protocol.WS)\n    try:\n        # pylint: disable=no-member\n        async with websockets.connect(  # type: ignore[attr-defined]\n            endpoint,\n            extra_headers=self._get_client_headers(),\n            close_timeout=self._close_timeout,\n            open_timeout=self._open_timeout,\n        ) as protocol:\n            yield StreamSocket(protocol, list(configs), stream_window_ms=stream_window_ms)\n    except websockets.exceptions.InvalidStatusCode as exc:\n        status_code: int = exc.status_code\n        if status_code == 401:  # Unauthorized\n            message = \"HumeStreamClient initialized with invalid API key.\"\n            raise HumeClientException(message) from exc\n        raise HumeClientException(\"Unexpected error when creating streaming connection\") from exc\n</code></pre>"},{"location":"stream/stream-socket/","title":"StreamSocket","text":"<p>Streaming socket connection.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>class StreamSocket:\n    \"\"\"Streaming socket connection.\"\"\"\n\n    _FACE_LIMIT = 100\n    _N_LANDMARKS = 478\n    _N_SPATIAL = 3\n\n    def __init__(\n        self,\n        protocol: \"WebSocketClientProtocol\",\n        configs: List[ModelConfigBase],\n        stream_window_ms: Optional[int] = None,\n    ):\n        \"\"\"Construct a `StreamSocket`.\n\n        Args:\n            protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n            configs (Optional[List[ModelConfigBase]]): List of model configurations.\n            stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n                aggregating media across streaming payloads within one websocket connection.\n\n        Raises:\n            HumeClientException: If there is an error processing media over the socket connection.\n        \"\"\"\n        self._protocol = protocol\n        self._configs = configs\n        self._stream_window_ms = stream_window_ms\n\n        # Serialize configs once for full lifetime of socket\n        self._serialized_configs = serialize_configs(configs)\n\n    async def send_file(\n        self,\n        filepath: Union[str, Path],\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; Any:\n        \"\"\"Send a file on the `StreamSocket`.\n\n        Args:\n            filepath (Path): Path to media file to send on socket connection.\n            configs (Optional[List[ModelConfigBase]]): List of model configurations.\n                If set these configurations will overwrite any configurations\n                set when initializing the `StreamSocket`.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        with Path(filepath).open(\"rb\") as f:\n            bytes_data = base64.b64encode(f.read())\n            return await self.send_bytes(bytes_data, configs=configs)\n\n    async def send_bytes(\n        self,\n        bytes_data: bytes,\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; Any:\n        \"\"\"Send raw bytes on the `StreamSocket`.\n\n        Note: Input should be base64 encoded bytes.\n            You can use base64.b64encode() to encode a raw string.\n\n        Args:\n            bytes_data (bytes): Raw bytes of media to send on socket connection.\n            configs (Optional[List[ModelConfigBase]]): List of model configurations.\n                If set these configurations will overwrite any configurations\n                set when initializing the `StreamSocket`.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        bytes_str = bytes_data.decode(\"utf-8\")\n        return await self._send_str(bytes_str, raw_text=False, configs=configs)\n\n    async def send_text(\n        self,\n        text: str,\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; Any:\n        \"\"\"Send text on the `StreamSocket`.\n\n        Note: This method is intended for use with a `LanguageConfig`.\n            When the socket is configured for other modalities this method will fail.\n\n        Args:\n            text (str): Text to send to the language model.\n            configs (Optional[List[ModelConfigBase]]): List of model configurations.\n                If set these configurations will overwrite any configurations\n                set when initializing the `StreamSocket`.\n\n        Raises:\n            HumeClientException: If the socket is configured with a modality other than language.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        self._validate_configs_with_model_type(LanguageConfig, \"send_text\", configs=configs)\n        return await self._send_str(text, raw_text=True, configs=configs)\n\n    async def send_facemesh(\n        self,\n        landmarks: List[List[List[float]]],\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; Any:\n        \"\"\"Send facemesh landmarks on the `StreamSocket`.\n\n        Note: This method is intended for use with a `FacemeshConfig`.\n            When the socket is configured for other modalities this method will fail.\n\n        Args:\n            landmarks (List[List[List[float]]]): List of landmark points for multiple faces.\n                The shape of this 3-dimensional list should be (n, 478, 3) where n is the number\n                of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3\n                represents the (x, y, z) coordinates of each landmark.\n            configs (Optional[List[ModelConfigBase]]): List of model configurations.\n                If set these configurations will overwrite any configurations\n                set when initializing the `StreamSocket`.\n\n        Raises:\n            HumeClientException: If the socket is configured with a modality other than facemesh.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        self._validate_configs_with_model_type(FacemeshConfig, \"send_facemesh\", configs=configs)\n\n        n_faces = len(landmarks)\n        if n_faces &gt; self._FACE_LIMIT:\n            raise HumeClientException(\n                \"Number of faces sent in facemesh payload was greater \"\n                f\"than the limit of {self._FACE_LIMIT}, found {n_faces}.\"\n            )\n        if n_faces == 0:\n            raise HumeClientException(\"No faces sent in facemesh payload.\")\n        n_landmarks = len(landmarks[0])\n        if n_landmarks != self._N_LANDMARKS:\n            raise HumeClientException(\n                f\"Number of MediaPipe landmarks per face must be exactly {self._N_LANDMARKS}, \" f\"found {n_landmarks}.\"\n            )\n        if len(landmarks[0][0]) != self._N_SPATIAL:\n            raise HumeClientException(\n                \"Invalid facemesh payload detected. Each facemesh landmark should be an (x, y, z) point.\"\n            )\n\n        landmarks_str = json.dumps(landmarks)\n        bytes_data = base64.b64encode(landmarks_str.encode(\"utf-8\"))\n        return await self.send_bytes(bytes_data, configs=configs)\n\n    async def reset_stream(self) -&gt; Any:\n        \"\"\"Reset the streaming sliding window.\n\n        A sliding window of context is maintained for the lifetime of your streaming connection.\n        Call this method when some media has been fully processed and you want to continue using the same\n        streaming connection without leaking context across media samples.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        payload = {\n            \"reset_stream\": True,\n        }\n        return await self._send_payload(payload)\n\n    async def get_job_details(self) -&gt; Any:\n        \"\"\"Get details associated with the current streaming connection.\n\n        Returns:\n            Any: Response from the streaming API.\n        \"\"\"\n        payload = {\n            \"job_details\": True,\n        }\n        return await self._send_payload(payload)\n\n    async def _send_str(\n        self,\n        data: str,\n        *,\n        raw_text: bool,\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; Any:\n        serialized_configs = self._serialized_configs\n        if configs is not None:\n            serialized_configs = serialize_configs(configs)\n\n        payload: Dict[str, Any] = {\n            \"data\": data,\n            \"models\": serialized_configs,\n            \"raw_text\": raw_text,\n        }\n        if self._stream_window_ms is not None:\n            payload[\"stream_window_ms\"] = self._stream_window_ms\n        return await self._send_payload(payload)\n\n    async def _send_payload(self, payload: Dict[str, Any]) -&gt; Any:\n        request_message = json.dumps(payload)\n        await self._protocol.send(request_message)\n        response_data = await self._protocol.recv()\n        # Cast to str because websockets can send bytes, but we will always accept JSON strings\n        response_str = str(response_data)\n\n        try:\n            response = json.loads(response_str)\n        except json.JSONDecodeError as exc:\n            raise HumeClientException(\"Unexpected error when fetching streaming API predictions\") from exc\n\n        if \"error\" in response:\n            error = response[\"error\"]\n            code = response[\"code\"]\n            raise HumeClientException.from_error(code, error)\n\n        return response\n\n    def _validate_configs_with_model_type(\n        self,\n        config_type: Any,\n        method_name: str,\n        configs: Optional[List[ModelConfigBase]] = None,\n    ) -&gt; None:\n        config_method = \"Socket\"\n        payload_configs = self._configs\n        if configs is not None:\n            config_method = \"Payload\"\n            payload_configs = configs\n\n        for config in payload_configs:\n            if not isinstance(config, config_type):\n                config_name = config_type.__name__\n                invalid_config_name = config.__class__.__name__\n                raise HumeClientException(\n                    f\"{config_method} configured with {invalid_config_name}. \"\n                    f\"{method_name} is only supported when using a {config_name}.\"\n                )\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.__init__","title":"<code>__init__(protocol, configs, stream_window_ms=None)</code>","text":"<p>Construct a <code>StreamSocket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>protocol</code> <code>WebSocketClientProtocol</code> <p>Protocol instance from websockets library.</p> required <code>configs</code> <code>Optional[List[ModelConfigBase]]</code> <p>List of model configurations.</p> required <code>stream_window_ms</code> <code>Optional[int]</code> <p>Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection.</p> <code>None</code> <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If there is an error processing media over the socket connection.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>def __init__(\n    self,\n    protocol: \"WebSocketClientProtocol\",\n    configs: List[ModelConfigBase],\n    stream_window_ms: Optional[int] = None,\n):\n    \"\"\"Construct a `StreamSocket`.\n\n    Args:\n        protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n        configs (Optional[List[ModelConfigBase]]): List of model configurations.\n        stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when\n            aggregating media across streaming payloads within one websocket connection.\n\n    Raises:\n        HumeClientException: If there is an error processing media over the socket connection.\n    \"\"\"\n    self._protocol = protocol\n    self._configs = configs\n    self._stream_window_ms = stream_window_ms\n\n    # Serialize configs once for full lifetime of socket\n    self._serialized_configs = serialize_configs(configs)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.get_job_details","title":"<code>get_job_details()</code>  <code>async</code>","text":"<p>Get details associated with the current streaming connection.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def get_job_details(self) -&gt; Any:\n    \"\"\"Get details associated with the current streaming connection.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    payload = {\n        \"job_details\": True,\n    }\n    return await self._send_payload(payload)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.reset_stream","title":"<code>reset_stream()</code>  <code>async</code>","text":"<p>Reset the streaming sliding window.</p> <p>A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def reset_stream(self) -&gt; Any:\n    \"\"\"Reset the streaming sliding window.\n\n    A sliding window of context is maintained for the lifetime of your streaming connection.\n    Call this method when some media has been fully processed and you want to continue using the same\n    streaming connection without leaking context across media samples.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    payload = {\n        \"reset_stream\": True,\n    }\n    return await self._send_payload(payload)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.send_bytes","title":"<code>send_bytes(bytes_data, configs=None)</code>  <code>async</code>","text":"<p>Send raw bytes on the <code>StreamSocket</code>.</p> Input should be base64 encoded bytes. <p>You can use base64.b64encode() to encode a raw string.</p> <p>Parameters:</p> Name Type Description Default <code>bytes_data</code> <code>bytes</code> <p>Raw bytes of media to send on socket connection.</p> required <code>configs</code> <code>Optional[List[ModelConfigBase]]</code> <p>List of model configurations. If set these configurations will overwrite any configurations set when initializing the <code>StreamSocket</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def send_bytes(\n    self,\n    bytes_data: bytes,\n    configs: Optional[List[ModelConfigBase]] = None,\n) -&gt; Any:\n    \"\"\"Send raw bytes on the `StreamSocket`.\n\n    Note: Input should be base64 encoded bytes.\n        You can use base64.b64encode() to encode a raw string.\n\n    Args:\n        bytes_data (bytes): Raw bytes of media to send on socket connection.\n        configs (Optional[List[ModelConfigBase]]): List of model configurations.\n            If set these configurations will overwrite any configurations\n            set when initializing the `StreamSocket`.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    bytes_str = bytes_data.decode(\"utf-8\")\n    return await self._send_str(bytes_str, raw_text=False, configs=configs)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.send_facemesh","title":"<code>send_facemesh(landmarks, configs=None)</code>  <code>async</code>","text":"<p>Send facemesh landmarks on the <code>StreamSocket</code>.</p> This method is intended for use with a <code>FacemeshConfig</code>. <p>When the socket is configured for other modalities this method will fail.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[List[List[float]]]</code> <p>List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark.</p> required <code>configs</code> <code>Optional[List[ModelConfigBase]]</code> <p>List of model configurations. If set these configurations will overwrite any configurations set when initializing the <code>StreamSocket</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the socket is configured with a modality other than facemesh.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def send_facemesh(\n    self,\n    landmarks: List[List[List[float]]],\n    configs: Optional[List[ModelConfigBase]] = None,\n) -&gt; Any:\n    \"\"\"Send facemesh landmarks on the `StreamSocket`.\n\n    Note: This method is intended for use with a `FacemeshConfig`.\n        When the socket is configured for other modalities this method will fail.\n\n    Args:\n        landmarks (List[List[List[float]]]): List of landmark points for multiple faces.\n            The shape of this 3-dimensional list should be (n, 478, 3) where n is the number\n            of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3\n            represents the (x, y, z) coordinates of each landmark.\n        configs (Optional[List[ModelConfigBase]]): List of model configurations.\n            If set these configurations will overwrite any configurations\n            set when initializing the `StreamSocket`.\n\n    Raises:\n        HumeClientException: If the socket is configured with a modality other than facemesh.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    self._validate_configs_with_model_type(FacemeshConfig, \"send_facemesh\", configs=configs)\n\n    n_faces = len(landmarks)\n    if n_faces &gt; self._FACE_LIMIT:\n        raise HumeClientException(\n            \"Number of faces sent in facemesh payload was greater \"\n            f\"than the limit of {self._FACE_LIMIT}, found {n_faces}.\"\n        )\n    if n_faces == 0:\n        raise HumeClientException(\"No faces sent in facemesh payload.\")\n    n_landmarks = len(landmarks[0])\n    if n_landmarks != self._N_LANDMARKS:\n        raise HumeClientException(\n            f\"Number of MediaPipe landmarks per face must be exactly {self._N_LANDMARKS}, \" f\"found {n_landmarks}.\"\n        )\n    if len(landmarks[0][0]) != self._N_SPATIAL:\n        raise HumeClientException(\n            \"Invalid facemesh payload detected. Each facemesh landmark should be an (x, y, z) point.\"\n        )\n\n    landmarks_str = json.dumps(landmarks)\n    bytes_data = base64.b64encode(landmarks_str.encode(\"utf-8\"))\n    return await self.send_bytes(bytes_data, configs=configs)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.send_file","title":"<code>send_file(filepath, configs=None)</code>  <code>async</code>","text":"<p>Send a file on the <code>StreamSocket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Path to media file to send on socket connection.</p> required <code>configs</code> <code>Optional[List[ModelConfigBase]]</code> <p>List of model configurations. If set these configurations will overwrite any configurations set when initializing the <code>StreamSocket</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def send_file(\n    self,\n    filepath: Union[str, Path],\n    configs: Optional[List[ModelConfigBase]] = None,\n) -&gt; Any:\n    \"\"\"Send a file on the `StreamSocket`.\n\n    Args:\n        filepath (Path): Path to media file to send on socket connection.\n        configs (Optional[List[ModelConfigBase]]): List of model configurations.\n            If set these configurations will overwrite any configurations\n            set when initializing the `StreamSocket`.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    with Path(filepath).open(\"rb\") as f:\n        bytes_data = base64.b64encode(f.read())\n        return await self.send_bytes(bytes_data, configs=configs)\n</code></pre>"},{"location":"stream/stream-socket/#hume._measurement.stream.stream_socket.StreamSocket.send_text","title":"<code>send_text(text, configs=None)</code>  <code>async</code>","text":"<p>Send text on the <code>StreamSocket</code>.</p> This method is intended for use with a <code>LanguageConfig</code>. <p>When the socket is configured for other modalities this method will fail.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text to send to the language model.</p> required <code>configs</code> <code>Optional[List[ModelConfigBase]]</code> <p>List of model configurations. If set these configurations will overwrite any configurations set when initializing the <code>StreamSocket</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If the socket is configured with a modality other than language.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Response from the streaming API.</p> Source code in <code>hume/_measurement/stream/stream_socket.py</code> <pre><code>async def send_text(\n    self,\n    text: str,\n    configs: Optional[List[ModelConfigBase]] = None,\n) -&gt; Any:\n    \"\"\"Send text on the `StreamSocket`.\n\n    Note: This method is intended for use with a `LanguageConfig`.\n        When the socket is configured for other modalities this method will fail.\n\n    Args:\n        text (str): Text to send to the language model.\n        configs (Optional[List[ModelConfigBase]]): List of model configurations.\n            If set these configurations will overwrite any configurations\n            set when initializing the `StreamSocket`.\n\n    Raises:\n        HumeClientException: If the socket is configured with a modality other than language.\n\n    Returns:\n        Any: Response from the streaming API.\n    \"\"\"\n    self._validate_configs_with_model_type(LanguageConfig, \"send_text\", configs=configs)\n    return await self._send_str(text, raw_text=True, configs=configs)\n</code></pre>"},{"location":"voice/hume-voice-client/","title":"HumeVoiceClient","text":"<p>             Bases: <code>ChatMixin</code>, <code>ChatsMixin</code>, <code>ConfigsMixin</code></p> <p>Empathic Voice Interface client.</p> Source code in <code>hume/_voice/hume_voice_client.py</code> <pre><code>class HumeVoiceClient(ChatMixin, ChatsMixin, ConfigsMixin):\n    \"\"\"Empathic Voice Interface client.\"\"\"\n</code></pre>"},{"location":"voice/microphone-interface/","title":"MicrophoneInterface","text":"<p>Interface for connecting a device microphone to an EVI connection.</p> Source code in <code>hume/_voice/microphone/microphone_interface.py</code> <pre><code>@dataclass\nclass MicrophoneInterface:\n    \"\"\"Interface for connecting a device microphone to an EVI connection.\"\"\"\n\n    DEFAULT_ALLOW_USER_INTERRUPT: ClassVar[bool] = False\n\n    @classmethod\n    async def start(\n        cls,\n        socket: VoiceSocket,\n        device: Optional[int] = Microphone.DEFAULT_DEVICE,\n        allow_user_interrupt: bool = DEFAULT_ALLOW_USER_INTERRUPT,\n    ) -&gt; None:\n        \"\"\"Start the microphone interface.\n\n        Args:\n            socket (VoiceSocket): EVI socket.\n            device (Optional[int]): Device index for the microphone.\n            allow_user_interrupt (bool): Whether to allow the user to interrupt EVI.\n        \"\"\"\n        with Microphone.context(device=device) as microphone:\n            sender = MicrophoneSender.new(microphone=microphone, allow_interrupt=allow_user_interrupt)\n            chat_client = ChatClient.new(sender=sender)\n            print(\"Configuring socket with microphone settings...\")\n            await socket.update_session_settings(\n                sample_rate=microphone.sample_rate,\n                num_channels=microphone.num_channels,\n            )\n            print(\"Microphone connected. Say something!\")\n            await chat_client.run(socket=socket)\n</code></pre>"},{"location":"voice/microphone-interface/#hume._voice.microphone.microphone_interface.MicrophoneInterface.start","title":"<code>start(socket, device=Microphone.DEFAULT_DEVICE, allow_user_interrupt=DEFAULT_ALLOW_USER_INTERRUPT)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Start the microphone interface.</p> <p>Parameters:</p> Name Type Description Default <code>socket</code> <code>VoiceSocket</code> <p>EVI socket.</p> required <code>device</code> <code>Optional[int]</code> <p>Device index for the microphone.</p> <code>DEFAULT_DEVICE</code> <code>allow_user_interrupt</code> <code>bool</code> <p>Whether to allow the user to interrupt EVI.</p> <code>DEFAULT_ALLOW_USER_INTERRUPT</code> Source code in <code>hume/_voice/microphone/microphone_interface.py</code> <pre><code>@classmethod\nasync def start(\n    cls,\n    socket: VoiceSocket,\n    device: Optional[int] = Microphone.DEFAULT_DEVICE,\n    allow_user_interrupt: bool = DEFAULT_ALLOW_USER_INTERRUPT,\n) -&gt; None:\n    \"\"\"Start the microphone interface.\n\n    Args:\n        socket (VoiceSocket): EVI socket.\n        device (Optional[int]): Device index for the microphone.\n        allow_user_interrupt (bool): Whether to allow the user to interrupt EVI.\n    \"\"\"\n    with Microphone.context(device=device) as microphone:\n        sender = MicrophoneSender.new(microphone=microphone, allow_interrupt=allow_user_interrupt)\n        chat_client = ChatClient.new(sender=sender)\n        print(\"Configuring socket with microphone settings...\")\n        await socket.update_session_settings(\n            sample_rate=microphone.sample_rate,\n            num_channels=microphone.num_channels,\n        )\n        print(\"Microphone connected. Say something!\")\n        await chat_client.run(socket=socket)\n</code></pre>"},{"location":"voice/voice-chat/","title":"VoiceChat","text":"<p>             Bases: <code>BaseModel</code></p> <p>Voice chat model.</p> Source code in <code>hume/_voice/models/chats_models.py</code> <pre><code>class VoiceChat(BaseModel):\n    \"\"\"Voice chat model.\"\"\"\n\n    id: str\n</code></pre>"},{"location":"voice/voice-config/","title":"VoiceConfig","text":"<p>             Bases: <code>BaseModel</code></p> <p>EVI configuration.</p> Source code in <code>hume/_voice/models/configs_models.py</code> <pre><code>class VoiceConfig(BaseModel):\n    \"\"\"EVI configuration.\"\"\"\n\n    id: str\n    name: str\n    description: Optional[str]\n    created_on: int\n    modified_on: int\n    prompt: Optional[str]\n</code></pre>"},{"location":"voice/voice-socket/","title":"VoiceSocket","text":"<p>Voice socket connection.</p> Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>class VoiceSocket:\n    \"\"\"Voice socket connection.\"\"\"\n\n    DEFAULT_CUT_MS: ClassVar[int] = 250\n    DEFAULT_NUM_CHANNELS: ClassVar[int] = 1\n    DEFAULT_SAMPLE_RATE: ClassVar[int] = 44_100\n\n    def __init__(self, protocol: WebSocket):\n        \"\"\"Construct a `VoiceSocket`.\n\n        Args:\n            protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n\n        Raises:\n            HumeClientException: If there is an error processing media over the socket connection.\n        \"\"\"\n        self._protocol = protocol\n\n        self._num_channels = self.DEFAULT_NUM_CHANNELS\n        self._sample_rate = self.DEFAULT_SAMPLE_RATE\n\n    async def __aiter__(self) -&gt; AsyncIterator[Any]:\n        \"\"\"Async iterator for the voice socket.\"\"\"\n        async for message in self._protocol:\n            yield message\n\n    async def send(self, byte_str: bytes) -&gt; None:\n        \"\"\"Send a byte string over the voice socket.\n\n        Args:\n            byte_str (bytes): Byte string to send.\n        \"\"\"\n        await self._protocol.send(byte_str)\n\n    async def recv(self) -&gt; Any:\n        \"\"\"Receive a message on the voice socket.\"\"\"\n        await self._protocol.recv()\n\n    async def update_session_settings(\n        self,\n        *,\n        sample_rate: Optional[int] = None,\n        num_channels: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Update the EVI session settings.\"\"\"\n        if num_channels is not None:\n            self._num_channels = num_channels\n        if sample_rate is not None:\n            self._sample_rate = sample_rate\n\n        session_settings = SessionSettings(\n            audio=AudioSettings(\n                channels=num_channels,\n                sample_rate=sample_rate,\n            ),\n        )\n\n        settings_dict = session_settings.model_dump(exclude_none=True)\n\n        logger.info(f\"Updating session settings to: {settings_dict}\")\n        message = json.dumps(settings_dict)\n        await self._protocol.send(message)\n\n    async def send_file(self, filepath: Path) -&gt; None:\n        \"\"\"Send a file over the voice socket.\n\n        Args:\n            filepath (Path): Filepath to the file to send over the socket.\n        \"\"\"\n        with filepath.open(\"rb\") as f:\n            segment: AudioSegment = AudioSegment.from_file(f)\n            segment = segment.set_frame_rate(self._sample_rate).set_channels(self._num_channels)\n            audio_bytes = segment.raw_data\n            await self._protocol.send(audio_bytes)\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.__aiter__","title":"<code>__aiter__()</code>  <code>async</code>","text":"<p>Async iterator for the voice socket.</p> Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>async def __aiter__(self) -&gt; AsyncIterator[Any]:\n    \"\"\"Async iterator for the voice socket.\"\"\"\n    async for message in self._protocol:\n        yield message\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.__init__","title":"<code>__init__(protocol)</code>","text":"<p>Construct a <code>VoiceSocket</code>.</p> <p>Parameters:</p> Name Type Description Default <code>protocol</code> <code>WebSocketClientProtocol</code> <p>Protocol instance from websockets library.</p> required <p>Raises:</p> Type Description <code>HumeClientException</code> <p>If there is an error processing media over the socket connection.</p> Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>def __init__(self, protocol: WebSocket):\n    \"\"\"Construct a `VoiceSocket`.\n\n    Args:\n        protocol (WebSocketClientProtocol): Protocol instance from websockets library.\n\n    Raises:\n        HumeClientException: If there is an error processing media over the socket connection.\n    \"\"\"\n    self._protocol = protocol\n\n    self._num_channels = self.DEFAULT_NUM_CHANNELS\n    self._sample_rate = self.DEFAULT_SAMPLE_RATE\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.recv","title":"<code>recv()</code>  <code>async</code>","text":"<p>Receive a message on the voice socket.</p> Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>async def recv(self) -&gt; Any:\n    \"\"\"Receive a message on the voice socket.\"\"\"\n    await self._protocol.recv()\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.send","title":"<code>send(byte_str)</code>  <code>async</code>","text":"<p>Send a byte string over the voice socket.</p> <p>Parameters:</p> Name Type Description Default <code>byte_str</code> <code>bytes</code> <p>Byte string to send.</p> required Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>async def send(self, byte_str: bytes) -&gt; None:\n    \"\"\"Send a byte string over the voice socket.\n\n    Args:\n        byte_str (bytes): Byte string to send.\n    \"\"\"\n    await self._protocol.send(byte_str)\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.send_file","title":"<code>send_file(filepath)</code>  <code>async</code>","text":"<p>Send a file over the voice socket.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Path</code> <p>Filepath to the file to send over the socket.</p> required Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>async def send_file(self, filepath: Path) -&gt; None:\n    \"\"\"Send a file over the voice socket.\n\n    Args:\n        filepath (Path): Filepath to the file to send over the socket.\n    \"\"\"\n    with filepath.open(\"rb\") as f:\n        segment: AudioSegment = AudioSegment.from_file(f)\n        segment = segment.set_frame_rate(self._sample_rate).set_channels(self._num_channels)\n        audio_bytes = segment.raw_data\n        await self._protocol.send(audio_bytes)\n</code></pre>"},{"location":"voice/voice-socket/#hume._voice.voice_socket.VoiceSocket.update_session_settings","title":"<code>update_session_settings(*, sample_rate=None, num_channels=None)</code>  <code>async</code>","text":"<p>Update the EVI session settings.</p> Source code in <code>hume/_voice/voice_socket.py</code> <pre><code>async def update_session_settings(\n    self,\n    *,\n    sample_rate: Optional[int] = None,\n    num_channels: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Update the EVI session settings.\"\"\"\n    if num_channels is not None:\n        self._num_channels = num_channels\n    if sample_rate is not None:\n        self._sample_rate = sample_rate\n\n    session_settings = SessionSettings(\n        audio=AudioSettings(\n            channels=num_channels,\n            sample_rate=sample_rate,\n        ),\n    )\n\n    settings_dict = session_settings.model_dump(exclude_none=True)\n\n    logger.info(f\"Updating session settings to: {settings_dict}\")\n    message = json.dumps(settings_dict)\n    await self._protocol.send(message)\n</code></pre>"}]}