{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Requirements Python versions 3.8 and 3.9 are supported Installation Basic installation: pip install hume Websocket and streaming features can be enabled with: pip install hume [ stream ] Basic Usage Submit a new batch job Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ config ]) print ( job ) print ( \"Running...\" ) job . await_complete () job . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded to predictions.json\" ) job . download_artifacts ( \"artifacts.zip\" ) print ( \"Artifacts downloaded to artifacts.zip\" ) Rehydrate a batch job from a job ID from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job ) Stream predictions over a websocket Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ config ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Other Resources Hume AI Homepage Platform Documentation API Reference Support The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Home"},{"location":"#home","text":"","title":"Home"},{"location":"#requirements","text":"Python versions 3.8 and 3.9 are supported","title":"Requirements"},{"location":"#installation","text":"Basic installation: pip install hume Websocket and streaming features can be enabled with: pip install hume [ stream ]","title":"Installation"},{"location":"#basic-usage","text":"","title":"Basic Usage"},{"location":"#submit-a-new-batch-job","text":"Note: Your personal API key can be found in the profile section of beta.hume.ai from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ config ]) print ( job ) print ( \"Running...\" ) job . await_complete () job . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded to predictions.json\" ) job . download_artifacts ( \"artifacts.zip\" ) print ( \"Artifacts downloaded to artifacts.zip\" )","title":"Submit a new batch job"},{"location":"#rehydrate-a-batch-job-from-a-job-id","text":"from hume import HumeBatchClient client = HumeBatchClient ( \"<your-api-key>\" ) job_id = \"<your-job-id>\" job = client . get_job ( job_id ) print ( job )","title":"Rehydrate a batch job from a job ID"},{"location":"#stream-predictions-over-a-websocket","text":"Note: pip install hume[stream] is required to use websocket features import asyncio from hume import HumeStreamClient from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ config ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ())","title":"Stream predictions over a websocket"},{"location":"#other-resources","text":"Hume AI Homepage Platform Documentation API Reference","title":"Other Resources"},{"location":"#support","text":"The Python SDK is open source! More details can be found on GitHub . If you've found a bug with this SDK please open an issue !","title":"Support"},{"location":"batch/batch-job-details/","text":"Batch job details. Source code in hume/_batch/batch_job_details.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class BatchJobDetails : \"\"\"Batch job details.\"\"\" def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], files : List [ str ], state : BatchJobState , callback_url : Optional [ str ] = None , notify : bool = False , ): \"\"\"Construct a BatchJobDetails. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. files (List[str]): Files processed in the `BatchJob`. state (BatchJobState): State of `BatchJob`. callback_url (Optional[str]): A URL to which a POST request is sent upon job completion. notify (bool): Whether an email notification should be sent upon job completion. \"\"\" self . configs = configs self . urls = urls self . files = files self . state = state self . callback_url = callback_url self . notify = notify @classmethod def from_response ( cls , response : Any ) -> \"BatchJobDetails\" : \"\"\"Construct a `BatchJobDetails` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobDetails: A `BatchJobDetails` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): if config_dict is None : continue model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config urls = request [ \"urls\" ] files = request [ \"files\" ] callback_url = request [ \"callback_url\" ] notify = request [ \"notify\" ] state_dict = response [ \"state\" ] state = BatchJobState ( status = BatchJobStatus . from_str ( state_dict [ \"status\" ]), created_timestamp_ms = state_dict . get ( \"created_timestamp_ms\" ), started_timestamp_ms = state_dict . get ( \"started_timestamp_ms\" ), ended_timestamp_ms = state_dict . get ( \"ended_timestamp_ms\" ), ) return cls ( configs = configs , urls = urls , files = files , state = state , callback_url = callback_url , notify = notify , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc @classmethod def _get_invalid_response_message ( cls , response : Any ) -> str : response_str = json . dumps ( response ) message = f \"Could not parse response into BatchJobDetails: { response_str } \" # Check for invalid API key if \"fault\" in response and \"faultstring\" in response [ \"fault\" ]: fault_string = response [ \"fault\" ][ \"faultstring\" ] if fault_string == \"Invalid ApiKey\" : message = \"HumeBatchClient initialized with invalid API key.\" return message def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . state . status def get_run_time_ms ( self ) -> Optional [ int ]: \"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . started_timestamp_ms is not None and self . state . ended_timestamp_ms is not None : return self . state . ended_timestamp_ms - self . state . started_timestamp_ms return None def get_created_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job was created. Returns: Optional[datetime]: Datetime when the job was created. If the job has not started then `None` is returned. \"\"\" if self . state . created_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . created_timestamp_ms / 1000 ) def get_started_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . state . started_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . started_timestamp_ms / 1000 ) def get_ended_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . ended_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . ended_timestamp_ms / 1000 ) __init__ ( * , configs , urls , files , state , callback_url = None , notify = False ) Construct a BatchJobDetails. Parameters: Name Type Description Default configs Dict [ ModelType , ModelConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required files List [ str ] Files processed in the BatchJob . required state BatchJobState State of BatchJob . required callback_url Optional [ str ] A URL to which a POST request is sent upon job completion. None notify bool Whether an email notification should be sent upon job completion. False Source code in hume/_batch/batch_job_details.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], files : List [ str ], state : BatchJobState , callback_url : Optional [ str ] = None , notify : bool = False , ): \"\"\"Construct a BatchJobDetails. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. files (List[str]): Files processed in the `BatchJob`. state (BatchJobState): State of `BatchJob`. callback_url (Optional[str]): A URL to which a POST request is sent upon job completion. notify (bool): Whether an email notification should be sent upon job completion. \"\"\" self . configs = configs self . urls = urls self . files = files self . state = state self . callback_url = callback_url self . notify = notify from_response ( response ) classmethod Construct a BatchJobDetails from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobDetails BatchJobDetails A BatchJobDetails based on a batch API job response. Source code in hume/_batch/batch_job_details.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobDetails\" : \"\"\"Construct a `BatchJobDetails` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobDetails: A `BatchJobDetails` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): if config_dict is None : continue model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config urls = request [ \"urls\" ] files = request [ \"files\" ] callback_url = request [ \"callback_url\" ] notify = request [ \"notify\" ] state_dict = response [ \"state\" ] state = BatchJobState ( status = BatchJobStatus . from_str ( state_dict [ \"status\" ]), created_timestamp_ms = state_dict . get ( \"created_timestamp_ms\" ), started_timestamp_ms = state_dict . get ( \"started_timestamp_ms\" ), ended_timestamp_ms = state_dict . get ( \"ended_timestamp_ms\" ), ) return cls ( configs = configs , urls = urls , files = files , state = state , callback_url = callback_url , notify = notify , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc get_created_time () Get the time the job was created. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job was created. If the job has not started then None is returned. Source code in hume/_batch/batch_job_details.py 123 124 125 126 127 128 129 130 131 132 def get_created_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job was created. Returns: Optional[datetime]: Datetime when the job was created. If the job has not started then `None` is returned. \"\"\" if self . state . created_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . created_timestamp_ms / 1000 ) get_ended_time () Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_details.py 145 146 147 148 149 150 151 152 153 154 def get_ended_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . ended_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . ended_timestamp_ms / 1000 ) get_run_time_ms () Get the total time in milliseconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_details.py 112 113 114 115 116 117 118 119 120 121 def get_run_time_ms ( self ) -> Optional [ int ]: \"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . started_timestamp_ms is not None and self . state . ended_timestamp_ms is not None : return self . state . ended_timestamp_ms - self . state . started_timestamp_ms return None get_started_time () Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_details.py 134 135 136 137 138 139 140 141 142 143 def get_started_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . state . started_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . started_timestamp_ms / 1000 ) get_status () Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job_details.py 104 105 106 107 108 109 110 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . state . status","title":"BatchJobDetails"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.__init__","text":"Construct a BatchJobDetails. Parameters: Name Type Description Default configs Dict [ ModelType , ModelConfigBase ] Configurations for the BatchJob . required urls List [ str ] URLs processed in the BatchJob . required files List [ str ] Files processed in the BatchJob . required state BatchJobState State of BatchJob . required callback_url Optional [ str ] A URL to which a POST request is sent upon job completion. None notify bool Whether an email notification should be sent upon job completion. False Source code in hume/_batch/batch_job_details.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , * , configs : Dict [ ModelType , ModelConfigBase ], urls : List [ str ], files : List [ str ], state : BatchJobState , callback_url : Optional [ str ] = None , notify : bool = False , ): \"\"\"Construct a BatchJobDetails. Args: configs (Dict[ModelType, ModelConfigBase]): Configurations for the `BatchJob`. urls (List[str]): URLs processed in the `BatchJob`. files (List[str]): Files processed in the `BatchJob`. state (BatchJobState): State of `BatchJob`. callback_url (Optional[str]): A URL to which a POST request is sent upon job completion. notify (bool): Whether an email notification should be sent upon job completion. \"\"\" self . configs = configs self . urls = urls self . files = files self . state = state self . callback_url = callback_url self . notify = notify","title":"__init__()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.from_response","text":"Construct a BatchJobDetails from a batch API job response. Parameters: Name Type Description Default response Any Batch API job response. required Returns: Name Type Description BatchJobDetails BatchJobDetails A BatchJobDetails based on a batch API job response. Source code in hume/_batch/batch_job_details.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @classmethod def from_response ( cls , response : Any ) -> \"BatchJobDetails\" : \"\"\"Construct a `BatchJobDetails` from a batch API job response. Args: response (Any): Batch API job response. Returns: BatchJobDetails: A `BatchJobDetails` based on a batch API job response. \"\"\" try : request = response [ \"request\" ] configs = {} for model_name , config_dict in request [ \"models\" ] . items (): if config_dict is None : continue model_type = ModelType . from_str ( model_name ) config = config_from_model_type ( model_type ) . from_dict ( config_dict ) configs [ model_type ] = config urls = request [ \"urls\" ] files = request [ \"files\" ] callback_url = request [ \"callback_url\" ] notify = request [ \"notify\" ] state_dict = response [ \"state\" ] state = BatchJobState ( status = BatchJobStatus . from_str ( state_dict [ \"status\" ]), created_timestamp_ms = state_dict . get ( \"created_timestamp_ms\" ), started_timestamp_ms = state_dict . get ( \"started_timestamp_ms\" ), ended_timestamp_ms = state_dict . get ( \"ended_timestamp_ms\" ), ) return cls ( configs = configs , urls = urls , files = files , state = state , callback_url = callback_url , notify = notify , ) # pylint: disable=broad-except except Exception as exc : message = cls . _get_invalid_response_message ( response ) raise HumeClientException ( message ) from exc","title":"from_response()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_created_time","text":"Get the time the job was created. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job was created. If the job has not started then None is returned. Source code in hume/_batch/batch_job_details.py 123 124 125 126 127 128 129 130 131 132 def get_created_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job was created. Returns: Optional[datetime]: Datetime when the job was created. If the job has not started then `None` is returned. \"\"\" if self . state . created_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . created_timestamp_ms / 1000 )","title":"get_created_time()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_ended_time","text":"Get the time the job stopped running if the job is in a terminal state. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_details.py 145 146 147 148 149 150 151 152 153 154 def get_ended_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job stopped running if the job is in a terminal state. Returns: Optional[datetime]: Datetime when the job started running. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . ended_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . ended_timestamp_ms / 1000 )","title":"get_ended_time()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_run_time_ms","text":"Get the total time in milliseconds it took for the job to run if the job is in a terminal state. Returns: Type Description Optional [ int ] Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then None is returned. Source code in hume/_batch/batch_job_details.py 112 113 114 115 116 117 118 119 120 121 def get_run_time_ms ( self ) -> Optional [ int ]: \"\"\"Get the total time in milliseconds it took for the job to run if the job is in a terminal state. Returns: Optional[int]: Time in milliseconds it took for the job to run. If the job is not in a terminal state then `None` is returned. \"\"\" if self . state . started_timestamp_ms is not None and self . state . ended_timestamp_ms is not None : return self . state . ended_timestamp_ms - self . state . started_timestamp_ms return None","title":"get_run_time_ms()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_started_time","text":"Get the time the job started running. Returns: Type Description Optional [ datetime ] Optional[datetime]: Datetime when the job started running. If the job has not started then None is returned. Source code in hume/_batch/batch_job_details.py 134 135 136 137 138 139 140 141 142 143 def get_started_time ( self ) -> Optional [ datetime ]: \"\"\"Get the time the job started running. Returns: Optional[datetime]: Datetime when the job started running. If the job has not started then `None` is returned. \"\"\" if self . state . started_timestamp_ms is None : return None return datetime . utcfromtimestamp ( self . state . started_timestamp_ms / 1000 )","title":"get_started_time()"},{"location":"batch/batch-job-details/#hume._batch.batch_job_details.BatchJobDetails.get_status","text":"Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job_details.py 104 105 106 107 108 109 110 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . state . status","title":"get_status()"},{"location":"batch/batch-job-state/","text":"Batch job state. Parameters: Name Type Description Default status BatchJobStatus Status of the batch job. required created_timestamp_ms Optional [ int ] Time when job was created. required started_timestamp_ms Optional [ int ] Time when job started. required ended_timestamp_ms Optional [ int ] Time when job ended. required Source code in hume/_batch/batch_job_state.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @dataclass class BatchJobState : \"\"\"Batch job state. Args: status (BatchJobStatus): Status of the batch job. created_timestamp_ms (Optional[int]): Time when job was created. started_timestamp_ms (Optional[int]): Time when job started. ended_timestamp_ms (Optional[int]): Time when job ended. \"\"\" status : BatchJobStatus created_timestamp_ms : Optional [ int ] started_timestamp_ms : Optional [ int ] ended_timestamp_ms : Optional [ int ]","title":"BatchJobState"},{"location":"batch/batch-job-status/","text":"Bases: Enum Batch job status. Source code in hume/_batch/batch_job_status.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class BatchJobStatus ( Enum ): \"\"\"Batch job status.\"\"\" COMPLETED = \"COMPLETED\" FAILED = \"FAILED\" IN_PROGRESS = \"IN_PROGRESS\" QUEUED = \"QUEUED\" @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ] @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) from_str ( status ) classmethod Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" ) is_terminal ( status ) classmethod Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"BatchJobStatus"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.from_str","text":"Convert a status to a string. Parameters: Name Type Description Default status str Status to convert. required Returns: Name Type Description BatchJobStatus BatchJobStatus The enum variant for the given string. Source code in hume/_batch/batch_job_status.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @classmethod def from_str ( cls , status : str ) -> \"BatchJobStatus\" : \"\"\"Convert a status to a string. Args: status (str): Status to convert. Returns: BatchJobStatus: The enum variant for the given string. \"\"\" for _ , enum_value in cls . __members__ . items (): if enum_value . value == status : return enum_value raise ValueError ( f \"Unknown status ' { status } '\" )","title":"from_str()"},{"location":"batch/batch-job-status/#hume._batch.batch_job_status.BatchJobStatus.is_terminal","text":"Check if a status is \"terminal\". Parameters: Name Type Description Default status BatchJobStatus Status to check. required Returns: Name Type Description bool bool Whether the status is \"terminal\". Source code in hume/_batch/batch_job_status.py 13 14 15 16 17 18 19 20 21 22 23 @classmethod def is_terminal ( cls , status : \"BatchJobStatus\" ) -> bool : \"\"\"Check if a status is \"terminal\". Args: status (BatchJobStatus): Status to check. Returns: bool: Whether the status is \"terminal\". \"\"\" return status in [ cls . COMPLETED , cls . FAILED ]","title":"is_terminal()"},{"location":"batch/batch-job/","text":"Batch job. Source code in hume/_batch/batch_job.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class BatchJob : \"\"\"Batch job.\"\"\" def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_details () . state . status def get_predictions ( self ) -> Any : \"\"\"Get `BatchJob` predictions. Returns: Any: Predictions for the `BatchJob`. \"\"\" return self . _client . get_job_predictions ( self . id ) def download_predictions ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Union[str, Path]): Filepath where predictions will be downloaded. \"\"\" predictions = self . get_predictions () with Path ( filepath ) . open ( \"w\" ) as f : json . dump ( predictions , f ) def download_artifacts ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` artifacts zip file. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. \"\"\" self . _client . download_job_artifacts ( self . id , filepath ) def get_details ( self ) -> BatchJobDetails : \"\"\"Get details for the BatchJob. Note that the details for a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" return self . _client . get_job_details ( self . id ) def await_complete ( self , timeout : int = 300 ) -> BatchJobDetails : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) # pylint: disable=unused-argument @retry () def _await_complete ( self , timeout : int = 300 ) -> BatchJobDetails : details = self . _client . get_job_details ( self . id ) if not BatchJobStatus . is_terminal ( details . state . status ): raise RetryIterError return details def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' __init__ ( client , job_id ) Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 17 18 19 20 21 22 23 24 25 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id __repr__ () Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 100 101 102 103 104 105 106 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")' await_complete ( timeout = 300 ) Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientException will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobDetails BatchJobDetails Details for the BatchJob . Source code in hume/_batch/batch_job.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def await_complete ( self , timeout : int = 300 ) -> BatchJobDetails : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout ) download_artifacts ( filepath ) Download BatchJob artifacts zip file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts will be downloaded. required Source code in hume/_batch/batch_job.py 53 54 55 56 57 58 59 def download_artifacts ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` artifacts zip file. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. \"\"\" self . _client . download_job_artifacts ( self . id , filepath ) download_predictions ( filepath ) Download BatchJob predictions file. Parameters: Name Type Description Default filepath Union [ str , Path ] Filepath where predictions will be downloaded. required Source code in hume/_batch/batch_job.py 43 44 45 46 47 48 49 50 51 def download_predictions ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Union[str, Path]): Filepath where predictions will be downloaded. \"\"\" predictions = self . get_predictions () with Path ( filepath ) . open ( \"w\" ) as f : json . dump ( predictions , f ) get_details () Get details for the BatchJob. Note that the details for a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning. Returns: Name Type Description BatchJobDetails BatchJobDetails Details for the BatchJob . Source code in hume/_batch/batch_job.py 61 62 63 64 65 66 67 68 69 70 71 def get_details ( self ) -> BatchJobDetails : \"\"\"Get details for the BatchJob. Note that the details for a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" return self . _client . get_job_details ( self . id ) get_predictions () Get BatchJob predictions. Returns: Name Type Description Any Any Predictions for the BatchJob . Source code in hume/_batch/batch_job.py 35 36 37 38 39 40 41 def get_predictions ( self ) -> Any : \"\"\"Get `BatchJob` predictions. Returns: Any: Predictions for the `BatchJob`. \"\"\" return self . _client . get_job_predictions ( self . id ) get_status () Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 27 28 29 30 31 32 33 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_details () . state . status","title":"BatchJob"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__init__","text":"Construct a BatchJob. Parameters: Name Type Description Default client HumeBatchClient HumeBatchClient instance. required job_id str Job ID. required Source code in hume/_batch/batch_job.py 17 18 19 20 21 22 23 24 25 def __init__ ( self , client : \"HumeBatchClient\" , job_id : str ): \"\"\"Construct a BatchJob. Args: client (HumeBatchClient): HumeBatchClient instance. job_id (str): Job ID. \"\"\" self . _client = client self . id = job_id","title":"__init__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.__repr__","text":"Get the string representation of the BatchJob . Returns: Type Description str The the string representation of the BatchJob . Source code in hume/_batch/batch_job.py 100 101 102 103 104 105 106 def __repr__ ( self ) -> str : \"\"\"Get the string representation of the `BatchJob`. Returns: The the string representation of the `BatchJob`. \"\"\" return f 'Job(id=\" { self . id } \")'","title":"__repr__()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.await_complete","text":"Block until the job has reached a terminal status. Parameters: Name Type Description Default timeout int Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a HumeClientException will be raised to the caller of await_complete . 300 Raises: Type Description ValueError If the timeout is not valid. Returns: Name Type Description BatchJobDetails BatchJobDetails Details for the BatchJob . Source code in hume/_batch/batch_job.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def await_complete ( self , timeout : int = 300 ) -> BatchJobDetails : \"\"\"Block until the job has reached a terminal status. Args: timeout (int): Maximum time in seconds to await. If the timeout is reached before the job reaches a terminal state the job will continue to be processed, but a `HumeClientException` will be raised to the caller of `await_complete`. Raises: ValueError: If the timeout is not valid. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" if timeout < 1 : raise ValueError ( \"timeout must be at least 1 second\" ) return self . _await_complete ( timeout = timeout )","title":"await_complete()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.download_artifacts","text":"Download BatchJob artifacts zip file. Parameters: Name Type Description Default filepath Optional [ Union [ str , Path ]] Filepath where artifacts will be downloaded. required Source code in hume/_batch/batch_job.py 53 54 55 56 57 58 59 def download_artifacts ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` artifacts zip file. Args: filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. \"\"\" self . _client . download_job_artifacts ( self . id , filepath )","title":"download_artifacts()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.download_predictions","text":"Download BatchJob predictions file. Parameters: Name Type Description Default filepath Union [ str , Path ] Filepath where predictions will be downloaded. required Source code in hume/_batch/batch_job.py 43 44 45 46 47 48 49 50 51 def download_predictions ( self , filepath : Union [ str , Path ]) -> None : \"\"\"Download `BatchJob` predictions file. Args: filepath (Union[str, Path]): Filepath where predictions will be downloaded. \"\"\" predictions = self . get_predictions () with Path ( filepath ) . open ( \"w\" ) as f : json . dump ( predictions , f )","title":"download_predictions()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_details","text":"Get details for the BatchJob. Note that the details for a job may be fetched before the job has completed. You may want to use job.await_complete() which will wait for the job to reach a terminal state before returning. Returns: Name Type Description BatchJobDetails BatchJobDetails Details for the BatchJob . Source code in hume/_batch/batch_job.py 61 62 63 64 65 66 67 68 69 70 71 def get_details ( self ) -> BatchJobDetails : \"\"\"Get details for the BatchJob. Note that the details for a job may be fetched before the job has completed. You may want to use `job.await_complete()` which will wait for the job to reach a terminal state before returning. Returns: BatchJobDetails: Details for the `BatchJob`. \"\"\" return self . _client . get_job_details ( self . id )","title":"get_details()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_predictions","text":"Get BatchJob predictions. Returns: Name Type Description Any Any Predictions for the BatchJob . Source code in hume/_batch/batch_job.py 35 36 37 38 39 40 41 def get_predictions ( self ) -> Any : \"\"\"Get `BatchJob` predictions. Returns: Any: Predictions for the `BatchJob`. \"\"\" return self . _client . get_job_predictions ( self . id )","title":"get_predictions()"},{"location":"batch/batch-job/#hume._batch.batch_job.BatchJob.get_status","text":"Get the status of the job. Returns: Name Type Description BatchJobStatus BatchJobStatus The status of the BatchJob . Source code in hume/_batch/batch_job.py 27 28 29 30 31 32 33 def get_status ( self ) -> BatchJobStatus : \"\"\"Get the status of the job. Returns: BatchJobStatus: The status of the `BatchJob`. \"\"\" return self . get_details () . state . status","title":"get_status()"},{"location":"batch/hume-batch-client/","text":"Bases: ClientBase Batch API client. Example from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient ( \"<your-api-key>\" ) urls = [ \"https://tinyurl.com/hume-img\" ] config = FaceConfig ( identify_faces = True ) job = client . submit_job ( urls , [ config ]) print ( job ) print ( \"Running...\" ) job . await_complete () job . download_predictions ( \"predictions.json\" ) print ( \"Predictions downloaded to predictions.json\" ) job . download_artifacts ( \"artifacts.zip\" ) print ( \"Artifacts downloaded to artifacts.zip\" ) Source code in hume/_batch/hume_batch_client.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 class HumeBatchClient ( ClientBase ): \"\"\"Batch API client. Example: ```python from hume import HumeBatchClient from hume.models.config import FaceConfig client = HumeBatchClient(\"<your-api-key>\") urls = [\"https://tinyurl.com/hume-img\"] config = FaceConfig(identify_faces=True) job = client.submit_job(urls, [config]) print(job) print(\"Running...\") job.await_complete() job.download_predictions(\"predictions.json\") print(\"Predictions downloaded to predictions.json\") job.download_artifacts(\"artifacts.zip\") print(\"Artifacts downloaded to artifacts.zip\") ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs ) @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ], transcription_config : Optional [ TranscriptionConfig ] = None , callback_url : Optional [ str ] = None , ) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object. callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _construct_request ( configs , urls , transcription_config , callback_url ) return self . _submit_job_from_request ( request ) def get_job_details ( self , job_id : str ) -> BatchJobDetails : \"\"\"Get details for the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job details cannot be loaded. Returns: BatchJobDetails: Batch job details. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job details\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobDetails . from_response ( body ) def get_job_predictions ( self , job_id : str ) -> Any : \"\"\"Get a batch job's predictions. Args: job_id (str): Job ID. Raises: HumeClientException: If the job predictions cannot be loaded. Returns: Any: Batch job predictions. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /predictions\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job predictions\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return body def download_job_artifacts ( self , job_id : str , filepath : Union [ str , Path ]) -> None : \"\"\"Download a batch job's artifacts as a zip file. Args: job_id (str): Job ID. filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. Raises: HumeClientException: If the job artifacts cannot be loaded. Returns: Any: Batch job artifacts. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /artifacts\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) with Path ( filepath ) . open ( \"wb\" ) as f : f . write ( response . content ) @classmethod def _construct_request ( cls , configs : List [ ModelConfigBase ], urls : List [ str ], transcription_config : Optional [ TranscriptionConfig ], callback_url : Optional [ str ], ) -> Dict [ str , Any ]: request = { \"urls\" : urls , \"models\" : serialize_configs ( configs ), } if transcription_config is not None : request [ \"transcription\" ] = transcription_config . to_dict () if callback_url is not None : request [ \"callback_url\" ] = callback_url return request def _submit_job_from_request ( self , request_body : Any ) -> BatchJob : \"\"\"Start a job for batch processing by passing a JSON request body. This request body should match the request body used by the batch API, including both the list of URLs and the models configuration. Args: request_body (Any): JSON request body to be passed to the batch API. Raises: HumeClientException: If the batch job fails to start. Returns: BatchJob: A `BatchJob` that wraps the batch computation. \"\"\" endpoint = self . _construct_endpoint ( \"jobs\" ) response = requests . post ( endpoint , json = request_body , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . decoder . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( f \"Failed batch request: { response . text } \" ) if \"job_id\" not in body : if \"fault\" in body and \"faultstring\" in body [ \"fault\" ]: fault = body [ \"fault\" ] fault_string = fault [ \"faultstring\" ] if \"detail\" in fault and \"errorcode\" in fault [ \"detail\" ]: detail = fault [ \"detail\" ] error_code = detail [ \"errorcode\" ] if \"InvalidApiKey\" in error_code : raise HumeClientException ( \"HumeBatchClient initialized with invalid API key.\" ) raise HumeClientException ( f \"Could not start batch job: { error_code } : { fault_string } \" ) raise HumeClientException ( f \"Could not start batch job: { fault_string } \" ) raise HumeClientException ( f \"Unexpected error when starting batch job: { body } \" ) return BatchJob ( self , body [ \"job_id\" ]) __init__ ( api_key , * args , ** kwargs ) Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 45 46 47 48 49 50 51 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs ) download_job_artifacts ( job_id , filepath ) Download a batch job's artifacts as a zip file. Parameters: Name Type Description Default job_id str Job ID. required filepath Optional [ Union [ str , Path ]] Filepath where artifacts will be downloaded. required Raises: Type Description HumeClientException If the job artifacts cannot be loaded. Returns: Name Type Description Any None Batch job artifacts. Source code in hume/_batch/hume_batch_client.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def download_job_artifacts ( self , job_id : str , filepath : Union [ str , Path ]) -> None : \"\"\"Download a batch job's artifacts as a zip file. Args: job_id (str): Job ID. filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. Raises: HumeClientException: If the job artifacts cannot be loaded. Returns: Any: Batch job artifacts. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /artifacts\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) with Path ( filepath ) . open ( \"wb\" ) as f : f . write ( response . content ) get_api_type () classmethod Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_batch/hume_batch_client.py 53 54 55 56 57 58 59 60 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH get_job ( job_id ) Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 62 63 64 65 66 67 68 69 70 71 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id ) get_job_details ( job_id ) Get details for the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job details cannot be loaded. Returns: Name Type Description BatchJobDetails BatchJobDetails Batch job details. Source code in hume/_batch/hume_batch_client.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def get_job_details ( self , job_id : str ) -> BatchJobDetails : \"\"\"Get details for the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job details cannot be loaded. Returns: BatchJobDetails: Batch job details. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job details\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobDetails . from_response ( body ) get_job_predictions ( job_id ) Get a batch job's predictions. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job predictions cannot be loaded. Returns: Name Type Description Any Any Batch job predictions. Source code in hume/_batch/hume_batch_client.py 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def get_job_predictions ( self , job_id : str ) -> Any : \"\"\"Get a batch job's predictions. Args: job_id (str): Job ID. Raises: HumeClientException: If the job predictions cannot be loaded. Returns: Any: Batch job predictions. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /predictions\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job predictions\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return body submit_job ( urls , configs , transcription_config = None , callback_url = None ) Submit a job for batch processing. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default urls List [ str ] List of URLs to media files to be processed. required configs List [ ModelConfigBase ] List of model config objects to run on each media URL. required transcription_config Optional [ TranscriptionConfig ] A TranscriptionConfig object. None callback_url Optional [ str ] A URL to which a POST request will be sent upon job completion. None Returns: Name Type Description BatchJob BatchJob The BatchJob representing the batch computation. Source code in hume/_batch/hume_batch_client.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ], transcription_config : Optional [ TranscriptionConfig ] = None , callback_url : Optional [ str ] = None , ) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object. callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _construct_request ( configs , urls , transcription_config , callback_url ) return self . _submit_job_from_request ( request )","title":"HumeBatchClient"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.__init__","text":"Construct a HumeBatchClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_batch/hume_batch_client.py 45 46 47 48 49 50 51 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeBatchClient. Args: api_key (str): Hume API key. \"\"\" super () . __init__ ( api_key , * args , ** kwargs )","title":"__init__()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.download_job_artifacts","text":"Download a batch job's artifacts as a zip file. Parameters: Name Type Description Default job_id str Job ID. required filepath Optional [ Union [ str , Path ]] Filepath where artifacts will be downloaded. required Raises: Type Description HumeClientException If the job artifacts cannot be loaded. Returns: Name Type Description Any None Batch job artifacts. Source code in hume/_batch/hume_batch_client.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def download_job_artifacts ( self , job_id : str , filepath : Union [ str , Path ]) -> None : \"\"\"Download a batch job's artifacts as a zip file. Args: job_id (str): Job ID. filepath (Optional[Union[str, Path]]): Filepath where artifacts will be downloaded. Raises: HumeClientException: If the job artifacts cannot be loaded. Returns: Any: Batch job artifacts. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /artifacts\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) with Path ( filepath ) . open ( \"wb\" ) as f : f . write ( response . content )","title":"download_job_artifacts()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_api_type","text":"Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_batch/hume_batch_client.py 53 54 55 56 57 58 59 60 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . BATCH","title":"get_api_type()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job","text":"Rehydrate a job based on a Job ID. Parameters: Name Type Description Default job_id str ID of the job to rehydrate. required Returns: Name Type Description BatchJob BatchJob Job associated with the given ID. Source code in hume/_batch/hume_batch_client.py 62 63 64 65 66 67 68 69 70 71 def get_job ( self , job_id : str ) -> BatchJob : \"\"\"Rehydrate a job based on a Job ID. Args: job_id (str): ID of the job to rehydrate. Returns: BatchJob: Job associated with the given ID. \"\"\" return BatchJob ( self , job_id )","title":"get_job()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_details","text":"Get details for the batch job. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job details cannot be loaded. Returns: Name Type Description BatchJobDetails BatchJobDetails Batch job details. Source code in hume/_batch/hume_batch_client.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def get_job_details ( self , job_id : str ) -> BatchJobDetails : \"\"\"Get details for the batch job. Args: job_id (str): Job ID. Raises: HumeClientException: If the job details cannot be loaded. Returns: BatchJobDetails: Batch job details. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } \" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job details\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return BatchJobDetails . from_response ( body )","title":"get_job_details()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.get_job_predictions","text":"Get a batch job's predictions. Parameters: Name Type Description Default job_id str Job ID. required Raises: Type Description HumeClientException If the job predictions cannot be loaded. Returns: Name Type Description Any Any Batch job predictions. Source code in hume/_batch/hume_batch_client.py 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 def get_job_predictions ( self , job_id : str ) -> Any : \"\"\"Get a batch job's predictions. Args: job_id (str): Job ID. Raises: HumeClientException: If the job predictions cannot be loaded. Returns: Any: Batch job predictions. \"\"\" endpoint = self . _construct_endpoint ( f \"jobs/ { job_id } /predictions\" ) response = requests . get ( endpoint , timeout = self . _DEFAULT_API_TIMEOUT , headers = self . _get_client_headers (), ) try : body = response . json () except json . JSONDecodeError : # pylint: disable=raise-missing-from raise HumeClientException ( \"Unexpected error when getting job predictions\" ) if \"message\" in body and body [ \"message\" ] == \"job not found\" : raise HumeClientException ( f \"Could not find a job with ID { job_id } \" ) return body","title":"get_job_predictions()"},{"location":"batch/hume-batch-client/#hume._batch.hume_batch_client.HumeBatchClient.submit_job","text":"Submit a job for batch processing. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default urls List [ str ] List of URLs to media files to be processed. required configs List [ ModelConfigBase ] List of model config objects to run on each media URL. required transcription_config Optional [ TranscriptionConfig ] A TranscriptionConfig object. None callback_url Optional [ str ] A URL to which a POST request will be sent upon job completion. None Returns: Name Type Description BatchJob BatchJob The BatchJob representing the batch computation. Source code in hume/_batch/hume_batch_client.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def submit_job ( self , urls : List [ str ], configs : List [ ModelConfigBase ], transcription_config : Optional [ TranscriptionConfig ] = None , callback_url : Optional [ str ] = None , ) -> BatchJob : \"\"\"Submit a job for batch processing. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: urls (List[str]): List of URLs to media files to be processed. configs (List[ModelConfigBase]): List of model config objects to run on each media URL. transcription_config (Optional[TranscriptionConfig]): A `TranscriptionConfig` object. callback_url (Optional[str]): A URL to which a POST request will be sent upon job completion. Returns: BatchJob: The `BatchJob` representing the batch computation. \"\"\" request = self . _construct_request ( configs , urls , transcription_config , callback_url ) return self . _submit_job_from_request ( request )","title":"submit_job()"},{"location":"batch/transcription-config/","text":"Bases: ConfigBase [ TranscriptionConfig ] Configuration for speech transcription. Parameters: Name Type Description Default language Optional [ str ] By default, we use an automated language detection method for our Speech Prosody, Language, and NER models. However, if you know what language is being spoken in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results. You can specify any of the following: zh , da , nl , en , en-AU , en-IN , en-NZ , en-GB , fr , fr-CA , de , hi , hi-Latn , id , it , ja , ko , no , pl , pt , pt-BR , pt-PT , ru , es , es-419 , sv , ta , tr , or uk . None Source code in hume/_batch/transcription_config.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @dataclass class TranscriptionConfig ( ConfigBase [ \"TranscriptionConfig\" ]): \"\"\"Configuration for speech transcription. Args: language (Optional[str]): By default, we use an automated language detection method for our Speech Prosody, Language, and NER models. However, if you know what language is being spoken in your media samples, you can specify it via its BCP-47 tag and potentially obtain more accurate results. You can specify any of the following: `zh`, `da`, `nl`, `en`, `en-AU`, `en-IN`, `en-NZ`, `en-GB`, `fr`, `fr-CA`, `de`, `hi`, `hi-Latn`, `id`, `it`, `ja`, `ko`, `no`, `pl`, `pt`, `pt-BR`, `pt-PT`, `ru`, `es`, `es-419`, `sv`, `ta`, `tr`, or `uk`. \"\"\" language : Optional [ str ] = None","title":"TranscriptionConfig"},{"location":"config/burst-config/","text":"Bases: ModelConfigBase [ BurstConfig ] Configuration for the vocal burst model. Source code in hume/models/config/burst_config.py 8 9 10 11 12 13 14 15 16 17 18 19 @dataclass class BurstConfig ( ModelConfigBase [ \"BurstConfig\" ]): \"\"\"Configuration for the vocal burst model.\"\"\" @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/burst_config.py 12 13 14 15 16 17 18 19 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST","title":"BurstConfig"},{"location":"config/burst-config/#hume.models.config.burst_config.BurstConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/burst_config.py 12 13 14 15 16 17 18 19 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . BURST","title":"get_model_type()"},{"location":"config/face-config/","text":"Bases: ModelConfigBase [ FaceConfig ] Configuration for the facial expression model. Parameters: Name Type Description Default fps_pred Optional [ float ] Number of frames per second to process. Other frames will be omitted from the response. This configuration is only available for the batch API. None prob_threshold Optional [ float ] Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. This configuration is only available for the batch API. None identify_faces Optional [ bool ] Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. None min_face_size Optional [ float ] Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. This configuration is only available for the batch API. None save_faces Optional [ bool ] Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is only available for the batch API. None descriptions Optional [ Dict [ str , Any ]] Configuration for Descriptions predictions. Descriptions prediction can be enabled by setting \"descriptions\": {}. Currently, Descriptions prediction cannot be further configured with any parameters. If missing or null, no descriptions predictions will be generated. None facs Optional [ Dict [ str , Any ]] Configuration for FACS predictions. FACS prediction can be enabled by setting \"facs\": {}. Currently, FACS prediction cannot be further configured with any parameters. If missing or null, no facs predictions will be generated. None Source code in hume/models/config/face_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @dataclass class FaceConfig ( ModelConfigBase [ \"FaceConfig\" ]): \"\"\"Configuration for the facial expression model. Args: fps_pred (Optional[float]): Number of frames per second to process. Other frames will be omitted from the response. This configuration is only available for the batch API. prob_threshold (Optional[float]): Face detection probability threshold. Faces detected with a probability less than this threshold will be omitted from the response. This configuration is only available for the batch API. identify_faces (Optional[bool]): Whether to return identifiers for faces across frames. If true, unique identifiers will be assigned to face bounding boxes to differentiate different faces. If false, all faces will be tagged with an \"unknown\" ID. min_face_size (Optional[float]): Minimum bounding box side length in pixels to treat as a face. Faces detected with a bounding box side length in pixels less than this threshold will be omitted from the response. This configuration is only available for the batch API. save_faces (Optional[bool]): Whether to extract and save the detected faces to the artifacts directory included in the response. This configuration is only available for the batch API. descriptions (Optional[Dict[str, Any]]): Configuration for Descriptions predictions. Descriptions prediction can be enabled by setting \"descriptions\": {}. Currently, Descriptions prediction cannot be further configured with any parameters. If missing or null, no descriptions predictions will be generated. facs (Optional[Dict[str, Any]]): Configuration for FACS predictions. FACS prediction can be enabled by setting \"facs\": {}. Currently, FACS prediction cannot be further configured with any parameters. If missing or null, no facs predictions will be generated. \"\"\" fps_pred : Optional [ float ] = None prob_threshold : Optional [ float ] = None identify_faces : Optional [ bool ] = None min_face_size : Optional [ float ] = None save_faces : Optional [ bool ] = None descriptions : Optional [ Dict [ str , Any ]] = None facs : Optional [ Dict [ str , Any ]] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/face_config.py 48 49 50 51 52 53 54 55 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE","title":"FaceConfig"},{"location":"config/face-config/#hume.models.config.face_config.FaceConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/face_config.py 48 49 50 51 52 53 54 55 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACE","title":"get_model_type()"},{"location":"config/facemesh-config/","text":"Bases: ModelConfigBase [ FacemeshConfig ] Configuration for the facemesh model. This model is not available for the batch API. Source code in hume/models/config/facemesh_config.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @dataclass class FacemeshConfig ( ModelConfigBase [ \"FacemeshConfig\" ]): \"\"\"Configuration for the facemesh model. This model is not available for the batch API. \"\"\" @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/facemesh_config.py 15 16 17 18 19 20 21 22 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH","title":"FacemeshConfig"},{"location":"config/facemesh-config/#hume.models.config.facemesh_config.FacemeshConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/facemesh_config.py 15 16 17 18 19 20 21 22 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . FACEMESH","title":"get_model_type()"},{"location":"config/language-config/","text":"Bases: ModelConfigBase [ LanguageConfig ] Configuration for the language emotion model. Parameters: Name Type Description Default granularity Optional [ str ] The granularity at which to generate predictions. Accepted values are word , sentence , utterance , or conversational_turn . The default is utterance . utterance corresponds to a natural pause or break in conversation conversational_turn corresponds to a change in speaker. This configuration is available for the streaming API, but only with values word and sentence . None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. None sentiment Optional [ Dict [ str , Any ]] Configuration for Sentiment predictions. Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, Sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated. None toxicity Optional [ Dict [ str , Any ]] Configuration for Toxicity predictions. Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, Toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated. None Source code in hume/models/config/language_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @dataclass class LanguageConfig ( ModelConfigBase [ \"LanguageConfig\" ]): \"\"\"Configuration for the language emotion model. Args: granularity (Optional[str]): The granularity at which to generate predictions. Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`. The default is `utterance`. `utterance` corresponds to a natural pause or break in conversation `conversational_turn` corresponds to a change in speaker. This configuration is available for the streaming API, but only with values `word` and `sentence`. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. sentiment (Optional[Dict[str, Any]]): Configuration for Sentiment predictions. Sentiment prediction can be enabled by setting \"sentiment\": {}. Currently, Sentiment prediction cannot be further configured with any parameters. If missing or null, no sentiment predictions will be generated. toxicity (Optional[Dict[str, Any]]): Configuration for Toxicity predictions. Toxicity prediction can be enabled by setting \"toxicity\": {}. Currently, Toxicity prediction cannot be further configured with any parameters. If missing or null, no toxicity predictions will be generated. \"\"\" granularity : Optional [ str ] = None identify_speakers : Optional [ bool ] = None sentiment : Optional [ Dict [ str , Any ]] = None toxicity : Optional [ Dict [ str , Any ]] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/language_config.py 39 40 41 42 43 44 45 46 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE","title":"LanguageConfig"},{"location":"config/language-config/#hume.models.config.language_config.LanguageConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/language_config.py 39 40 41 42 43 44 45 46 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . LANGUAGE","title":"get_model_type()"},{"location":"config/ner-config/","text":"Bases: ModelConfigBase [ NerConfig ] Configuration for the named-entity emotion model. This model is only available for the batch API. Parameters: Name Type Description Default identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. None Source code in hume/models/config/ner_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @dataclass class NerConfig ( ModelConfigBase [ \"NerConfig\" ]): \"\"\"Configuration for the named-entity emotion model. This model is only available for the batch API. Args: identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. \"\"\" identify_speakers : Optional [ bool ] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/ner_config.py 24 25 26 27 28 29 30 31 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER","title":"NerConfig"},{"location":"config/ner-config/#hume.models.config.ner_config.NerConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/ner_config.py 24 25 26 27 28 29 30 31 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . NER","title":"get_model_type()"},{"location":"config/prosody-config/","text":"Bases: ModelConfigBase [ ProsodyConfig ] Configuration for the speech prosody model. Parameters: Name Type Description Default granularity Optional [ str ] The granularity at which to generate predictions. Accepted values are word , sentence , utterance , or conversational_turn . The default is utterance . utterance corresponds to a natural pause or break in conversation conversational_turn corresponds to a change in speaker. This configuration is only available for the batch API. None identify_speakers Optional [ bool ] Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. None window Optional [ Dict [ str , float ]] Sliding window used to chunk audio. This dictionary input takes two entries: length and step representing the width of the window in seconds and the the step size in seconds. This configuration is only available for the batch API. None Source code in hume/models/config/prosody_config.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @dataclass class ProsodyConfig ( ModelConfigBase [ \"ProsodyConfig\" ]): \"\"\"Configuration for the speech prosody model. Args: granularity (Optional[str]): The granularity at which to generate predictions. Accepted values are `word`, `sentence`, `utterance`, or `conversational_turn`. The default is `utterance`. `utterance` corresponds to a natural pause or break in conversation `conversational_turn` corresponds to a change in speaker. This configuration is only available for the batch API. identify_speakers (Optional[bool]): Whether to return identifiers for speakers over time. If true, unique identifiers will be assigned to spoken words to differentiate different speakers. If false, all speakers will be tagged with an \"unknown\" ID. This configuration is only available for the batch API. window (Optional[Dict[str, float]]): Sliding window used to chunk audio. This dictionary input takes two entries: `length` and `step` representing the width of the window in seconds and the the step size in seconds. This configuration is only available for the batch API. \"\"\" identify_speakers : Optional [ bool ] = None granularity : Optional [ str ] = None window : Optional [ Dict [ str , float ]] = None @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY get_model_type () classmethod Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/prosody_config.py 34 35 36 37 38 39 40 41 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY","title":"ProsodyConfig"},{"location":"config/prosody-config/#hume.models.config.prosody_config.ProsodyConfig.get_model_type","text":"Get the configuration model type. Returns: Name Type Description ModelType ModelType Model type. Source code in hume/models/config/prosody_config.py 34 35 36 37 38 39 40 41 @classmethod def get_model_type ( cls ) -> ModelType : \"\"\"Get the configuration model type. Returns: ModelType: Model type. \"\"\" return ModelType . PROSODY","title":"get_model_type()"},{"location":"stream/hume-stream-client/","text":"Bases: ClientBase Streaming API client. Example import asyncio from hume import HumeStreamClient , StreamSocket from hume.models.config import FaceConfig async def main (): client = HumeStreamClient ( \"<your-api-key>\" ) config = FaceConfig ( identify_faces = True ) async with client . connect ([ config ]) as socket : result = await socket . send_file ( \"<your-image-filepath>\" ) print ( result ) asyncio . run ( main ()) Source code in hume/_stream/hume_stream_client.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 class HumeStreamClient ( ClientBase ): \"\"\"Streaming API client. Example: ```python import asyncio from hume import HumeStreamClient, StreamSocket from hume.models.config import FaceConfig async def main(): client = HumeStreamClient(\"<your-api-key>\") config = FaceConfig(identify_faces=True) async with client.connect([config]) as socket: result = await socket.send_file(\"<your-image-filepath>\") print(result) asyncio.run(main()) ``` \"\"\" _DEFAULT_API_TIMEOUT = 10 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs ) @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc @asynccontextmanager async def _connect_with_configs_dict ( self , configs_dict : Any ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API with a single models configuration dict. Args: configs_dict (Any): Models configurations dict. This should be a dict from model name to model configuration dict. An empty dict uses the default configuration. \"\"\" configs = deserialize_configs ( configs_dict ) async with self . connect ( configs ) as websocket : yield websocket __init__ ( api_key , * args , ** kwargs ) Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs ) connect ( configs , stream_window_ms = None ) async Connect to the streaming API. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default configs List [ ModelConfigBase ] List of job configs. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Source code in hume/_stream/hume_stream_client.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc get_api_type () classmethod Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_stream/hume_stream_client.py 55 56 57 58 59 60 61 62 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM","title":"HumeStreamClient"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.__init__","text":"Construct a HumeStreamClient. Parameters: Name Type Description Default api_key str Hume API key. required Source code in hume/_stream/hume_stream_client.py 42 43 44 45 46 47 48 49 50 51 52 53 def __init__ ( self , api_key : str , * args : Any , ** kwargs : Any ): \"\"\"Construct a HumeStreamClient. Args: api_key (str): Hume API key. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) super () . __init__ ( api_key , * args , ** kwargs )","title":"__init__()"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.connect","text":"Connect to the streaming API. Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Parameters: Name Type Description Default configs List [ ModelConfigBase ] List of job configs. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Source code in hume/_stream/hume_stream_client.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @asynccontextmanager async def connect ( self , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ) -> AsyncIterator [ StreamSocket ]: \"\"\"Connect to the streaming API. Note: Only one config per model type should be passed. If more than one config is passed for a given model type, only the last config will be used. Args: configs (List[ModelConfigBase]): List of job configs. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. \"\"\" endpoint = self . _construct_endpoint ( \"models\" ) try : # pylint: disable=no-member async with websockets . connect ( # type: ignore[attr-defined] endpoint , extra_headers = self . _get_client_headers ()) as protocol : yield StreamSocket ( protocol , configs , stream_window_ms = stream_window_ms ) except websockets . exceptions . InvalidStatusCode as exc : status_code : int = exc . status_code if status_code == 401 : # Unauthorized message = \"HumeStreamClient initialized with invalid API key.\" raise HumeClientException ( message ) from exc raise HumeClientException ( \"Unexpected error when creating streaming connection\" ) from exc","title":"connect()"},{"location":"stream/hume-stream-client/#hume._stream.hume_stream_client.HumeStreamClient.get_api_type","text":"Get the ApiType of the client. Returns: Name Type Description ApiType ApiType API type of the client. Source code in hume/_stream/hume_stream_client.py 55 56 57 58 59 60 61 62 @classmethod def get_api_type ( cls ) -> ApiType : \"\"\"Get the ApiType of the client. Returns: ApiType: API type of the client. \"\"\" return ApiType . STREAM","title":"get_api_type()"},{"location":"stream/stream-socket/","text":"Streaming socket connection. Source code in hume/_stream/stream_socket.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class StreamSocket : \"\"\"Streaming socket connection.\"\"\" _FACE_LIMIT = 100 _N_LANDMARKS = 478 _N_SPATIAL = 3 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs ) async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data ) async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload ) async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload ) async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload ) async def _send_bytes_str ( self , bytes_str : str ) -> Any : payload : Dict [ str , Any ] = { \"data\" : bytes_str , \"models\" : self . _serialized_configs , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload ) async def _send_payload ( self , payload : Dict [ str , Any ]) -> Any : request_message = json . dumps ( payload ) await self . _protocol . send ( request_message ) response_data = await self . _protocol . recv () # Cast to str because websockets can send bytes, but we will always accept JSON strings response_str = str ( response_data ) try : response = json . loads ( response_str ) except json . JSONDecodeError as exc : raise HumeClientException ( \"Unexpected error when fetching streaming API predictions\" ) from exc if \"error\" in response : error = response [ \"error\" ] code = response [ \"code\" ] raise HumeClientException . from_error ( code , error ) return response def _validate_configs_with_model_type ( self , config_type : Any , method_name : str ) -> None : for config in self . _configs : if not isinstance ( config , config_type ): config_name = config_type . __name__ invalid_config_name = config . __class__ . __name__ raise HumeClientException ( f \"Socket configured with { invalid_config_name } . \" f \" { method_name } is only supported when using a { config_name } .\" ) __init__ ( protocol , configs , stream_window_ms = None ) Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ ModelConfigBase ] List of model configurations. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Raises: Type Description HumeClientException If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs ) get_job_details () async Get details associated with the current streaming connection. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 161 162 163 164 165 166 167 168 169 170 async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload ) reset_stream () async Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload ) send_bytes ( bytes_data ) async Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str ) send_facemesh ( landmarks ) async Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientException If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data ) send_file ( filepath ) async Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 54 55 56 57 58 59 60 61 62 63 64 65 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data ) send_text ( text ) async Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientException If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload )","title":"StreamSocket"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.__init__","text":"Construct a StreamSocket . Parameters: Name Type Description Default protocol WebSocketClientProtocol Protocol instance from websockets library. required configs List [ ModelConfigBase ] List of model configurations. required stream_window_ms Optional [ int ] Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. None Raises: Type Description HumeClientException If there is an error processing media over the socket connection. Source code in hume/_stream/stream_socket.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , protocol : \"WebSocketClientProtocol\" , configs : List [ ModelConfigBase ], stream_window_ms : Optional [ int ] = None , ): \"\"\"Construct a `StreamSocket`. Args: protocol (WebSocketClientProtocol): Protocol instance from websockets library. configs (List[ModelConfigBase]): List of model configurations. stream_window_ms (Optional[int]): Length of the sliding window in milliseconds to use when aggregating media across streaming payloads within one websocket connection. Raises: HumeClientException: If there is an error processing media over the socket connection. \"\"\" if not HAS_WEBSOCKETS : raise HumeClientException ( \"The websockets package is required to use HumeStreamClient. \" \"Run `pip install hume[stream]` to install a version compatible with the\" \"Hume Python SDK.\" ) self . _protocol = protocol self . _configs = configs self . _stream_window_ms = stream_window_ms # Serialize configs once for full lifetime of socket self . _serialized_configs = serialize_configs ( configs )","title":"__init__()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.get_job_details","text":"Get details associated with the current streaming connection. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 161 162 163 164 165 166 167 168 169 170 async def get_job_details ( self ) -> Any : \"\"\"Get details associated with the current streaming connection. Returns: Any: Response from the streaming API. \"\"\" payload = { \"job_details\" : True , } return await self . _send_payload ( payload )","title":"get_job_details()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.reset_stream","text":"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 async def reset_stream ( self ) -> Any : \"\"\"Reset the streaming sliding window. A sliding window of context is maintained for the lifetime of your streaming connection. Call this method when some media has been fully processed and you want to continue using the same streaming connection without leaking context across media samples. Returns: Any: Response from the streaming API. \"\"\" payload = { \"reset_stream\" : True , } return await self . _send_payload ( payload )","title":"reset_stream()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_bytes","text":"Send raw bytes on the StreamSocket . Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Parameters: Name Type Description Default bytes_data bytes Raw bytes of media to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 async def send_bytes ( self , bytes_data : bytes ) -> Any : \"\"\"Send raw bytes on the `StreamSocket`. Note: Input should be base64 encoded bytes. You can use base64.b64encode() to encode a raw string. Args: bytes_data (bytes): Raw bytes of media to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" bytes_str = bytes_data . decode ( \"utf-8\" ) return await self . _send_bytes_str ( bytes_str )","title":"send_bytes()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_facemesh","text":"Send text on the StreamSocket . This method is intended for use with a FacemeshConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default landmarks List [ List [ List [ float ]]] List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. required Raises: Type Description HumeClientException If the socket is configured with a modality other than facemesh. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def send_facemesh ( self , landmarks : List [ List [ List [ float ]]]) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `FacemeshConfig`. When the socket is configured for other modalities this method will fail. Args: landmarks (List[List[List[float]]]): List of landmark points for multiple faces. The shape of this 3-dimensional list should be (n, 478, 3) where n is the number of faces to be processed, 478 is the number of MediaPipe landmarks per face and 3 represents the (x, y, z) coordinates of each landmark. Raises: HumeClientException: If the socket is configured with a modality other than facemesh. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( FacemeshConfig , \"send_facemesh\" ) n_faces = len ( landmarks ) if n_faces > self . _FACE_LIMIT : raise HumeClientException ( \"Number of faces sent in facemesh payload was greater \" f \"than the limit of { self . _FACE_LIMIT } , found { n_faces } .\" ) if n_faces == 0 : raise HumeClientException ( \"No faces sent in facemesh payload.\" ) n_landmarks = len ( landmarks [ 0 ]) if n_landmarks != self . _N_LANDMARKS : raise HumeClientException ( f \"Number of MediaPipe landmarks per face must be exactly { self . _N_LANDMARKS } , \" f \"found { n_landmarks } .\" ) if len ( landmarks [ 0 ][ 0 ]) != self . _N_SPATIAL : raise HumeClientException ( \"Invalid facemesh payload detected. \" \"Each facemesh landmark should be an (x, y, z) point.\" ) landmarks_str = json . dumps ( landmarks ) bytes_data = base64 . b64encode ( landmarks_str . encode ( \"utf-8\" )) return await self . send_bytes ( bytes_data )","title":"send_facemesh()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_file","text":"Send a file on the StreamSocket . Parameters: Name Type Description Default filepath Path Path to media file to send on socket connection. required Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 54 55 56 57 58 59 60 61 62 63 64 65 async def send_file ( self , filepath : Union [ str , Path ]) -> Any : \"\"\"Send a file on the `StreamSocket`. Args: filepath (Path): Path to media file to send on socket connection. Returns: Any: Response from the streaming API. \"\"\" with Path ( filepath ) . open ( 'rb' ) as f : bytes_data = base64 . b64encode ( f . read ()) return await self . send_bytes ( bytes_data )","title":"send_file()"},{"location":"stream/stream-socket/#hume._stream.stream_socket.StreamSocket.send_text","text":"Send text on the StreamSocket . This method is intended for use with a LanguageConfig . When the socket is configured for other modalities this method will fail. Parameters: Name Type Description Default text str Text to send to the language model. required Raises: Type Description HumeClientException If the socket is configured with a modality other than language. Returns: Name Type Description Any Any Response from the streaming API. Source code in hume/_stream/stream_socket.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 async def send_text ( self , text : str ) -> Any : \"\"\"Send text on the `StreamSocket`. Note: This method is intended for use with a `LanguageConfig`. When the socket is configured for other modalities this method will fail. Args: text (str): Text to send to the language model. Raises: HumeClientException: If the socket is configured with a modality other than language. Returns: Any: Response from the streaming API. \"\"\" self . _validate_configs_with_model_type ( LanguageConfig , \"send_text\" ) payload = { \"data\" : text , \"models\" : self . _serialized_configs , \"raw_text\" : True , } if self . _stream_window_ms is not None : payload [ \"stream_window_ms\" ] = self . _stream_window_ms return await self . _send_payload ( payload )","title":"send_text()"}]}